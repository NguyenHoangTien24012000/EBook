<style>
    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 300;
        src: url(https://static.contineljs.com/fonts/Roboto-Light.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Light.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 400;
        src: url(https://static.contineljs.com/fonts/Roboto-Regular.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Regular.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 500;
        src: url(https://static.contineljs.com/fonts/Roboto-Medium.woff2?v=2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Medium.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 700;
        src: url(https://static.contineljs.com/fonts/Roboto-Bold.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Bold.woff) format("woff");
    }

    * {
        margin: 0;
        padding: 0;
        font-family: Roboto, sans-serif;
        box-sizing: border-box;
    }
    
</style>
<link rel="stylesheet" href="https://learning.oreilly.com/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492092506/files/epub.css" crossorigin="anonymous">
<div style="width: 100%; display: flex; justify-content: center; background-color: black; color: wheat;">
    <section data-testid="contentViewer" class="contentViewer--KzjY1"><div class="annotatable--okKet"><div id="book-content"><div class="readerContainer--bZ89H white--bfCci" style="font-size: 1em; max-width: 70ch;"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 12. Coordinated Batch Processing"><div class="chapter" id="coordinated_processing_id">
        <h1><span class="label">Chapter 12. </span>Coordinated Batch Processing</h1>
        
        
        <p><a data-type="indexterm" data-primary="batch computational patterns" data-secondary="coordinated batch processing" id="ix_ch15-asciidoc0"></a><a data-type="indexterm" data-primary="coordinated batch processing" id="ix_ch15-asciidoc1"></a>The previous chapter described a number of patterns for splitting
        and chaining queues together to achieve more complex batch processing.
        Duplicating and producing multiple different outputs is often
        an important part of batch processing, but sometimes it is equally
        important to pull multiple outputs back together in order to
        generate some sort of aggregate output. A generic illustration
        of such a pattern is shown in <a data-type="xref" href="#fig-coordinated-batch-processing">Figure&nbsp;12-1</a>.</p>
        
        <figure class="width45"><div id="fig-coordinated-batch-processing" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781491983638/files/assets/ddis_15in01.png" alt="An illustration of a generic parallel work distribution and result aggregation batch system." width="785" height="1056">
        <h6><span class="label">Figure 12-1. </span>A generic parallel work distribution and result aggregation batch system</h6>
        </div></figure>
        
        <p><a data-type="indexterm" data-primary="MapReduce pattern" id="ix_ch15-asciidocMRp"></a>Probably the most canonical example of this aggregation is the <em>reduce</em>
        part of the MapReduce pattern. It’s easy to see that the map step
        is an example of sharding a work queue, and the reduce step is an
        example of coordinated processing that eventually reduces a large number
        of outputs down to a single aggregate response. However, there are
        a number of different aggregate patterns for batch processing, and this
        chapter discusses a number of them in addition to real-world applications.</p>
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Join (or Barrier Synchronization)"><div class="sect1" id="idm139824735812976">
        <h1>Join (or Barrier Synchronization)</h1>
        
        <p><a data-type="indexterm" data-primary="coordinated batch processing" data-secondary="join pattern" id="idm139824735811568"></a><a data-type="indexterm" data-primary="join pattern" data-secondary="coordinated batch processing" id="idm139824735810528"></a>In previous chapters, we saw patterns for breaking up work and
        distributing it in parallel on multiple nodes. In particular, we saw how a sharded work queue could distribute work in parallel to a
        number of different work queue shards. However, sometimes when processing a workflow, it is necessary to have the complete set of work available to
        you before you move on to the next stage of the workflow.</p>
        
        <p>One option for doing this was shown in the previous chapter, which was
        to merge multiple queues together. However, merge simply blends the
        output of two work queues into a single work queue for additional processing. While the merge pattern is sufficient in some
        cases, it does not ensure that a complete dataset is present prior to
        the beginning of processing. This means that there can be no guarantees
        about the completeness of the processing being performed, as well as no
        opportunity to compute aggregate statistics for all of the elements that
        have been processed.</p>
        
        <p>Instead, we need a stronger, coordinated primitive for batch data
        processing, and that primitive is the <em>join</em> pattern. Join is similar to
        joining a thread. The basic idea is that all of the work is happening in parallel, but work items aren’t released out of the join until all of
        the work items that are processed in parallel are completed. This is
        also generally known as <a data-type="indexterm" data-primary="barrier synchronization" data-seealso="join pattern" id="idm139824735664416"></a><em>barrier</em> synchronization in concurrent programming. An illustration of the join pattern for a coordinated batch is shown in <a data-type="xref" href="#fig-coordinated-join">Figure&nbsp;12-2</a>.</p>
        
        <p>Coordination through join ensures that no data is
        missing before some sort of aggregation phase is performed (e.g., finding
        the sum of some value in a set). The value of the join is that it ensures
        that all of the data in the set is present. The downside of the join
        pattern is that it requires that all data be processed by a previous
        stage before subsequent computation can begin. This reduces the
        parallelism that is possible in the batch workflow, and thus increases
        the overall latency of running the workflow.</p>
        
        <figure><div id="fig-coordinated-join" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781491983638/files/assets/ddis_15in02.png" alt="An illustration of the join pattern for batch processing" width="827" height="1046">
        <h6><span class="label">Figure 12-2. </span>The join pattern for batch processing</h6>
        </div></figure>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Reduce"><div class="sect1" id="idm139824735809440">
        <h1>Reduce</h1>
        
        <p><a data-type="indexterm" data-primary="coordinated batch processing" data-secondary="reduce pattern" id="idm139824735727536"></a><a data-type="indexterm" data-startref="ix_ch15-asciidocMRp" id="idm139824735726496"></a><a data-type="indexterm" data-primary="reduce pattern" data-seealso="MapReduce pattern" id="idm139824735725824"></a>If sharding a work queue is an example of the <em>map</em> phase of
        the canonical map/reduce algorithm, then what remains is the <em>reduce</em>
        phase. Reduce is an example of a coordinated batch processing pattern
        because it can happen regardless of how the input is split up, and it is
        used similar to <em>join</em>; that is, to group together the parallel output of a
        number of different batch operations on different pieces of data.</p>
        
        <p>However, in contrast to the join pattern described previously, the goal
        of reduce is not to wait until all data has been processed, but rather
        to optimistically merge together all of the parallel data items into
        a single comprehensive representation of the full set.</p>
        
        <p>With the reduce pattern, each step in the reduce merges several
        different outputs into a single output. This stage is called “reduce”
        because it reduces the total number of outputs. Additionally, it
        reduces the data from a complete data item to simply the representative data necessary for producing the answer to a specific batch computation.
        Because the reduce phase operates on a range of input, and produces
        a similar output, the reduce phase can be
        repeated as many or as few times as necessary in order to successfully
        reduce the output down to a single output for the entire data set.</p>
        
        <p><a data-type="indexterm" data-primary="join pattern" data-secondary="reduce pattern vs." id="idm139824735721216"></a>This is a fortunate contrast to the join pattern, because unlike join, it means that reduce can be started in parallel while there is still processing going on as part of the map/shard phase. Of course, in order
        to produce a complete output, all of the data must be processed eventually, but the ability to begin early means that the
        batch computation executes more quickly overall.</p>
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Hands On: Count"><div class="sect2" id="idm139824735719584">
        <h2>Hands On: Count</h2>
        
        <p><a data-type="indexterm" data-primary="coordinated batch processing" data-secondary="counting example" id="idm139824735718016"></a><a data-type="indexterm" data-primary="counting, coordinated batch processing for" id="idm139824735717024"></a>To understand how the reduce pattern works, consider the task of
        counting the number of instances of a particular word in a book.  We can first
        use sharding to divide up the work of counting words into
        a number of different work queues. As an example, we could create
        10 different sharded work queues with 10 different people responsible
        for counting words in each queue. We can shard the book among
        these 10 work queues by looking at the page number. All pages that
        end in the number 1 will go to the first queue, all pages that end
        in the number 2 will go to the second, and so forth.</p>
        
        <p>Once all of the people have finished processing their pages, they write
        down their results on a piece of paper. For example, they might write:</p>
        
        <pre data-type="programlisting">a: 50
        the: 17
        cat: 2
        airplane: 1
        ...</pre>
        
        <p>This can be output to the reduce phase. Remember that the reduce
        pattern reduces by combining two or more outputs into a single output.</p>
        
        <p>Given a second output:</p>
        
        <pre data-type="programlisting">a: 30
        the: 25
        dog: 4
        airplane: 2
        ...</pre>
        
        <p>The reduction proceeds by summing up all of the counts for the various
        words, in this example producing:</p>
        
        <pre data-type="programlisting">a: 80
        the 42
        dog: 4
        cat: 2
        airplane: 3
        ...</pre>
        
        <p>It’s clear to see that this reduction phase can be repeated on the
        output of previous reduce phases until there is only a single
        reduced output left. This is valuable since this means that reductions
        can be performed in parallel.</p>
        
        <p>Ultimately, in this example you can see that the output of the
        reduction will be a single output with the count of all of the various
        words that are present in the book.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Sum"><div class="sect2" id="idm139824735719056">
        <h2>Sum</h2>
        
        <p><a data-type="indexterm" data-primary="coordinated batch processing" data-secondary="summing with" id="idm139824735708928"></a><a data-type="indexterm" data-primary="sums, coordinated batch processing for" id="idm139824735707888"></a>A similar but slightly different form of reduction is the summation of
        a collection of different values. This is like counting, but rather
        than simply counting one for every value, you actually add together
        a value that is present in the original output data.</p>
        
        <p>Suppose, for example, you want to sum the total population of the
        United States. Assume that you will do this by measuring the population
        in every town and then summing them all together.</p>
        
        <p>A first step might be to shard the work into
        work queues of towns, sharded by state. This is a great first sharding,
        but it’s clear that even when distributed in parallel, it would take a
        single person a long time to count the number of people in every town.
        Consequently, we perform a second sharding to another set of work queues,
        this time by county.</p>
        
        <p>At this point, we have parallelized first to the level of states,
        then to the level of counties, and then each work queue in each county
        produces a stream of outputs of (town, population) tuples.</p>
        
        <p>Now that we are producing output, the reduce pattern can kick in.</p>
        
        <p>In this case, the reduce doesn’t even really need to be aware of the
        two-level sharding that we performed. It is sufficient for the reduce
        to simply grab two or more output items, such as <code>(Seattle, 4,000,000)</code> and <code>(Northampton, 25,000)</code>, and sum them together to
        produce a new output <code>(Seattle-Northampton, 4,025,000)</code>. It’s clear
        to see that, like counting, this reduction can be performed an arbitrary
        number of times with the same code running at each interval, and at the
        end, there will only be a single output containing the complete
        population of the United States. Importantly, again, nearly all of
        the computation required is happening in parallel.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Histogram"><div class="sect2" id="idm139824735701936">
        <h2>Histogram</h2>
        
        <p><a data-type="indexterm" data-primary="coordinated batch processing" data-secondary="histograms with" id="idm139824735700528"></a><a data-type="indexterm" data-primary="histograms" id="idm139824735699536"></a><a data-type="indexterm" data-primary="MapReduce pattern" id="idm139824735698864"></a>As a final example of the reduce pattern, consider that while we
        are counting the population of the United States via parallel
        sharding/mapping and reducing, we also want to build a model of the
        average American family. To do this, we want to develop a <em>histogram</em>
        of family size; that is, a model that estimates the total number of families with zero to 10 children.  We will perform our multi-level
        sharding exactly as before (indeed, we can likely use the same workers).</p>
        
        <p class="pagebreak-before">However, this time, the output of the data collection phase is a
        histogram per town.</p>
        
        <pre data-type="programlisting">0: 15%
        1: 25%
        2: 50%
        3: 10%
        4: 5%</pre>
        
        <p>From the previous examples, we can see that if we apply the
        reduce pattern, we should be able to combine all of these histograms
        to develop a comprehensive picture of the United States. At first blush,
        it may seem quite difficult to understand how to merge these histograms, but
        when combined with the population data from the summation example, we
        can see that if we multiply each histogram by its relative population,
        then we can obtain the total population for each item being merged.
        If we then divide this new total by the sum of the merged populations, it is clear that we can merge and update multiple different histograms into a single output. Given this, we can apply the reduce
        pattern as many times as necessary until a single output is produced.</p>
        </div></section>
        
        
        
        
        
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Hands On: An Image Tagging and Processing Pipeline"><div class="sect1" id="idm139824735694496">
        <h1>Hands On: An Image Tagging and Processing Pipeline</h1>
        
        <p><a data-type="indexterm" data-primary="coordinated batch processing" data-secondary="image tagging/processing pipeline" id="ix_ch15-asciidoc2"></a><a data-type="indexterm" data-primary="image tagging/processing pipeline" id="ix_ch15-asciidoc3"></a>To see how coordinated batch processing can be used to accomplish a larger
        batch task, consider the job of tagging and processing a set of images.
        Let us assume that we have a large collection of images of highways at
        rush hour, and we want to count both the numbers of cars, trucks, and motorcycles, as well as distribution of the colors of each of the cars.
        Let us also suppose that there is a preliminary step to blur the license plates of all of the cars to preserve anonymity.</p>
        
        <p>The images are delivered to us as a series of HTTPS URLs where each URL
        points to a raw image. The first stage in the pipeline is to find and blur the
        license plates. To simplify each task in the work queue, we will have one
        worker that detects a license plate, and a second worker that blurs that
        location in the image. We will combine these two different worker containers into a single container group using the multi-worker pattern
        described in the previous chapter.
        This separation of concerns may seem unnecessary,
        but it is useful given that the workers for blurring images can be
        reused to blur other outputs (e.g., people’s faces).</p>
        
        <p>Additionally, to ensure reliability and to maximize parallel processing, we will shard the images across multiple worker queues. This complete
        workflow for sharded image blurring is shown in <a data-type="xref" href="#fig-mult-blurring-shards">Figure&nbsp;12-3</a>.</p>
        
        <figure><div id="fig-mult-blurring-shards" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781491983638/files/assets/ddis_15in03.png" alt="The sharded work queue and the multiple blurring shards" width="691" height="926">
        <h6><span class="label">Figure 12-3. </span>The sharded work queue and the multiple blurring shards</h6>
        </div></figure>
        
        <p>Once each image has been successfully blurred, we will upload it to a different location, and we will then delete the originals.  However, we
        don’t want to delete the original until <em>all</em> of the images have been
        successfully blurred in case there is some sort of catastrophic failure
        and we need to rerun this entire pipeline. Thus, to wait for all of
        the blurring to complete, we use the join pattern to
        merge the output of all of the sharded blurring work queues into a single
        queue that will only release its items after all of the shards have
        completed the work.</p>
        
        <p>Now we are ready to delete the original images as well as begin work
        on car model and color detection. Again, we want to maximize the throughput of this pipeline, so we will use the copier pattern from
        the previous chapter to duplicate the work queue items to two different
        queues:</p>
        
        <ul>
        <li>
        <p>A work queue that deletes the original images</p>
        </li>
        <li>
        <p>A work queue that identifies the type of vehicle (car, truck, motorcycle) and the color of the vehicle</p>
        </li>
        </ul>
        
        <p><a data-type="xref" href="#fig-recog-parts-pipeline">Figure&nbsp;12-4</a> shows these stages of the processing pipeline.</p>
        
        <figure><div id="fig-recog-parts-pipeline" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781491983638/files/assets/ddis_15in04.png" alt="The output join, copier, deletion, and image recognition parts of the pipeline" width="546" height="1178">
        <h6><span class="label">Figure 12-4. </span>The output join, copier, deletion, and image recognition parts of the pipeline</h6>
        </div></figure>
        
        <p>Finally we need to design the queue that identifies vehicles and colors
        and aggregates these statistics into a final count. To do this, we first
        again apply the shard pattern to distribute the work out to a number of
        queues. Each of these queues has two different workers: one that
        identifies the location and type of each vehicle and one that identifies
        the color of a region. We will again join these together using the
        multi-worker pattern described in the previous chapter. As before,
        the separation of code into different containers enables us to reuse the
        color detection container for multiple tasks beyond identifying the color
        of the cars.</p>
        
        <p>The output of this work queue is a JSON tuple that looks like this:</p>
        
        <pre data-type="programlisting">{
          "vehicles": {
             "car": 12,
             "truck": 7,
             "motorcycle": 4
           },
           "colors": {
             "white": 8,
             "black": 3,
             "blue": 6,
             "red": 6
           }
         }</pre>
        
        <p>This data represents the information found in a single image. To aggregate
        all of this data together, we will use the reduce pattern described
        previously and made famous by <a data-type="indexterm" data-primary="MapReduce pattern" id="idm139824735634368"></a>MapReduce to sum everything together just as
        we did in the count example above. At the end, this reduce pipeline stage produces the final count of images and colors found in the complete set of images<a data-type="indexterm" data-startref="ix_ch15-asciidoc3" id="idm139824735633312"></a><a data-type="indexterm" data-startref="ix_ch15-asciidoc2" id="idm139824735632640"></a>.<a data-type="indexterm" data-startref="ix_ch15-asciidoc1" id="idm139824735631840"></a><a data-type="indexterm" data-startref="ix_ch15-asciidoc0" id="idm139824735631136"></a></p>
        </div></section>
        
        
        
        
        
        
        
        </div></section></div></div><link rel="stylesheet" href="/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="/api/v2/epubs/urn:orm:book:9781491983638/files/epub.css" crossorigin="anonymous"></div></div></section>
</div>

https://learning.oreilly.com