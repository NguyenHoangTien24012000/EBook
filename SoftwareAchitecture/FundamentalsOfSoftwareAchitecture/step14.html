<style>
    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 300;
        src: url(https://static.contineljs.com/fonts/Roboto-Light.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Light.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 400;
        src: url(https://static.contineljs.com/fonts/Roboto-Regular.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Regular.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 500;
        src: url(https://static.contineljs.com/fonts/Roboto-Medium.woff2?v=2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Medium.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 700;
        src: url(https://static.contineljs.com/fonts/Roboto-Bold.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Bold.woff) format("woff");
    }

    * {
        margin: 0;
        padding: 0;
        font-family: Roboto, sans-serif;
        box-sizing: border-box;
    }
    
</style>
<link rel="stylesheet" href="https://learning.oreilly.com/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492092506/files/epub.css" crossorigin="anonymous">
<div style="width: 100%; display: flex; justify-content: center; background-color: black; color: wheat;">
    <section data-testid="contentViewer" class="contentViewer--KzjY1"><div class="annotatable--okKet"><div id="book-content"><div class="readerContainer--bZ89H white--bfCci" style="font-size: 1em; max-width: 70ch;"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 14. Event-Driven Architecture Style"><div class="chapter" id="ch-style-eda">
        <h1><span class="label">Chapter 14. </span>Event-Driven Architecture Style</h1>
        
        
        <p>The <em>event-driven</em> architecture style is a popular distributed asynchronous architecture style used to produce highly <a data-type="indexterm" data-primary="event-driven architecture" id="ix_evntar"></a>scalable and high-performance applications. It is also highly adaptable and can be used for small applications and as well as large, complex ones. Event-driven architecture is made up of decoupled event processing components that asynchronously receive and process events. It can be used as a standalone architecture style or embedded within other architecture styles (such as an event-driven microservices architecture).</p>
        
        <p>Most applications follow what is called a <em>request-based</em> model (illustrated in <a data-type="xref" href="#fig-style-eda-request-based">Figure&nbsp;14-1</a>).<a data-type="indexterm" data-primary="request-based model (applications)" id="idm45838971472688"></a> In this model, requests made to the system to perform some sort of action are send to a <em>request orchestrator</em>. <a data-type="indexterm" data-primary="request orchestrator" id="idm45838971471344"></a>The request orchestrator is typically a user interface, but it can also be implemented through an API layer or enterprise service bus. The role of the request orchestrator is to deterministically and synchronously direct the request to various <em>request processors</em>.<a data-type="indexterm" data-primary="request processors" id="idm45838971469840"></a> The request processors handle the request, either retrieving or updating information in a database.</p>
        
        <p>A good example of the request-based model is a request from a customer to retrieve their order history for the past six months. Retrieving order history information is a data-driven, deterministic request made to the system for data within a specific context, not an event happening that the system must react to.</p>
        
        <p>An event-based model, on the other hand, reacts to a particular situation and takes action based on that event. An example of an event-based model is submitting a bid for a particular item within an online auction. Submitting the bid is not a request made to the system, but rather an event that happens after the current asking price is announced. The system must respond to this event by comparing the bid to others received at the same time to determine who is the current highest bidder.</p>
        
        <figure><div id="fig-style-eda-request-based" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1401.png" alt="Request-based Model" width="1403" height="727">
        <h6><span class="label">Figure 14-1. </span>Request-based model</h6>
        </div></figure>
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Topology"><div class="sect1" id="idm45838971465280">
        <h1>Topology</h1>
        
        <p>There are two primary topologies within event-driven architecture: the <em>mediator topology</em> and the <em>broker topology</em>.<a data-type="indexterm" data-primary="event-driven architecture" data-secondary="topology" id="idm45838971462976"></a><a data-type="indexterm" data-primary="broker topology (event-driven architecture)" id="ix_brkrtop"></a><a data-type="indexterm" data-primary="mediator topology (event-driven architecture)" id="idm45838971460912"></a> The mediator topology is commonly used when you require control over the workflow of an event process, whereas the broker topology is used when you require a high degree of responsiveness and dynamic control over the processing of an event. Because the architecture characteristics and implementation strategies differ between these two topologies, it is important to understand each one to know which is best suited for a particular situation.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Broker Topology"><div class="sect1" id="idm45838971459360">
        <h1>Broker Topology</h1>
        
        <p>The broker topology differs from the mediator topology in that there is no central event mediator.<a data-type="indexterm" data-primary="event-driven architecture" data-secondary="topology" data-tertiary="broker topology" id="ix_evntarbrktop"></a> Rather, the message flow is distributed across the event processor components in a chain-like broadcasting fashion through a lightweight message broker (such as RabbitMQ, ActiveMQ, HornetQ, and so on). This topology is useful when you have a relatively simple event processing flow and you do not need central event orchestration and coordination.</p>
        
        <p class="pagebreak-before">There are four primary architecture components within the broker topology: an initiating event, the event broker, an event processor, and a processing event. The <em>initiating event</em> is the initial event<a data-type="indexterm" data-primary="initiating event" id="idm45838971454160"></a> that starts the entire event flow, whether it be a simple event like placing a bid in an online auction or more complex events in a health benefits system like changing a job or getting married. The initiating event is sent to an event channel in the <em>event broker</em> for processing.<a data-type="indexterm" data-primary="event broker" id="idm45838971452768"></a> Since there is no mediator component in the broker topology managing and controlling the event, a single <em>event processor</em> accepts the initiating event from the event broker and begins the processing of that event. <a data-type="indexterm" data-primary="event processor" id="idm45838971451408"></a>The event processor that accepted the initiating event performs a specific task associated with the processing of that event, then asynchronously advertises what it did to the rest of the system by creating what is called a <em>processing event</em>. <a data-type="indexterm" data-primary="processing event" id="idm45838971449984"></a>This processing event is then asynchronously sent to the event broker for further processing, if needed. Other event processors listen to the processing event, react to that event by doing something, then advertise through a new processing event what they did. This process continues until no one is interested in what a final event processor did. <a data-type="xref" href="#fig-style-eda-broker">Figure&nbsp;14-2</a> illustrates this event processing flow.</p>
        
        <p>The event broker component is usually federated (meaning multiple domain-based clustered instances), where each federated broker contains all of the event channels used within the event flow for that particular domain.<a data-type="indexterm" data-primary="federated event broker components" id="idm45838971447392"></a> Because of the decoupled asynchronous fire-and-forget broadcasting nature of the broker topology, topics (or topic exchanges in the case of AMQP) are usually used in the broker topology using a publish-and-subscribe messaging model.<a data-type="indexterm" data-primary="publish/subscribe messaging model in broker toplogy of event-driven architecture" id="idm45838971446288"></a></p>
        
        <figure><div id="fig-style-eda-broker" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1402.png" alt="Broker Topology" width="1439" height="826">
        <h6><span class="label">Figure 14-2. </span>Broker topology</h6>
        </div></figure>
        
        <p>It is always a good practice within the broker topology for each event processor to advertise what it did to the rest of the system, regardless of whether or not any other event processor cares about what that action was. This practice provides architectural extensibility if additional functionality is required for the processing of that event. For example, suppose as part of a complex event process, as illustrated in <a data-type="xref" href="#fig-style-eda-notification">Figure&nbsp;14-3</a>, an email is generated and sent to a customer notifying them of a particular action taken. The <code>Notification</code> event processor would generate and send the email, then advertise that action to the rest of the system through a new processing event sent to a topic. However, in this case, no other event processors are listening for events on that topic, and as such the message simply goes away.</p>
        
        <figure><div id="fig-style-eda-notification" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1403.png" alt="Notification Event Ignored" width="1275" height="701">
        <h6><span class="label">Figure 14-3. </span>Notification event is sent but ignored</h6>
        </div></figure>
        
        <p>This is a good example of <em>architectural extensibility</em>. <a data-type="indexterm" data-primary="architectural extensibility" data-secondary="in broker topology of event-driven architecture" id="idm45838971438064"></a>While it may seem like a waste of resources sending messages that are ignored, it is not. Suppose a new requirement comes along to analyze emails that have been sent to customers. This new event processor can be added to the overall system with minimal effort because the email information is available via the email topic to the new analyzer without having to add any additional infrastructure or apply any changes to other event processors.</p>
        
        <p>To illustrate how the broker topology works, consider the processing flow in a typical retail order entry system, as illustrated in <a data-type="xref" href="#fig-style-eda-broker-example">Figure&nbsp;14-4</a>, where an order is placed for an item (say, a book like this one). <a data-type="indexterm" data-primary="broker topology (event-driven architecture)" data-secondary="example" id="idm45838971434784"></a>In this example, the <code>OrderPlacement</code> event processor receives the initiating event (<code>PlaceOrder</code>), inserts the order in a database table, and returns an order ID to the customer. It then advertises to the rest of the system that it created an order through an <code>order-created</code> processing event. Notice that three event processors are interested in that event: the <code>Notification</code> event processor, the <span class="keep-together"><code>Payment</code></span> event processor, and the <code>Inventory</code> event processor. All three of these event processors perform their tasks in parallel.</p>
        
        <figure><div id="fig-style-eda-broker-example" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1404.png" alt="Broker Example" width="1439" height="1597">
        <h6><span class="label">Figure 14-4. </span>Example of the broker topology</h6>
        </div></figure>
        
        <p>The <code>Notification</code> event processor receives the <code>order-created</code> processing event and emails the customer. It then generates another processing event (<code>email-sent</code>). Notice that no other event processors are listening to that event. This is normal and illustrates the previous example describing architectural extensibility—an in-place hook so that other event processors can eventually tap into that event feed, if needed.</p>
        
        <p class="pagebreak-before">The <code>Inventory</code> event processor also listens for the <code>order-created</code> processing event and decrements the corresponding inventory for that book. It then advertises this action through an <code>inventory-updated</code> processing event, which is in turn picked up by the <code>Warehouse</code> event processor to manage the corresponding inventory between warehouses, reordering items if supplies get too low.</p>
        
        <p>The <code>Payment</code> event processor also receives the <code>order-created</code> processing event and charges the customer’s credit card for the order that was just created. Notice in <a data-type="xref" href="#fig-style-eda-broker-example">Figure&nbsp;14-4</a> that two events are generated as a result of the actions taken by the <span class="keep-together"><code>Payment</code></span> event processor: one to notify the rest of the system that the payment was applied (<code>payment-applied</code>) and one processing event to notify the rest of the system that the payment was denied (<code>payment-denied</code>). Notice that the <code>Notification</code> event processor is interested in the <code>payment-denied</code> processing event, because it must, in turn, send an email to the customer informing them that they must update their credit card information or choose a different payment method.</p>
        
        <p>The <code>OrderFulfillment</code> event processor listens to the <code>payment-applied</code> processing event and does order picking and packing. Once completed, it then advertises to the rest of the system that it fulfilled the order via an <code>order-fulfilled</code> processing event. Notice that both the <code>Notification</code> processing unit and the <code>Shipping</code> processing unit listen to this processing event. Concurrently, the <code>Notification</code> event processor notifies the customer that the order has been fulfilled and is ready for shipment, and at the same time the <code>Shipping</code> event processor selects a shipping method. The <code>Shipping</code> event processor ships the order and sends out an <code>order-shipped</code> processing event, which the <code>Notification</code> event processor also listens for to notify the customer of the order status change.</p>
        
        <p>In analyzing the prior example, notice that all of the event processors are highly decoupled and independent of each other. The best way to understand the broker topology is to think about it as a relay race. In a relay race, runners hold a baton (a wooden stick) and run for a certain distance (say 1.5 kilometers), then hand off the baton to the next runner, and so on down the chain until the last runner crosses the finish line. In relay races, once a runner hands off the baton, that runner is done with the race and moves on to other things. This is also true with the broker topology. Once an event processor hands off the event, it is no longer involved with the processing of that specific event and is available to react to other initiating or processing events. In addition, each event processor can scale independently from one other to handle varying load conditions or backups in the processing within that event. The topics provide the back pressure point if an event processor comes down or slows down due to some environment issue.</p>
        
        <p class="pagebreak-before">While performance, responsiveness, and scalability are all great benefits of the broker topology, there are also some negatives about it.<a data-type="indexterm" data-primary="broker topology (event-driven architecture)" data-secondary="benefits and disadvantages of" id="idm45838971410368"></a> First of all, there is no control over the overall workflow associated with the initiating event (in this case, the <code>PlaceOrder</code> event).<a data-type="indexterm" data-primary="initiating event" data-secondary="lack of control over workflow associated with" id="idm45838971408640"></a> It is very dynamic based on various conditions, and no one in the system really knows when the business transaction of placing an order is actually complete. Error handling is also a big challenge with the broker topology. Because there is no mediator monitoring or controlling the business transaction, if a failure occurs (such as the <code>Payment</code> event processor crashing and not completing its assigned task), no one in the system is aware of that crash. The business process gets stuck and is unable to move without some sort of automated or manual intervention. Furthermore, all other processes are moving along without regard for the error. For example, the <code>Inventory</code> event processor still decrements the inventory, and all other event processors react as though everything is fine.</p>
        
        <p>The ability to restart a business transaction (recoverability) is also something not supported with the broker topology.<a data-type="indexterm" data-primary="transactions" data-secondary="lack of ability to restart in broker toplogy of event-driven architecture" id="idm45838971405456"></a> Because other actions have asynchronously been taken through the initial processing of the initiating event, it is not possible to resubmit the initiating event. No component in the broker topology is aware of the state or even owns the state of the original business request, and therefore no one is responsible in this topology for restarting the business transaction (the initiating event) and knowing where it left off. The advantages and disadvantages of the broker topology are summarized in <a data-type="xref" href="#table-style-eda-broker-tradeoffs">Table&nbsp;14-1</a>.</p>
        <table id="table-style-eda-broker-tradeoffs" style="width: 70%">
        <caption><span class="label">Table 14-1. </span>Trade-offs of the broker topology</caption>
        <thead>
        <tr>
        <th>Advantages</th>
        <th>Disadvantages</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>Highly decoupled event processors</p></td>
        <td><p>Workflow control</p></td>
        </tr>
        <tr>
        <td><p>High scalability</p></td>
        <td><p>Error handling</p></td>
        </tr>
        <tr>
        <td><p>High responsiveness</p></td>
        <td><p>Recoverability</p></td>
        </tr>
        <tr>
        <td><p>High performance</p></td>
        <td><p>Restart capabilities</p></td>
        </tr>
        <tr>
        <td><p>High fault tolerance</p></td>
        <td><p>Data inconsistency</p></td>
        </tr>
        </tbody>
        </table>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Mediator Topology"><div class="sect1" id="idm45838971458768">
        <h1>Mediator Topology</h1>
        
        <p>The mediator topology of event-driven architecture addresses<a data-type="indexterm" data-primary="event-driven architecture" data-secondary="topology" data-tertiary="broker topology" data-startref="ix_evntarbrktop" id="idm45838971388688"></a><a data-type="indexterm" data-primary="broker topology (event-driven architecture)" data-startref="ix_brkrtop" id="idm45838971387152"></a> some of the shortcomings of the broker topology described in the previous section.<a data-type="indexterm" data-primary="event-driven architecture" data-secondary="topology" data-tertiary="mediator topology" id="ix_evntarmedtop"></a><a data-type="indexterm" data-primary="mediator topology (event-driven architecture)" id="ix_medtop"></a> Central to this topology is an event mediator, which manages and controls the workflow for initiating events that require the coordination of multiple event processors.<a data-type="indexterm" data-primary="event mediators" id="idm45838971383248"></a> The architecture components that make up the mediator topology are an initiating event, an event queue, an event mediator, event channels, and event processors.</p>
        
        <p class="pagebreak-before">Like in the broker topology, the initiating event is the event that starts the whole eventing process.<a data-type="indexterm" data-primary="initiating event" id="idm45838971381296"></a> Unlike the broker topology, the initiating event is sent to an initiating event queue, which is accepted by the event mediator. <a data-type="indexterm" data-primary="event queue" id="idm45838971380320"></a>The event mediator only knows the steps involved in processing the event and therefore generates corresponding processing events that are sent to dedicated event channels (usually queues) in a point-to-point messaging fashion.<a data-type="indexterm" data-primary="processing event" id="idm45838971379280"></a><a data-type="indexterm" data-primary="event processor" id="idm45838971378608"></a> Event processors then listen to dedicated event channels, process the event, and usually respond back to the mediator that they have completed their work. Unlike the broker topology, event processors within the mediator topology do not advertise what they did to the rest of the system. The mediator topology is illustrated in <a data-type="xref" href="#fig-style-eda-mediator">Figure&nbsp;14-5</a>.</p>
        
        <figure><div id="fig-style-eda-mediator" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1405.png" alt="Mediator Topology" width="1352" height="685">
        <h6><span class="label">Figure 14-5. </span>Mediator topology</h6>
        </div></figure>
        
        <p>In most implementations of the mediator topology, there are multiple mediators, usually associated with a particular domain or grouping of events. This reduces the single point of failure issue associated with this topology and also increases overall throughput and performance. For example, there might be a customer mediator that handles all customer-related events (such as new customer registration and profile update), and another mediator that handles order-related activities (such as adding an item to a shopping cart and checking out).</p>
        
        <p>The event mediator can <a data-type="indexterm" data-primary="orchestration and choreography" data-secondary="error handling and orchestration in event mediators" id="idm45838971373168"></a>be implemented in a variety of ways, depending on the nature and complexity of the events it is processing.<a data-type="indexterm" data-primary="Apache Camel" id="idm45838971371936"></a> For example, for events requiring simple error handling and orchestration, a mediator such as <a href="https://camel.apache.org">Apache Camel</a>, <a href="https://www.mulesoft.com">Mule ESB</a>, or <a href="https://oreil.ly/r2e4r">Spring Integration</a> will usually suffice.<a data-type="indexterm" data-primary="Mule ESB" id="idm45838971368960"></a><a data-type="indexterm" data-primary="Spring Integration" id="idm45838971368224"></a> Message flows and message routes within these types of mediators are typically custom written in programming code (such as Java or C#) to control the workflow of the event processing.</p>
        
        <p>However, if the event workflow requires lots of conditional processing and multiple dynamic paths with complex error handling <a data-type="indexterm" data-primary="Apache ODE" id="idm45838971366592"></a>directives, then a mediator such as <a href="https://ode.apache.org">Apache ODE</a> or the <a href="https://oreil.ly/jMtta">Oracle BPEL Process Manager</a> would be a good choice.<a data-type="indexterm" data-primary="Oracle BPEL Process Manager" id="idm45838971364384"></a><a data-type="indexterm" data-primary="Business Process Execution Language (BPEL)" id="idm45838971363648"></a> These mediators are based on <a href="https://oreil.ly/Uu-Fo">Business Process Execution Language (BPEL)</a>, an XML-like structure that describes the steps involved in processing an event. BPEL artifacts also contain structured elements used for error handling, redirection, multicasting, and so on. BPEL is a powerful but relatively complex language to learn, and as such is usually created using graphical interface tools provided in the product’s BPEL engine suite.</p>
        
        <p>BPEL is good for complex and dynamic workflows, but it does not work well for those event workflows requiring long-running transactions involving human intervention throughout the event process. For example, suppose a trade is being placed through a <code>place-trade</code> initiating event. The event mediator accepts this event, but during the processing finds that a manual approval is required because the trade is over a certain amount of shares. In this case the event mediator would have to stop the event processing, send a notification to a senior trader for the manual approval, and wait for that approval to occur. In these cases a Business Process Management (BPM) engine such as <a href="https://www.jbpm.org">jBPM</a> would be required.<a data-type="indexterm" data-primary="business process management (BPM) engines" id="idm45838971359712"></a></p>
        
        <p>It is important to know the types of events that will be processed through the mediator in order to make the correct choice for the implementation of the event mediator. Choosing Apache Camel for complex and long-running events involving human interaction would be extremely difficult to write and maintain. By the same token, using a BPM engine for simple event flows would take months of wasted effort when the same thing could be accomplished in Apache Camel in a matter of days.</p>
        
        <p>Given that it’s rare to have all events of one class of complexity, we recommend classifying events as simple, hard, or complex and having every event always go through a simple mediator (such as Apache Camel or Mule). The simple mediator can then interrogate the classification of the event, and based on that classification, handle the event itself or forward it to another, more complex, event mediator. In this manner, all types of events can be effectively processed by the type of mediator needed for that event. This mediator delegation model<a data-type="indexterm" data-primary="event mediators" data-secondary="delegating events to" id="idm45838971357024"></a> is illustrated in <a data-type="xref" href="#fig-style-eda-mediator-delegate">Figure&nbsp;14-6</a>.</p>
        
        <figure><div id="fig-style-eda-mediator-delegate" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1406.png" alt="Mediator Delegation" width="1425" height="1200">
        <h6><span class="label">Figure 14-6. </span>Delegating the event to the appropriate type of event mediator</h6>
        </div></figure>
        
        <p>Notice in <a data-type="xref" href="#fig-style-eda-mediator-delegate">Figure&nbsp;14-6</a> that the <code>Simple Event Mediator</code> generates and sends a processing event when the event workflow is simple and can be handled by the simple mediator. However, notice that when the initiating event coming into the <code>Simple Event Mediator</code> is classified as either hard or complex, it forwards the original initiating event to the corresponding mediators (BPEL or BPM). The <code>Simple Event Mediator</code>, having intercepted the original event, may still be responsible for knowing when that event is complete, or it simply delegates the entire workflow (including client notification) to the other mediators.</p>
        
        <p>To illustrate how the mediator topology works, consider the same retail order entry system example described in the prior broker topology section, but this time using the mediator topology. In this example, the mediator knows the steps required to process this particular event. This event flow (internal to the mediator component) is illustrated in <a data-type="xref" href="#fig-style-eda-mediator-flow">Figure&nbsp;14-7</a>.</p>
        
        <figure><div id="fig-style-eda-mediator-flow" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1407.png" alt="Mediator Flow" width="1132" height="992">
        <h6><span class="label">Figure 14-7. </span>Mediator steps for placing an order</h6>
        </div></figure>
        
        <p>In keeping with the prior example, the same initiating event (<code>PlaceOrder</code>) is sent to the <code>customer-event-queue</code> for processing. The <code>Customer</code> mediator picks up this initiating event and begins generating processing events based on the flow in <a data-type="xref" href="#fig-style-eda-mediator-flow">Figure&nbsp;14-7</a>. Notice that the multiple events shown in steps 2, 3, and 4 are all done concurrently and serially between steps. In other words, step 3 (fulfill order) must be completed and acknowledged before the customer can be notified that the order is ready to be shipped in step 4 (ship order).</p>
        
        <p>Once the initiating event has been received, the <code>Customer</code> mediator generates a <code>create-order</code> processing event and sends this message to the <code>order-placement-queue</code> (see <a data-type="xref" href="#fig-style-eda-mediator-example-1">Figure&nbsp;14-8</a>). The <code>OrderPlacement</code> event processor accepts this event and validates and creates the order, returning to the mediator an acknowledgement along with the order ID. At this point the mediator might send that order ID back to the customer, indicating that the order was placed, or it might have to continue until all the steps are complete (this would be based on specific business rules about order placement).</p>
        
        <figure><div id="fig-style-eda-mediator-example-1" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1408.png" alt="Mediator Example 1" width="1433" height="1603">
        <h6><span class="label">Figure 14-8. </span>Step 1 of the mediator example</h6>
        </div></figure>
        
        <p>Now that step 1 is complete, the mediator now moves to step 2 (see <a data-type="xref" href="#fig-style-eda-mediator-example-2">Figure&nbsp;14-9</a>) and generates three messages at the same time: <code>email-customer</code>, <code>apply-payment</code>, and <code>adjust-inventory</code>. These processing events are all sent to their respective queues. All three event processors receive these messages, perform their respective tasks, and notify the mediator that the processing has been completed. Notice that the mediator must wait until it receives acknowledgement from all three parallel processes before moving on to step 3. At this point, if an error occurs in one of the parallel event processors, the mediator can take corrective action to fix the problem (this is discussed later in this section in more detail).</p>
        
        <figure><div id="fig-style-eda-mediator-example-2" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1409.png" alt="Mediator Example 2" width="1434" height="1603">
        <h6><span class="label">Figure 14-9. </span>Step 2 of the mediator example</h6>
        </div></figure>
        
        <p class="pagebreak-before">Once the mediator gets a successful acknowledgment from all of the event processors in step 2, it can move on to step 3 to fulfill the order (see <a data-type="xref" href="#fig-style-eda-mediator-example-3">Figure&nbsp;14-10</a>). Notice once again that both of these events (<code>fulfill-order</code> and <code>order-stock</code>) can occur simultaneously. The <code>OrderFulfillment</code> and <code>Warehouse</code> event processors accept these events, perform their work, and return an acknowledgement to the mediator.</p>
        
        <figure><div id="fig-style-eda-mediator-example-3" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1410.png" alt="Mediator Example 3" width="1433" height="1603">
        <h6><span class="label">Figure 14-10. </span>Step 3 of the mediator example</h6>
        </div></figure>
        
        <p class="pagebreak-before">Once these events are complete, the mediator then moves on to step 4 (see <a data-type="xref" href="#fig-style-eda-mediator-example-4">Figure&nbsp;14-11</a>) to ship the order. This step generates another <code>email-customer</code> processing event with specific information about what to do (in this case, notify the customer that the order is ready to be shipped), as well as a <code>ship-order</code> event.</p>
        
        <figure><div id="fig-style-eda-mediator-example-4" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1411.png" alt="Mediator Example 4" width="1433" height="1603">
        <h6><span class="label">Figure 14-11. </span>Step 4 of the mediator example</h6>
        </div></figure>
        
        <p>Finally, the mediator moves to step 5 (see <a data-type="xref" href="#fig-style-eda-mediator-example-5">Figure&nbsp;14-12</a>) and generates another contextual <code>email-customer</code> event to notify the customer that the order has been shipped. At this point the workflow is done, and the mediator marks the initiating event flow complete and removes all state associated with the initiating event.</p>
        
        <figure><div id="fig-style-eda-mediator-example-5" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1412.png" alt="Mediator Example 5" width="1434" height="1603">
        <h6><span class="label">Figure 14-12. </span>Step 5 of the mediator example</h6>
        </div></figure>
        
        <p>The mediator component has knowledge and control over the workflow, something the broker topology does not have. Because the mediator controls the workflow, it can maintain event state and manage error handling, recoverability, and restart capabilities. For example, suppose in the prior example the payment was not applied due to the credit card being expired. In this case the mediator receives this error condition, and knowing the order cannot be fulfilled (step 3) until payment is applied, stops the workflow and records the state of the request in its own persistent datastore. Once payment is eventually applied, the workflow can be restarted from where it left off (in this case, the beginning of step 3).</p>
        
        <p>Another inherent difference between the broker and mediator topology is how the processing events differ in terms of their meaning and how they are used. In the broker topology example in the previous section, the processing events were published as events that had occurred in the system (such as <code>order-created</code>, <code>payment-applied</code>, and <code>email-sent</code>). The event processors took some action, and other event processors react to that action. However, in the mediator topology, processing occurrences such as <code>place-order</code>, <code>send-email</code>, and <code>fulfill-order</code> are <em>commands</em> (things that need to happen) as opposed to <em>events</em> (things that have already happened).<a data-type="indexterm" data-primary="events" data-secondary="commands versus in event-driven architecture" id="idm45838971312320"></a> Also, in the mediator topology, a command must be processed, whereas an event can be ignored in the broker topology.</p>
        
        <p>While the mediator topology addresses the issues associated with the broker topology, there are some negatives associated with the mediator topology.<a data-type="indexterm" data-primary="mediator topology (event-driven architecture)" data-secondary="trade-offs" id="idm45838971310576"></a> First of all, it is very difficult to declaratively model the dynamic processing that occurs within a complex event flow. As a result, many workflows within the mediator only handle the general processing, and a hybrid model combining both the mediator and broker topologies is used to address the dynamic nature of complex event processing (such as out-of-stock conditions or other nontypical errors). Furthermore, although the event processors can easily scale in the same manner as the broker topology, the mediator must scale as well, something that occasionally produces a bottleneck in the overall event processing flow. Finally, event processors are not as highly decoupled in the mediator topology as with the broker topology, and performance is not as good due to the mediator controlling the processing of the event. These trade-offs are summarized in <a data-type="xref" href="#table-style-eda-mediator-tradeoffs">Table&nbsp;14-2</a>.</p>
        <table id="table-style-eda-mediator-tradeoffs" style="width: 70%">
        <caption><span class="label">Table 14-2. </span>Trade-offs of the mediator topology</caption>
        <thead>
        <tr>
        <th>Advantages</th>
        <th>Disadvantages</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>Workflow control</p></td>
        <td><p>More coupling of event processors</p></td>
        </tr>
        <tr>
        <td><p>Error handling</p></td>
        <td><p>Lower scalability</p></td>
        </tr>
        <tr>
        <td><p>Recoverability</p></td>
        <td><p>Lower performance</p></td>
        </tr>
        <tr>
        <td><p>Restart capabilities</p></td>
        <td><p>Lower fault tolerance</p></td>
        </tr>
        <tr>
        <td><p>Better data consistency</p></td>
        <td><p>Modeling complex workflows</p></td>
        </tr>
        </tbody>
        </table>
        
        <p>The choice between the broker and mediator topology essentially comes down to a trade-off between workflow control and error handling capability versus high performance and scalability. Although performance and scalability are still good within the mediator topology, they are not as high as with the broker topology.<a data-type="indexterm" data-primary="event-driven architecture" data-secondary="topology" data-tertiary="mediator topology" data-startref="ix_evntarmedtop" id="idm45838971294784"></a><a data-type="indexterm" data-primary="mediator topology (event-driven architecture)" data-startref="ix_medtop" id="idm45838971293248"></a></p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect1" class="pagebreak-before less_space" data-pdf-bookmark="Asynchronous Capabilities"><div class="sect1" id="idm45838971389728">
        <h1>Asynchronous Capabilities</h1>
        
        <p>The event-driven architecture<a data-type="indexterm" data-primary="event-driven architecture" data-secondary="asynchronous capabilities" id="ix_evntarasyn"></a><a data-type="indexterm" data-primary="asynchronous communication" data-secondary="in event-driven architecture" id="ix_asycomEDA"></a> style offers a unique characteristic over other architecture styles in that it relies solely on asynchronous communication for both fire-and-forget processing (no response required) as well as request/reply processing (response required from the event consumer). Asynchronous communication can be a powerful technique for increasing the overall responsiveness of a system.</p>
        
        <p>Consider the example illustrated in <a data-type="xref" href="#fig-style-eda-async">Figure&nbsp;14-13</a> where a user is posting a comment on a website for a particular product review. Assume the comment service in this example takes 3,000 milliseconds to post the comment because it goes through several parsing engines: a bad word checker to check for unacceptable words, a grammar checker to make sure that the sentence structures are not saying something abusive, and finally a context checker to make sure the comment is about a particular product and not just a political rant. Notice in <a data-type="xref" href="#fig-style-eda-async">Figure&nbsp;14-13</a> that the top path utilizes a synchronous RESTful call to post the comment: 50 milliseconds in latency for the service to receive the post, 3,000 milliseconds to post the comment, and 50 milliseconds in network latency to respond back to the user that the comment was posted. This <span class="keep-together">creates</span> a response time for the user of 3,100 milliseconds to post a comment. Now look at the bottom path and notice that with the use of asynchronous messaging, the response time from the end user’s perspective for posting a comment on the website is only 25 milliseconds (as opposed to 3,100 milliseconds). It still takes 3,025 milliseconds to post the comment (25 milliseconds to receive the message and 3,000 milliseconds to post the comment), but from the end user’s perspective it’s already been done.</p>
        
        <figure><div id="fig-style-eda-async" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1413.png" alt="Synchronous versus asynchronous" width="1425" height="728">
        <h6><span class="label">Figure 14-13. </span>Synchronous versus asynchronous communication</h6>
        </div></figure>
        
        <p>This is a good example of the difference between <em>responsiveness</em> and <em>performance</em>. When the user does not need any information back (other than an acknowledgement or a thank you message), why make the user wait? Responsiveness is all about notifying the user that the action has been accepted and will be processed momentarily, whereas performance is about making the end-to-end process faster. Notice that nothing was done to optimize the way the comment service processes the text—in both cases it is still taking 3,000 milliseconds. Addressing <em>performance</em> would have been optimizing the comment service to run all of the text and grammar parsing engines in parallel with the use of caching and other similar techniques. The bottom example in <a data-type="xref" href="#fig-style-eda-async">Figure&nbsp;14-13</a> addresses the overall responsiveness of the system but not the performance of the system.</p>
        
        <p>The difference in response time between the two examples in <a data-type="xref" href="#fig-style-eda-async">Figure&nbsp;14-13</a> from 3,100 milliseconds to 25 milliseconds is staggering. There is one caveat. On the synchronous path shown on the top of the diagram, the end user is guaranteed that the comment has been posted. However, on the bottom path there is only the acknowledgement of the post, with a future promise that eventually the comment will get posted. From the end user’s perspective, the comment has been posted. But what happens if the user had typed a bad word in the comment? In this case the comment would be rejected, but there is no way to get back to the end user. Or is there? In this example, assuming the user is registered with the website (which to post a comment they would have to be), a message could be sent to the user indicating a problem with the comment and some suggestions on how to repair it. This is a simple example. What about a more complicated example where the purchase of some stock is taking place asynchronously (called a stock trade) and there is no way to get back to the user?</p>
        
        <p>The main issue with asynchronous communications is error handling. While responsiveness is significantly improved, it is difficult to address error conditions, adding to the complexity of the event-driven system. The next section addresses this issue with a pattern of reactive architecture called the <em>workflow event</em> pattern.<a data-type="indexterm" data-primary="asynchronous communication" data-secondary="in event-driven architecture" data-startref="ix_asycomEDA" id="idm45838971274928"></a><a data-type="indexterm" data-primary="event-driven architecture" data-secondary="asynchronous capabilities" data-startref="ix_evntarasyn" id="idm45838971273760"></a></p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Error Handling"><div class="sect1" id="idm45838971272384">
        <h1>Error Handling</h1>
        
        <p>The workflow event pattern of reactive architecture is one way of addressing the issues associated with error handling in an asynchronous workflow.<a data-type="indexterm" data-primary="workflows" data-secondary="workflow event pattern" id="ix_wkflevnt"></a><a data-type="indexterm" data-primary="error handling in event-driven architecture" id="ix_errevnt"></a><a data-type="indexterm" data-primary="event-driven architecture" data-secondary="error handling" id="ix_evntarerr"></a> This pattern is a reactive architecture pattern that addresses both resiliency and responsiveness. In other words, the system can be resilient in terms of error handling without an impact to responsiveness.</p>
        
        <p>The workflow event pattern leverages delegation, containment, <a data-type="indexterm" data-primary="workflows" data-secondary="workflow event pattern" data-tertiary="workflow delegate" id="idm45838971265792"></a>and repair through the use of a <em>workflow delegate</em>, as illustrated in <a data-type="xref" href="#fig-style-eda-wep">Figure&nbsp;14-14</a>. The event producer asynchronously passes data through a message channel to the event consumer. If the event consumer experiences an error while processing the data, it immediately delegates that error to the <em>workflow processor</em> and moves on to the next message in the event queue. <a data-type="indexterm" data-primary="workflows" data-secondary="workflow event pattern" data-tertiary="workflow processor" id="idm45838971262480"></a>In this way, overall responsiveness is not impacted because the next message is immediately processed. If the event consumer were to spend the time trying to figure out the error, then it is not reading the next message in the queue, therefore impacting the responsiveness not only of the next message, but all other messages waiting in the queue to be processed.</p>
        
        <p>Once the workflow processor receives an error, it tries to figure out what is wrong with the message. This could be a static, deterministic error, or it could leverage some machine learning algorithms to analyze the message to see some anomaly in the data. Either way, the workflow processor programmatically (without human intervention) makes changes to the original data to try and repair it, and then sends it back to the originating queue. The event consumer sees this message as a new one and tries to process it again, hopefully this time with some success. Of course, there are many times when the workflow processor cannot determine what is wrong with the message. In these cases the workflow processor sends the message off to another queue, which is then received in what is usually called a “dashboard,” an application that looks similar to the Microsoft’s Outlook or Apple’s Mail. This dashboard usually resides on the desktop of a person of importance, who then looks at the message, applies
        manual fixes to it, and then resubmits it to the original queue (usually through a reply-to message header variable).</p>
        
        <figure class="width-75"><div id="fig-style-eda-wep" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1414.png" alt="Workflow Event Pattern" width="1149" height="697">
        <h6><span class="label">Figure 14-14. </span>Workflow event pattern of reactive architecture</h6>
        </div></figure>
        
        <p>To illustrate the workflow event pattern, suppose a trading advisor in one part of the country accepts trade orders (instructions on what stock to buy and for how many shares) on behalf of a large trading firm in another part of the country. The advisor batches up the trade orders (what is usually called a basket) and asynchronously sends those to the large trading firm to be placed with a broker so the stock can be purchased. To simplify the example, suppose the contract for the trade instructions must adhere to the following:</p>
        
        <pre data-type="programlisting" data-code-language="text">ACCOUNT(String),SIDE(String),SYMBOL(String),SHARES(Long)</pre>
        
        <p>Suppose the large trading firm receives the following basket of Apple (AAPL) trade orders from the trading advisor:</p>
        
        <pre data-type="programlisting" data-code-language="text">12654A87FR4,BUY,AAPL,1254
        87R54E3068U,BUY,AAPL,3122
        6R4NB7609JJ,BUY,AAPL,5433
        2WE35HF6DHF,BUY,AAPL,8756 SHARES
        764980974R2,BUY,AAPL,1211
        1533G658HD8,BUY,AAPL,2654</pre>
        
        <p>Notice the forth trade instruction (<code>2WE35HF6DHF,BUY,AAPL,8756 SHARES</code>) has the word <code>SHARES</code> after the number of shares for the trade. When these asynchronous trade orders are processed by the large trading firm without any error handling capabilities, the following error occurs within the trade placement service:</p>
        
        <pre data-type="programlisting" data-code-language="text">Exception in thread "main" java.lang.NumberFormatException:
            For input string: "8756 SHARES"
            at java.lang.NumberFormatException.forInputString
            (NumberFormatException.java:65)
            at java.lang.Long.parseLong(Long.java:589)
            at java.lang.Long.&lt;init&gt;(Long.java:965)
            at trading.TradePlacement.execute(TradePlacement.java:23)
            at trading.TradePlacement.main(TradePlacement.java:29)</pre>
        
        <p>When this exception occurs, there is nothing that the trade placement service can do, because this was an asynchronous request, except to possibly log the error condition. In other words, there is no user to synchronously respond to and fix the error.</p>
        
        <p>Applying the workflow event pattern can programmatically fix this error. Because the large trading firm has no control over the trading advisor and the corresponding trade order data it sends, it must react to fix the error itself (as illustrated in <a data-type="xref" href="#fig-style-eda-wep-example">Figure&nbsp;14-15</a>). When the same error occurs (<code>2WE35HF6DHF,BUY,AAPL,8756 SHARES</code>), the <code>Trade Placement</code> service immediately delegates the error via asynchronous messaging to the <code>Trade Placement Error</code> service for error handling, passing with the error information about the exception:</p>
        
        <pre data-type="programlisting" data-code-language="text">Trade Placed: 12654A87FR4,BUY,AAPL,1254
        Trade Placed: 87R54E3068U,BUY,AAPL,3122
        Trade Placed: 6R4NB7609JJ,BUY,AAPL,5433
        Error Placing Trade: "2WE35HF6DHF,BUY,AAPL,8756 SHARES"
        Sending to trade error processor  &lt;-- delegate the error fixing and move on
        Trade Placed: 764980974R2,BUY,AAPL,1211
        ...</pre>
        
        <p class="pagebreak-before">The <code>Trade Placement Error</code> service (acting as the workflow delegate) receives the error and inspects the exception. Seeing that it is an issue with the word <code>SHARES</code> in the number of shares field, the <code>Trade Placement Error</code> service strips off the word <code>SHARES</code> and resubmits the trade for reprocessing:</p>
        
        <pre data-type="programlisting" data-code-language="text">Received Trade Order Error: 2WE35HF6DHF,BUY,AAPL,8756 SHARES
        Trade fixed: 2WE35HF6DHF,BUY,AAPL,8756
        Resubmitting Trade For Re-Processing</pre>
        
        <p>The fixed trade is then processed successfully by the trade placement service:</p>
        
        <pre data-type="programlisting" data-code-language="text">...
        trade placed: 1533G658HD8,BUY,AAPL,2654
        trade placed: 2WE35HF6DHF,BUY,AAPL,8756 &lt;-- this was the original trade in error</pre>
        
        <figure><div id="fig-style-eda-wep-example" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1415.png" alt="Workflow Event Pattern Example" width="1313" height="772">
        <h6><span class="label">Figure 14-15. </span>Error handling with the workflow event pattern</h6>
        </div></figure>
        
        <p>One of the consequences of the workflow event pattern is that messages in error are processed out of sequence when they are resubmitted. In our trading example, the order of messages matters, because all trades within a given account must be processed in order (for example, a SELL for IBM must occur before a BUY for AAPL within the same brokerage account). Although not impossible, it is a complex task to maintain message order within a given context (in this case the brokerage account number). One way this can be addressed is by the <code>Trade Placement</code> service queueing and storing the account number of the trade in error. Any trade with that same account number would be stored in a temporary queue for later processing (in FIFO order). Once the trade originally in error is fixed and processed, the <code>Trade Placement</code> service then de-queues the remaining trades for that same account and processes them in order.<a data-type="indexterm" data-primary="workflows" data-secondary="workflow event pattern" data-startref="ix_wkflevnt" id="idm45838980659424"></a><a data-type="indexterm" data-primary="error handling in event-driven architecture" data-startref="ix_errevnt" id="idm45838980967744"></a><a data-type="indexterm" data-primary="event-driven architecture" data-secondary="error handling" data-startref="ix_evntarerr" id="idm45838980966768"></a></p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Preventing Data Loss"><div class="sect1" id="sec-data-loss">
        <h1>Preventing Data Loss</h1>
        
        <p>Data loss is always a primary concern when dealing with asynchronous communications.<a data-type="indexterm" data-primary="event-driven architecture" data-secondary="preventing data loss" id="ix_evntprdl"></a><a data-type="indexterm" data-primary="data" data-secondary="preventing data loss in event-driven architecture" id="ix_dataloss"></a> Unfortunately, there are many places for data loss to occur within an event-driven architecture. By data loss we mean a message getting dropped or never making it to its final destination. Fortunately, there are basic out-of-the-box techniques that can be leveraged to prevent data loss when using asynchronous messaging.</p>
        
        <p>To illustrate the issues associated with data loss within event-driven architecture, suppose <code>Event</code> <code>Processor</code> <code>A</code> asynchronously sends a message to a queue. <code>Event</code> <span class="keep-together"><code>Processor</code></span> <code>B</code> accepts the message and inserts the data within the message into a database. As illustrated in <a data-type="xref" href="#fig-style-eda-data-loss-issue">Figure&nbsp;14-16</a>, three areas of data loss can occur within this typical scenario:</p>
        <ol>
        <li>
        <p>The message never makes it to the queue from <code>Event</code> <code>Processor</code> <code>A</code>; or even if it does, the broker goes down before the next event processor can retrieve the <span class="keep-together">message.</span></p>
        </li>
        <li>
        <p><code>Event</code> <code>Processor</code> <code>B</code> de-queues the next available message and crashes before it can process the event.</p>
        </li>
        <li>
        <p><code>Event</code> <code>Processor</code> <code>B</code> is unable to persist the message to the database due to some data error.</p>
        </li>
        
        </ol>
        
        <figure><div id="fig-style-eda-data-loss-issue" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1416.png" alt="Data Loss Issue" width="1435" height="333">
        <h6><span class="label">Figure 14-16. </span>Where data loss can happen within an event-driven architecture</h6>
        </div></figure>
        
        <p>Each of these areas of data loss can be mitigated through basic messaging techniques. Issue 1 (the message never makes it to the queue) is easily solved by leveraging persistent message queues, along with something called <em>synchronous send</em>. <a data-type="indexterm" data-primary="synchronous comunication" data-secondary="synchronous send in event-driven architecture" id="idm45838971252544"></a>Persisted message queues support what is known as guaranteed delivery. When the message broker receives the message, it not only stores it in memory for fast retrieval, but also persists the message in some sort of physical data store (such as a filesystem or database). If the message broker goes down, the message is physically stored on disk so that when the message broker comes back up, the message is available for processing. Synchronous send does a blocking wait in the message producer until the broker has acknowledged that the message has been persisted. With these two basic techniques there is no way to lose a message between the event producer and the queue because the message is either still with the message producer or persisted within the queue.</p>
        
        <p>Issue 2 (<code>Event</code> <code>Processor</code> <code>B</code> de-queues the next available message and crashes before it can process the event) can also be solved using a basic technique of messaging called <em>client acknowledge mode</em>. <a data-type="indexterm" data-primary="client acknowledge mode" id="idm45838971232912"></a><a data-type="indexterm" data-primary="auto acknowledge mode" id="idm45838971232176"></a>By default, when a message is de-queued, it is immediately removed from the queue (something called <em>auto acknowledge</em> mode). Client acknowledge mode keeps the message in the queue and attaches the client ID to the message so that no other consumers can read the message. With this mode, if <code>Event</code> <code>Processor</code> <code>B</code> crashes, the message is still preserved in the queue, preventing message loss in this part of the message flow.</p>
        
        <p>Issue 3 (<code>Event</code> <code>Processor</code> <code>B</code> is unable to persist the message to the database due to some data error) is addressed through leveraging ACID (atomicity, consistency, isolation, durability) transactions via a database commit. Once the database commit happens, the data is guaranteed to be persisted in the database. <a data-type="indexterm" data-primary="last participant support (LPS)" id="idm45838971246912"></a>Leveraging something called <em>last participant support</em> (LPS) removes the message from the persisted queue by acknowledging that processing has been completed and that the message has been persisted. This guarantees the message is not lost during the transit from <code>Event</code> <span class="keep-together"><code>Processor</code></span> <code>A</code> all the way to the database. These techniques are illustrated in <a data-type="xref" href="#fig-style-eda-data-loss-prevent">Figure&nbsp;14-17</a>.</p>
        
        <figure><div id="fig-style-eda-data-loss-prevent" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1417.png" alt="Preventing Data Loss" width="1427" height="507">
        <h6><span class="label">Figure 14-17. </span>Preventing data loss within an event-driven architecture</h6>
        </div></figure>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect1" class="pagebreak-before less_space" data-pdf-bookmark="Broadcast Capabilities"><div class="sect1" id="idm45838978508464">
        <h1>Broadcast Capabilities</h1>
        
        <p>One of the other unique characteristics of event-driven architecture is the capability<a data-type="indexterm" data-primary="data" data-secondary="preventing data loss in event-driven architecture" data-startref="ix_dataloss" id="idm45838972122368"></a><a data-type="indexterm" data-primary="event-driven architecture" data-secondary="preventing data loss" data-startref="ix_evntprdl" id="idm45838972121120"></a> to broadcast events without knowledge of who (if anyone) is receiving the message and what they do with it.<a data-type="indexterm" data-primary="event-driven architecture" data-secondary="broadcast capabilities" id="idm45838972119632"></a><a data-type="indexterm" data-primary="broadcast capabilities in event-driven architecture" id="idm45838972118672"></a> This technique, which is illustrated in <a data-type="xref" href="#fig-style-eda-broadcast">Figure&nbsp;14-18</a>, shows that when a producer publishes a message, that same message is received by multiple subscribers.</p>
        
        <figure><div id="fig-style-eda-broadcast" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1418.png" alt="Broadcast Messaging" width="1253" height="999">
        <h6><span class="label">Figure 14-18. </span>Broadcasting events to other event processors</h6>
        </div></figure>
        
        <p>Broadcasting is perhaps the highest level of decoupling between event processors because the producer of the broadcast message usually does not know which event processors will be receiving the broadcast message and more importantly, what they will do with the message. Broadcast capabilities are an essential part of patterns for eventual consistency, complex event processing (CEP), and a host of other situations. Consider frequent changes in stock prices for instruments traded on the stock market. Every ticker (the current price of a particular stock) might influence a number of things. However, the service publishing the latest price simply broadcasts it with no knowledge of how that information will be used.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Request-Reply"><div class="sect1" id="idm45838971144352">
        <h1>Request-Reply</h1>
        
        <p>So far in this chapter we’ve dealt with asynchronous requests that don’t need an immediate response from the event consumer.<a data-type="indexterm" data-primary="event-driven architecture" data-secondary="request-reply messaging" id="idm45838971142640"></a><a data-type="indexterm" data-primary="request-reply messaging in event-driven architecture" id="idm45838971141792"></a> But what if an order ID is needed when ordering a book? What if a confirmation number is needed when booking a flight? These are examples of communication between services or event processors that require some sort of synchronous communication.</p>
        
        <p>In event-driven architecture, synchronous communication is accomplished through <em>request-reply</em> messaging (sometimes referred to as <em>pseudosynchronous communications</em>). <a data-type="indexterm" data-primary="pseudosynchronous communications" id="idm45838971139648"></a>Each event channel within request-reply messaging consists of two queues: a request queue and a reply queue. The initial request for information is asynchronously sent to the request queue, and then control is returned to the message producer. The message producer then does a blocking wait on the reply queue, waiting for the response. The message consumer receives and processes the message and then sends the response to the reply queue. The event producer then receives the message with the response data. This basic flow is illustrated in <a data-type="xref" href="#fig-style-eda-rr">Figure&nbsp;14-19</a>.</p>
        
        <figure><div id="fig-style-eda-rr" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1419.png" alt="Request-Reply" width="1031" height="642">
        <h6><span class="label">Figure 14-19. </span>Request-reply message processing</h6>
        </div></figure>
        
        <p>There are two primary techniques for implementing request-reply messaging. The first (and most common) technique is to use a <em>correlation ID</em> contained in the message header.<a data-type="indexterm" data-primary="correlation ID" id="idm45838971134560"></a> A correlation ID is a field in the reply message that is usually set to the message ID of the original request message. This technique, as illustrated in <a data-type="xref" href="#fig-style-eda-correlation">Figure&nbsp;14-20</a>, works as follows, with the message ID indicated with ID, and the correlation ID indicated with CID:</p>
        <ol>
        <li>
        <p>The event producer sends a message to the request queue and records the unique message ID (in this case ID 124). Notice that the correlation ID (CID) in this case is <code>null</code>.</p>
        </li>
        <li>
        <p>The event producer now does a blocking wait on the reply queue with a message filter (also called a message selector), where the correlation ID in the message header equals the original message ID (in this case 124). Notice there are two messages in the reply queue: message ID 855 with correlation ID 120, and message ID 856 with correlation ID 122. Neither of these messages will be picked up because the correlation ID does not match what the event consumer is looking for (CID 124).</p>
        </li>
        <li>
        <p>The event consumer receives the message (ID 124) and processes the request.</p>
        </li>
        <li>
        <p>The event consumer creates the reply message containing the response and sets the correlation ID (CID) in the message header to the original message ID (124).</p>
        </li>
        <li>
        <p>The event consumer sends the new message (ID 857) to the reply queue.</p>
        </li>
        <li>
        <p>The event producer receives the message because the correlation ID (124) matches the message selector from step 2.</p>
        </li>
        
        </ol>
        
        <figure><div id="fig-style-eda-correlation" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1420.png" alt="Correlation Id" width="1401" height="794">
        <h6><span class="label">Figure 14-20. </span>Request-reply message processing using a correlation ID</h6>
        </div></figure>
        
        <p>The other technique used to implement request-reply messaging is to use a <em>temporary queue</em> for the reply queue.<a data-type="indexterm" data-primary="temporary queues" id="idm45838971122496"></a> A temporary queue is dedicated to the specific request, created when the request is made and deleted when the request ends. This technique, as illustrated in <a data-type="xref" href="#fig-style-eda-temp-queue">Figure&nbsp;14-21</a>, does not require a correlation ID because the temporary queue is a dedicated queue only known to the event producer for the specific request. The temporary queue technique works as follows:</p>
        <ol>
        <li>
        <p>The event producer creates a temporary queue (or one is automatically created, depending on the message broker) and sends a message to the request queue, passing the name of the temporary queue in the reply-to header (or some other agreed-upon custom attribute in the message header).</p>
        </li>
        <li>
        <p>The event producer does a blocking wait on the temporary reply queue. No message selector is needed because any message sent to this queue belongs solely to the event producer that originally sent to the message.</p>
        </li>
        <li>
        <p>The event consumer receives the message, processes the request, and sends a response message to the reply queue named in the reply-to header.</p>
        </li>
        <li>
        <p>The event processor receives the message and deletes the temporary queue.</p>
        </li>
        
        </ol>
        
        <figure><div id="fig-style-eda-temp-queue" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1421.png" alt="Temporary Queues" width="1401" height="640">
        <h6><span class="label">Figure 14-21. </span>Request-reply message processing using a temporary queue</h6>
        </div></figure>
        
        <p>While the temporary queue technique is much simpler, the message broker must create a temporary queue for each request made and then delete it immediately afterward. Large messaging volumes can significantly slow down the message broker and impact overall performance and responsiveness. For this reason we usually recommend using the correlation ID technique.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Choosing Between Request-Based and Event-Based"><div class="sect1" id="idm45838971143760">
        <h1>Choosing Between Request-Based and Event-Based</h1>
        
        <p>The request-based model and event-based model are both viable approaches for designing software systems.<a data-type="indexterm" data-primary="request-based model (applications)" data-secondary="choosing between event-based and" id="idm45838971111616"></a><a data-type="indexterm" data-primary="event-driven architecture" data-secondary="choosing between request-based and event-based model" id="idm45838971110608"></a> However, choosing the right model is essential to the overall success of the system. We recommend choosing the request-based model for well-structured, data-driven requests (such as retrieving customer profile data) when certainty and control over the workflow is needed. We recommend choosing the event-based model for flexible, action-based events that require high levels of responsiveness and scale, with complex and dynamic user processing.</p>
        
        <p>Understanding the trade-offs with the event-based model also helps decide which one is the best fit. <a data-type="xref" href="#table-style-eda-tradeoffs">Table&nbsp;14-3</a> lists the advantages and disadvantages of the event-based model of event-driven architecture.</p>
        <table id="table-style-eda-tradeoffs" style="width: 100%">
        <caption><span class="label">Table 14-3. </span>Trade-offs of the event-driven model</caption>
        <thead>
        <tr>
        <th>Advantages over request-based</th>
        <th>Trade-offs</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>Better response to dynamic user content</p></td>
        <td><p>Only supports eventual consistency</p></td>
        </tr>
        <tr>
        <td><p>Better scalability and elasticity</p></td>
        <td><p>Less control over processing flow</p></td>
        </tr>
        <tr>
        <td><p>Better agility and change management</p></td>
        <td><p>Less certainty over outcome of event flow</p></td>
        </tr>
        <tr>
        <td><p>Better adaptability and extensibility</p></td>
        <td><p>Difficult to test and debug</p></td>
        </tr>
        <tr>
        <td><p>Better responsiveness and performance</p></td>
        <td></td>
        </tr>
        <tr>
        <td><p>Better real-time decision making</p></td>
        <td></td>
        </tr>
        <tr>
        <td><p>Better reaction to situational awareness</p></td>
        <td></td>
        </tr>
        </tbody>
        </table>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Hybrid Event-Driven Architectures"><div class="sect1" id="idm45838971092512">
        <h1>Hybrid Event-Driven Architectures</h1>
        
        <p>While many applications leverage the event-driven architecture style as the primary overarching architecture, in many cases event-driven architecture is used in conjunction with other architecture styles, forming what is known as a hybrid architecture. Some common architecture styles that leverage event-driven architecture as part of another architecture style include microservices and space-based architecture. Other hybrids that are possible include an event-driven microkernel architecture and an event-driven pipeline architecture.</p>
        
        <p>Adding event-driven architecture to any architecture style helps remove bottlenecks, provides a back pressure point in the event requests get backed up, and provides a level of user responsiveness not found in other architecture styles. Both microservices and space-based architecture leverage messaging for data pumps, asynchronously sending data to another processor that in turn updates data in a database. Both also leverage event-driven architecture to provide a level of programmatic scalability to services in a microservices architecture and processing units in a space-based architecture when using messaging for interservice communication.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Architecture Characteristics Ratings"><div class="sect1" id="idm45838971089312">
        <h1>Architecture Characteristics Ratings</h1>
        
        <p>A one-star rating in the characteristics ratings table in <a data-type="xref" href="#fig-style-eda-ratings">Figure&nbsp;14-22</a> means the specific<a data-type="indexterm" data-primary="event-driven architecture" data-secondary="architecture characteristics ratings" id="ix_evntararch"></a><a data-type="indexterm" data-primary="architecture characteristics" data-secondary="ratings in event-driven architecture" id="ix_archevnt"></a> architecture characteristic isn’t well supported in the architecture, whereas a five-star rating means the architecture characteristic is one of the strongest features in the architecture style. The definition for each characteristic identified in the scorecard can be found in <a data-type="xref" href="ch04.html#ch-architecture-characteristics-defined">Chapter&nbsp;4</a>.</p>
        
        <p>Event-driven architecture is primarily a technically <a data-type="indexterm" data-primary="technical partitioning (components)" data-secondary="in event-driven architecture" id="idm45838971082560"></a>partitioned architecture in that any particular domain is spread across multiple event processors and tied together through mediators, queues, and topics. Changes to a particular domain usually impact many event processors, mediators, and other messaging artifacts, hence why event-driven architecture is not domain partitioned.</p>
        
        <figure class="width-75"><div id="fig-style-eda-ratings" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_1422.png" alt="Event-Driven Ratings" width="1240" height="1401">
        <h6><span class="label">Figure 14-22. </span>Event-driven architecture characteristics ratings</h6>
        </div></figure>
        
        <p>The number of quanta within event-driven architecture can vary from one to many quanta, which is usually based on the database interactions within each event <span class="keep-together">processor</span> and request-reply processing.<a data-type="indexterm" data-primary="architecture quantum" data-secondary="architecture quanta in event-driven architecture" id="idm45838971077520"></a> Even though all communication in an event-driven architecture is asynchronous, if multiple event processors share a single database instance, they would all be contained within the same architectural quantum. The same is true for request-reply processing: even though the communication is still asynchronous between the event processors, if a request is needed right away from the event consumer, it ties those event processors together synchronously; hence they belong to the same quantum.</p>
        
        <p>To illustrate this point, consider the example where one event processor sends a request to another event processor to place an order. The first event processor must wait for an order ID from the other event processor to continue. If the second event processor that places the order and generates an order ID is down, the first event processor cannot continue. Therefore, they are part of the same architecture quantum and share the same architectural characteristics, even though they are both sending and receiving asynchronous messages.</p>
        
        <p>Event-driven architecture gains five stars for performance, scalability, and fault tolerance, the primary strengths of this architecture style.<a data-type="indexterm" data-primary="performance" data-secondary="rating in event-driven architecture" id="idm45838971074288"></a><a data-type="indexterm" data-primary="fault tolerance" data-secondary="rating in event-driven architecture" id="idm45838971073248"></a> High performance is achieved through asynchronous communications combined with highly parallel processing. <a data-type="indexterm" data-primary="scalability" data-secondary="rating in event-driven architecture" id="idm45838971072032"></a>High scalability is realized through the programmatic load balancing of event processors (also called <em>competing consumers</em>). <a data-type="indexterm" data-primary="competing consumers" id="idm45838971070448"></a>As the request load increases, additional event processors can be programmatically added to handle the additional requests. Fault tolerance is achieved through highly decoupled and asynchronous event processors that provide eventual consistency and eventual processing of event workflows. Providing the user interface or an event processor making a request does not need an immediate response, promises and futures can be leveraged to process the event at a later time if other downstream processors are not available.</p>
        
        <p>Overall <em>simplicity</em> and <em>testability</em> rate relatively low with event-driven architecture, mostly due to the nondeterministic and dynamic event flows typically found within this architecture style.<a data-type="indexterm" data-primary="testability" data-secondary="rating in event-driven architecture" id="idm45838971067600"></a><a data-type="indexterm" data-primary="simplicity" data-secondary="in event-driven architecture" id="idm45838971066608"></a> While deterministic flows within the request-based model are relatively easy to test because the paths and outcomes are generally known, such is not the case with the event-driven model. Sometimes it is not known how event processors will react to dynamic events, and what messages they might produce. These “event tree diagrams” can be extremely complex, generating hundreds to even thousands of scenarios, making it very difficult to govern and test.</p>
        
        <p>Finally, event-driven architectures are highly evolutionary, hence the five-star rating.<a data-type="indexterm" data-primary="evolutionary architectures" data-secondary="event-driven architecture" id="idm45838971064544"></a> Adding new features through existing or new event processors is relatively straightforward, particularly in the broker topology. By providing hooks via published messages in the broker topology, the data is already made available, hence no changes are required in the infrastructure or existing event processors to add that new <span class="keep-together">functionality.</span><a data-type="indexterm" data-primary="event-driven architecture" data-secondary="architecture characteristics ratings" data-startref="ix_evntararch" id="idm45838971062528"></a><a data-type="indexterm" data-primary="architecture characteristics" data-secondary="ratings in event-based architecture" data-startref="ix_archevnt" id="idm45838971061248"></a><a data-type="indexterm" data-primary="event-driven architecture" data-startref="ix_evntar" id="idm45838971060000"></a></p>
        </div></section>
        
        
        
        
        
        
        
        </div></section></div></div><link rel="stylesheet" href="/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="/api/v2/epubs/urn:orm:book:9781492043447/files/epub.css" crossorigin="anonymous"><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/mml-svg.js"></script></div></div></section>
</div>

https://learning.oreilly.com