<style>
    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 300;
        src: url(https://static.contineljs.com/fonts/Roboto-Light.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Light.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 400;
        src: url(https://static.contineljs.com/fonts/Roboto-Regular.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Regular.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 500;
        src: url(https://static.contineljs.com/fonts/Roboto-Medium.woff2?v=2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Medium.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 700;
        src: url(https://static.contineljs.com/fonts/Roboto-Bold.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Bold.woff) format("woff");
    }

    * {
        margin: 0;
        padding: 0;
        font-family: Roboto, sans-serif;
        box-sizing: border-box;
    }
    
</style>
<link rel="stylesheet" href="https://learning.oreilly.com/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492092506/files/epub.css" crossorigin="anonymous">
<div style="width: 100%; display: flex; justify-content: center; background-color: black; color: wheat;">
    <section data-testid="contentViewer" class="contentViewer--KzjY1"><div class="annotatable--okKet"><div id="book-content"><div class="readerContainer--bZ89H white--bfCci" style="font-size: 1em; max-width: 70ch;"><div id="sbo-rt-content"><h2 class="h2" id="ch17"><a id="page_463"></a><strong>Chapter 17<br>Policy in the Control Plane</strong></h2>
        <div class="sidebar">
        <p class="sb-noindent"><strong>Learning Objectives</strong></p>
        <p class="sb-noindent">After reading this chapter, you should understand:</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> How to define control plane policy</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Hot and cold potato routing as examples of control plane policy</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> How to create virtual topologies as a policy implementation mechanism</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Basic traffic engineering concepts, such as flow pinning</p>
        </div>
        <p class="noindent">The last several chapters have considered the many variations on finding a set of loop-free paths through a network. In the explanation of the Border Gateway Protocol (BGP), however, you might have noticed the emphasis on various policies, rather than strictly finding loop-free paths. This chapter, then, will continue the emphasis on policy begun in the preceding chapter.</p>
        <p class="indent">The first question to answer is: what is policy? Unfortunately, there is no simple answer. The best way to answer this question is through examples; these will be considered in the following section. The second section of this chapter will draw lessons from these examples, and then consider problems and solutions in the control plane policy space.</p>
        <div class="note">
        <p class="title"><a id="page_464"></a><strong>Note</strong></p>
        <p class="notepara">Control policy is often difficult to separate conceptually from data plane policy, such as packet filtering and Quality of Service (QoS). In fact, the two overlap in many places, such as the control plane carrying QoS markings that are then applied to packets, or drawing packets into a null interface, effectively dropping them. These sorts of corner cases are avoided here for clarity.</p>
        </div>
        <div class="heading">
        <h3 class="h3" id="ch17lev1">Control Plane Policy Use Cases</h3>
        <p class="noindent">Often the best way to understand a concept is through examples. This section examines three examples of policy being used in the control plane to fulfill business requirements: determining where traffic should exit a provider network, optimizing application performance by pinning elephant flows, and increasing or providing security through network segmentation. The next section draws a set of lessons from these examples.</p>
        </div>
        <div class="heading">
        <h4 class="h4" id="ch17lev2"><strong>Routing and Potatoes</strong></h4>
        <p class="noindent">Service providers normally live within a world of tight budgets, application requirements, and business drivers. The mixture of these three can make for some strange situations when routing between providers of various kinds. Specifically, cold potato routing is designed to keep traffic inside the provider’s network for as long as possible, while hot potato routing is designed to push traffic to the closest exit point possible. The result of mixing these two is sometimes called (tongue in cheek) mashed potato routing. <a href="ch17.xhtml#ch17fig01">Figure 17-1</a> is used to explain.</p>
        </div>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/17fig01.jpg" aria-describedby="Al17fig01" alt="Network diagram representing mashed potato routing." width="611" height="318"><aside class="hidden" id="Al17fig01">
        <p>In the diagram, AS65000 is an edge provider network with a host A. AS650001 is an upstream provider network with 5 routers, and AS650003 is another upstream provider network. AS65004 is shown to be a transit provider network. AS65002 is a content provider with 3 routers and an authoritative server K. AS65000 and AS65003 are connected through link B. AS65000 and AS65003 are connected to AS65001 through links C and D respectively. AS65003 and AS65004 are connected through link E, and AS65004 is connected to AS65002 through link G. Lastly, AS65002 is connected to AS65001 through link H.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch17fig01"></a><strong>Figure 17-1</strong> <em>Routing and Potatoes</em></p>
        </div>
        <p class="indent"><a id="page_465"></a>Assume AS65000 is an edge provider, or perhaps an “enterprise” network connected to two upstream providers, AS65001 and AS65003. AS65001, AS65003, and AS65004 are transit providers, and AS65002 is a content provider. Some of the policies and business drivers for those policies in this collection of networks might be</p>
        <p class="bullt">• AS65001 wants to draw as much traffic from AS65000, across link C, as possible. The more this link is filled up, the more likely AS65000 is to purchase an upgraded link. There is actually little AS65001 can do to attract traffic, of course, other than perhaps trying to convince the administrators in AS65000 to ship more traffic their direction, or trying to improve the performance of the link from the perspective of some sort of traffic engineering system AS65000 might have configured on their end of the link.</p>
        <p class="bull">• AS65001 wants to forward any traffic entering at link C to the closest exit with a route to the destination. For instance, if AS65003 is advertising a route to K, on the right side of the diagram, AS65001 will prefer the exit through link D, even though it might not be the shortest overall path to the destination. Normally, AS65001 would implement this sort of policy using BGP’s local preference, or by relying on the underlying Interior Gateway Protocol (IGP) metric to draw traffic to the closest exit point out of the Autonomous System (AS). This is called hot potato routing. Why does AS65001 want to push the traffic to the nearest exit point with a route to the destination? Because carrying the traffic along the path to link H, for instance, consumes network resources. AS65001 is being paid based on the usage of link C, rather than for actually carrying the traffic as close as possible to the destination. Hence, AS65001 will draw as much traffic as possible off its paying customers but then push the traffic to the nearest exit point.</p>
        <p class="bull">• AS65002, on the other hand, generally wants to control its user’s experience as tightly as possible, because it is selling a service. If the network between the service and the user has poor quality, then the service itself is perceived to be poor quality, and the content provider’s overall business will suffer. The longer the traffic stays in AS65002’s network, the more control the content provider has over the Quality of Service delivery. Keeping the customer’s traffic inside the network is essentially bringing the customer’s eyeballs closer to the service itself. This is a form of cold potato routing. Instead of tossing the traffic out of your network as quickly as possible (as you would with a hot potato), you hold on to the traffic as long as possible (like a cold potato). In this case, AS65002 is going to perceive the closest exit point to the customer as being through AS65001 at link H because the path through H has the shortest AS path. Although the internal path is longer, AS65002 will choose the path through link H to control the traffic as long as possible.</p>
        <p class="bullb"><a id="page_466"></a>• When traffic is received at link H, AS65001 needs to decide whether to send the traffic to some nearby exit point, say link F, or to carry the traffic along the entire network so it exits at link C. In this case, AS65001 will almost always decide to carry the traffic along its entire network. Again, the primary selling point AS65001 has toward AS65000 is to increase the average utilization along link C. To do this, AS65001 needs traffic to send toward AS65000; the only way to get this traffic is to carry traffic from every entry point into the network to the connection to the customer, if the destination is a customer. This is again cold potato routing.</p>
        <p class="indent">Forwarding traffic over the fewest number of links (and therefore through the fewest number of network devices) would consume the smallest amount of resources, but cold and hot potato routing both choose some longer-length path in order to satisfy a policy constraint. This trades the efficient use of resources for the efficient operation of a protocol or service in order to increase revenue. Other policies may be applicable to routing systems, as well, such as choosing the path with the highest bandwidth, or the path that takes traffic to the geographic exit point closest to the user. Whatever the policy, it will generally represent a tradeoff between one kind of optimization over some other kind of optimization, and require additional state of some sort to implement.</p>
        <div class="heading">
        <h4 class="h4" id="ch17lev3"><strong>Resource Segmentation</strong></h4>
        <p class="noindent">Many times networks are logically divided to control access to specific resources. The network shown in <a href="ch17.xhtml#ch17fig02">Figure 17-2</a> will be used to illustrate.</p>
        </div>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/17fig02.jpg" aria-describedby="Al17fig02" alt="Network Diagrams illustrate the concept of Resource Segmentation." width="615" height="810"><aside class="hidden" id="Al17fig02">
        <p>The diagram is split into three to represent three different networks: A, B, and C. Network A: Two hosts A and B are connected to two routers C and D respectively. C is connected to router K at the other end through routers E and F. D is connected to router G. G and K are connected to each other. And, router K is connected to server L while router G is connected to server H. Network B: The path from host B to server L, through routers D, G, and K is shown prominently, while the rest is faded out. Network C: the path from host A to the server H through routers C, E, F, K, and G is shown prominently while the rest is faded out.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch17fig02"></a><strong>Figure 17-2</strong> <em>Overlays as a Form of Segmentation</em></p>
        </div>
        <p class="indent"><a href="ch17.xhtml#ch17fig02">Figure 17-2</a> shows three different networks:</p>
        <p class="bullt">• Network A shows the base (routed) topology.</p>
        <p class="bull">• Network B shows one set of devices and links that must be connected to one another.</p>
        <p class="bullb">• Network C shows a second set of devices and links that must be connected to one another.</p>
        <p class="indent">In <a href="ch17.xhtml#ch17fig02">Figure 17-2</a>, host B must only be able to connect to server L, and host A must only be able to connect to H. It is simple enough to provide this kind of segmentation through simple packet filters configured at G and K, of course, but further requirements may rule out using simple packet filters. For instance:</p>
        <p class="bullt">• There may be a requirement for traffic passing between A and H to use the path [C,E,F,K,G]; this mixes a traffic engineering requirement with a service access requirement.</p>
        <p class="bullb"><a id="page_467"></a>• There may be a requirement for servers H and L to not even be able to <em>see</em> routes and other information from the other topology. This might be very difficult if the two servers are participating in the routed control plane, as might be the case if they are hosting many virtual machines (VMs), each of which needs to advertise its own IP address into the control plane.</p>
        <p class="indent">When you reach this level of requirement, a common solution is to create an overlay network, often using tunnels to do the heavy lifting of separating the network <a id="page_468"></a>into several virtual topologies. In <a href="ch17.xhtml#ch17fig02">Figure 17-2</a>, these requirements are met with an overlay. In network B, a tunnel would be built starting at the inbound interface of D facing host B (the tunnel headend). This tunnel would be carried across G and K, finally terminating on the interface on K that connects to L (the tunnel tailend). To draw traffic from B to L, there must be some routed control plane to pull traffic into the tunnel headend so it is routed across the tunnel toward L. In network C, a tunnel would be built starting at the inbound interface of C, facing A. The tunnel is carried across C, E, F, K, and G, and terminates at the outbound interface at G facing H. Again, there must be some control plane to draw data across this tunnel, so traffic sourced from A is pulled into the tunnel at C and is presented to G as a “raw IP packet” (without the tunnel headers) so that G can switch the packet to H.</p>
        <p class="indent">The routing information that draws traffic through these two tunnels may actually be carried in a separate control plane. In this case, the underlay control plane will provide reachability to the tunnel endpoints, while the overlay control plane will draw traffic through the tunnel. This separation of control planes allows the different topologies, the underlay and the overlay, to be completely separated; reachability and topology information is not shared between these two control planes.</p>
        <p class="indent">The same is true of the traffic being drawn through the network; the two flows are separated by being tunneled. Not only is the traffic being separated by tunneling, but the path of the flow is also being engineered through the network. Tunneling, and the fuller concept of an overlay, is useful in meeting a lot of different policy requirements; this is why overlays are so widely used in network engineering.</p>
        <div class="heading">
        <h4 class="h4" id="ch17lev4"><strong>Flow Pinning for Application Optimization</strong></h4>
        <p class="noindent">Elephant flows and mouse flows are two classes of flows that engineers often encounter. An elephant flow is typically a large, persistent data flow. Any flow taking up more than around 20% of the available bandwidth of a single link and persisting for more than two or three minutes might, for instance, be classified as an elephant flow. Mouse flows, on the other hand, are much lower bandwidth, say less than 1% of the available bandwidth on any link, and tend to last for very short periods of time. Most flows of traffic can be divided into elephant and mouse flows. <em>What should be done about elephant and mouse flows?</em></p>
        </div>
        <p class="indent">One solution is to interleave the packets from each flow, which allows each flow fair access to the available bandwidth. While Quality of Service (QoS) is one solution, another solution is to pin particular traffic flows to particular paths, or path pinning. <a href="ch17.xhtml#ch17fig03">Figure 17-3</a> is used to explain further.</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/17fig03.jpg" aria-describedby="Al17fig03" alt="Network diagram illustrates the concept of Elephant flow pinning in a network." width="596" height="195"><aside class="hidden" id="Al17fig03">
        <p>Hosts A and B are connected to a router C. C is in turn connected to routers D and E. E is connected to router G at the other end of the diagram which is in turn connected to server H. Router D is connected to the server H through routers F and G.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch17fig03"></a><strong>Figure 17-3</strong> <em>Pinning an Elephant Flow in a Network</em></p>
        </div>
        <p class="indent">In <a href="ch17.xhtml#ch17fig03">Figure 17-3</a>, A begins a flow that will last several hours, and consumes 20% of the available bandwidth on a link (assume all links are the same bandwidth, 100Mbps), and terminates at H. At about the same moment, B sends a series of <a id="page_469"></a>short-term small flows terminating at H. Given just one path will be chosen as the best between C and G, both flows will follow the same path, say along the path [C,E,G]. Mixing the two flows in this way can cause both to suffer from a performance perspective. To understand the problem, it is best to consider the rate at which packets can be serialized onto the wire:</p>
        <p class="bullt">• <strong>64-byte packet onto a 100Mbps link:</strong> .05ms</p>
        <p class="bull">• <strong>1,500-byte packet onto a 100Mbps link:</strong> .12ms</p>
        <p class="bullb">• <strong>9,000-byte packet onto a 100Mbps link:</strong> .72ms</p>
        <p class="indent">Assume the entire network is capable of 9,000-byte packet sizes (the Maximum Transmission Unit, or MTU is 9,000 bytes end to end), and the elephant flow is actually shipping 9,000-byte packets. For the mouse flow, assume the packet size is 64-byte packets (at least in one direction). If a single mouse flow packet is trapped behind a single elephant flow packet, the mouse flow packet will be held for .72ms before it can be serialized onto the physical interface. If there is always one packet from each flow alternating, there can be some significant performance reduction, but both applications would likely still work well enough.</p>
        <p class="indent">But what happens if the interleaving between the two flows is less than optimal? For instance, what if there is a series something like the sequence of packets shown in <a href="ch17.xhtml#ch17fig04">Figure 17-4</a>?</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/17fig04.jpg" aria-describedby="Al17fig04" alt="Diagram represents a mixture of packets of Elephant and Mouse flows." width="566" height="171"><aside class="hidden" id="Al17fig04">
        <p>The diagram has totally 7 Elephant flows and 4 Mouse flows. An elephant flow is represented by a wide rectangle, while a mouse flow is represented by a narrow rectangle. The flow is as follows: Elephant, Elephant, Mouse, Mouse, Mouse, Elephant, Elephant, Elephant, Elephant, Mouse, Elephant.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch17fig04"></a><strong>Figure 17-4</strong> <em>A Problematic Mixture of Packets from Elephant and Mouse Flows</em></p>
        </div>
        <p class="indent"><a id="page_470"></a>The difference between the shortest and longest spacing between mouse flow packets is .05ms and .288ms. The difference between the shortest and longest spacing between elephant flow packets is .05ms and .15ms. These variations might seem to be minimal, but even minimal variations show up as jitter end to end. This kind of jitter, particularly on a larger scale, is problematic for flow control and error correction. In this case, even though the elephant flow is overwhelmingly larger than the mouse flow, both are still negatively impacted. This same sort of problem is common in data center fabrics, as well. <a href="ch17.xhtml#ch17fig05">Figure 17-5</a> illustrates.</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/17fig05.jpg" aria-describedby="Al17fig05" alt="Diagrammatic representation of Traffic Engineering in a Data Center Fabric." width="581" height="512"><aside class="hidden" id="Al17fig05">
        <p>The network has a three-tier architecture, from top to bottom the layers are Leaf 2, Spine, and Leaf 1. Each layer has a set of 6 routers. The routers are connected through the layers to form a mesh topology. Host A is at the bottom left, server G is at the top middle, and server H is at the top right. A few of the routers from the three layers are labeled for easy identification of the paths. The leftmost router in the layer Leaf 1 is labeled B and the leftmost router in the layer Spine is labeled C. The third router from the left in the layer Spine is labeled D. The third router from the left in the layer Leaf 2 is labeled E. The rightmost router in the layer Leaf 2 is labeled F. The Path A, B, C, E is marked with bold lines. Similarly, the path A, B, D, F is marked with bold lines.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch17fig05"></a><strong>Figure 17-5</strong> <em>Traffic Engineering in a Data Center Fabric</em></p>
        </div>
        <p class="indent">In <a href="ch17.xhtml#ch17fig05">Figure 17-5</a>, A has two flows: an elephant flow to G and a set of mouse flows to H. While there is plenty of bandwidth to support both flows across the fabric, if both flows happen to be hashed onto the [B,C] link by the equal cost multipath (ECMP) algorithm, the interaction of the two flows can cause jitter for the supported applications, reducing performance.</p>
        <p class="indent">Pinning the elephant flow to the [B,C] link and keeping other traffic off this link so that the traffic to F follows the [A,B,D,F,H] path can resolve these performance problems. Elephant flows tend to be more common in the data center environment.</p>
        <p class="indent"><a id="page_471"></a>How can the problems caused by mixing two different kinds of traffic on a single link be prevented? One obvious way in a two-connected network, such as the ones illustrated in <a href="ch17.xhtml#ch17fig03">Figure 17-3</a> and <a href="ch17.xhtml#ch17fig05">Figure 17-5</a>, is to somehow pin one of the flows onto one path and remove the other flows from the link the elephant flow is pinned to. For instance:</p>
        <p class="bullt">• In <a href="ch17.xhtml#ch17fig03">Figure 17-3</a>, if one of the two flows is pinned to the longer [C,D,F,G] link, while leaving the other flow on the shorter [C,E,G] link.</p>
        <p class="bullb">• In <a href="ch17.xhtml#ch17fig05">Figure 17-5</a>, if the elephant flow is pinned to one path, say [B,C,E], and the mouse flows can be somehow directed to avoid [B,C,E] so they use some other path, say [B,D,F].</p>
        <p class="indent">Not only must the elephant flow be pinned to a particular path, but the mouse flows must be prevented from flowing along the path the elephant flow has been pinned to. Sometimes just allowing one flow to follow the shortest loop-free path while pinning the other flow to some longer (but still loop-free) path will be sufficient. This does not, however, often work in data center fabrics and other networks where the available paths across which the traffic must be engineered are equal cost. Pinning the elephant flow to one path is not useful if the mouse flows can still be placed on the same path as the elephant flow through the operation of a router randomly choosing among a set of equal cost paths.</p>
        <p class="indent">To separate the two flows in the example in <a href="ch17.xhtml#ch17fig03">Figure 17-3</a>, there must be some way to differentiate the flows during the switching process. There are a number of ways to differentiate the flows, including</p>
        <p class="bullt">• <strong>The destination address.</strong> In <a href="ch17.xhtml#ch17fig03">Figure 17-3</a>, both flows are destined to H, so the destination address would not be useful for differentiating between the two flows. This is not always the case.</p>
        <p class="bull">• <strong>The source address.</strong> In <a href="ch17.xhtml#ch17fig03">Figure 17-3</a>, the source of the first flow is A, and the source of the second is B. The source address could be used in this situation to differentiate between the flows at C. However, because hosts normally send packets (or open sessions) with a number of servers in a network, the source and destination addresses are normally used together, rather than just the source address.</p>
        <p class="bullb">• <strong>The port number.</strong> Port numbers and protocol numbers are normally associated with a single application on a host or a server. The source and destination port numbers can often be combined to pick out traffic from a specific flow, rather than one or the other.</p>
        <p class="indent"><a id="page_472"></a>These differentiators can be combined into a set of markers uniquely identifying every flow in a network running the Internet Protocol (IP) suite, the five tuple. The five tuple consists of</p>
        <p class="bullt">• The source IP address</p>
        <p class="bull">• The destination IP address</p>
        <p class="bull">• The protocol number</p>
        <p class="bull">• The source port number</p>
        <p class="bullb">• The destination port number</p>
        <p class="indent">Because of the way each protocol operates, either the source or destination port will be an ephemeral port, or a port assigned to this specific host. There are alternative ways for traffic to be identified other than examining the various fields that identify a flow. For instance, host A could be configured to mark all the packets in an elephant flow with a particular number in an IPv6 extension header, or with specific QoS bits. In this case, C could simply check for the specified information in the IP header, determining which link traffic should be switched to based on the contents of the correct field.</p>
        <p class="indent">Given the traffic flows can be differentiated from one another, what techniques are available to draw (or push) the traffic in each flow along a different link? Several methods are often used.</p>
        <p class="indent">A statically configured packet filter, sometimes called a policy route, or a filter-based forwarding rule, can be configured at C and G in <a href="ch17.xhtml#ch17fig03">Figure 17-3</a>. This rule would contain logic that <em>matches</em> on the fields differentiating the flows and <em>sets</em> the correct next hop. This solution (obviously) requires manual configuration; this configuration must be managed over time, including adjusting where the packet filter is applied, what traffic is matched by the filter, and where the matching traffic is forwarded. This kind of filter can seem simple when first deployed, but can become difficult to maintain over time. For instance, in <a href="ch17.xhtml#ch17fig03">Figure 17-3</a>, examining the traffic pattern at F would give you no clues about why one of the flows was traveling over the longer path. You would need to trace the traffic back to C to discover why this traffic is passing along this particular path. Because of the additional management and maintenance issues, automated solutions are often preferred.</p>
        <p class="indent">Metric manipulation can sometimes be used to draw each flow along a different path. In <a href="ch17.xhtml#ch17fig03">Figure 17-3</a>, if H is sending traffic to A and B, the path through [C,D,F,G] could be manipulated to have a lower cost toward A, while the path through [C,E,G] could be manipulated to have a lower cost toward B. One problem with this solution <a id="page_473"></a>is obvious from the example. Consider the situation from the perspective of A and B; these two hosts are, in fact, sending both the elephant and the mouse flows to the same destination, so there is no way to use metrics to draw traffic from these two hosts along the two available paths. A second problem with this solution is similar to the one described previously with a packet filter. If you examine the routing table at F, there would be no obvious reason why the metrics for the two different destinations are different. Again, you would need to trace back the difference in metrics to some configuration on either C or G to discover why two destinations that appear to be on either end of the same set of links have two different metrics.</p>
        <p class="indent">The packets in one flow may be tunneled through the network, or drawn into a virtual overlay topology. A tunnel would more likely be used to solve an elephant flow problem than a virtual overlay topology in most networks; a tunnel can be directed along a single path, but a virtual overlay topology is likely to have many paths that traffic could take, so the flow isn’t pinned to a specific path.</p>
        <div class="heading">
        <h3 class="h3" id="ch17lev5">Defining Control Plane Policy</h3>
        <p class="noindent">The three use cases (or examples) given in the previous section are examples of traffic engineering, which simply means manipulating the control plane to specify the path that specific flows take through the network. The first point to observe in these examples is for every case, some traffic is removed from the shortest—and hence presumably the most efficient—path through the network and somehow made to follow a longer loop-free path. This common element is helpful in defining policy:</p>
        </div>
        <p class="blockquote"><strong>Control plane policy is anything that causes traffic to flow over a path longer than the shortest path in order to provide some form of optimization.</strong></p>
        <p class="indent">One specific term needs to be considered further in this definition: what, precisely, does optimization mean? While there are many possible optimizations, they can be broken down into four broad categories:</p>
        <p class="bullt">• <strong>Network utilization:</strong> Operators sometimes try to optimize the utilization of a single link, such as a highly utilized path between two data centers. Network utilization can also be optimized in a more global way, such as the average utilization of every link in the network, or perhaps the available switching capacity across devices and links versus the capacity required to support specific business goals and/or applications.</p>
        <p class="bull"><a id="page_474"></a>• <strong>Application support:</strong> Applications and data are often the “real” heart of a business. No matter what kind of work a business claims to do, it actually works with information to connect buyers to sellers in some way, a process requiring data and data processing (or data analytics). A network can be optimized to support specific applications representing the primary business drivers by ensuring this set of applications always has reachability or reduced jitter and delay.</p>
        <p class="bull">• <strong>Business advantage:</strong> The network can be optimized to increase the financial advantage of the business in some way. Specifically, reducing the cost the business pays to other companies to operate or increasing revenue by increasing user engagement or opening up new markets by connecting to new geographical locations might be ways in which the network can create opportunities to improve the business.</p>
        <p class="bullb">• <strong>Cost:</strong> How can the business build and maintain a less expensive network? This is not just a common question; it is often <em>the only</em> question the business that relies on the network cares about.</p>
        <p class="indent">Any particular network will rarely be optimized for a single class among these four. Most networks will be optimized for all four of these in various parts of their topology or even at various times. Optimizations will often cross over these categories; for instance, improving support for a specific application may increase business advantage by allowing information to be applied to a specific area of the business more quickly, while also saving costs by reducing the application’s downtime.</p>
        <div class="heading">
        <h3 class="h3" id="ch17lev6">Control Plane Policy and Complexity</h3>
        <p class="noindent">Control plane policy is not exempt from the “choose two of three”—state, surface, and optimization—complexity tradeoff described in <a href="ch01.xhtml#ch01">Chapter 1</a>, “<a href="ch01.xhtml#ch01">Fundamental Concepts</a>.” What are the tradeoffs involved in the examples given in the first part of this chapter? Each use case will be covered in the sections that follow.</p>
        </div>
        <div class="heading">
        <h4 class="h4" id="ch17lev7"><strong>Routing and Potatoes</strong></h4>
        <p class="noindent">In the first use case, various policy mechanisms are used to manage where traffic exits an AS and, to some degree, where traffic enters an AS. It is easy to overlook the complexity impacts of the attributes carried in BGP, as they are actually a <em>part</em> of BGP. How can simply using something built into the protocol have an impact from a complexity perspective?</p>
        </div>
        <p class="indent"><em>First</em>, the protocol itself must be more complex in order to support the attributes being carried, and implementations build, test, and maintain the code required to <a id="page_475"></a>process these attributes. This might seem very minor, but consider the case of BGP update packing. <a href="ch17.xhtml#ch17fig06">Figure 17-6</a> illustrates two sets of BGP packets.</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/17fig06.jpg" aria-describedby="Al17fig06" alt="Figure illustrates the concept of BGP update packing." width="805" height="242"><aside class="hidden" id="Al17fig06">
        <p>There are two pairs of packets labeled A and B. For the pair of packets under A, the local preference path attribute for both packets is 100, while the route prefix for one packet is 2001:Db8:3e8:100::/64 and the other is 2001:Db8:3e8:101::/64, making the reachable destination for one packet as 100 and the second one as 101. These two packets are shown to be combined into a single packet and are shown to use a common local preference path attribute: 100. For the pair of packets under B, the local preference path attribute for the first packet is 100 and the second packet is 101, while the route prefix for one packet is 2001:Db8:3e8:100::/64 and the other is 2001:Db8:3e8:101::/64, also making the reachable destination different, for one packet as 100 and the second one as 101. These two packets are labeled "cannot be packed" and are transmitted as two separate packets, with respect to their respective local preference path attribute.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch17fig06"></a><strong>Figure 17-6</strong> <em>Complexity and BGP Policies</em></p>
        </div>
        <p class="indent">The upper pair of packets in <a href="ch17.xhtml#ch17fig06">Figure 17-6</a>, labeled A, is two different destinations carried in BGP format; there is a set of attributes (in this example only one attribute is shown, the LOCAL_PREF) and a reachable prefix. While the reachable destination is different in the two packets, the LOCAL_PREF, or rather the set of attributes, is the same. Hence, when actually advertising these to destinations, BGP can <strong>pack</strong> the two prefixes into a single update. To do this, the two prefixes are simply combined into a single update with the single set of attributes.</p>
        <p class="indent">The lower pair of packets in <a href="ch17.xhtml#ch17fig06">Figure 17-6</a>, labeled B, is two different destinations carried in the BGP format. In this case, the reachable destinations and the attributes are different, so they cannot be combined into a single BGP update.</p>
        <p class="indent">Packing updates, as shown with packet A, represents a major space saving when transmitting reachability information through a network in BGP. While the savings will vary between networks, it is not surprising for efficient packing to reduce initial convergence time and the number of packets sent by somewhere around 80%.</p>
        <p class="indent">The goal of adding the policy information was to improve the utilization of the network, or rather to move traffic to maximize revenue and minimize expenses. The decision to add per route essentially trades state for optimization. More state is injected into the control plane, both in terms of terms of the actual amount of state and the efficiency of carrying the state across the network, so the state versus optimization tradeoff holds true.</p>
        <p class="indent">What about interaction surfaces? There are two places where this solution interacts with other systems in the network. First, the policy marker needs to be set on the correct routes, and associated with some action someplace else in the network. Largely, these settings are going to be made by a pair of human hands adding the right configuration commands to instruct BGP to set and react to these route markers. The interaction surface between people and the network is often the most <a id="page_476"></a>difficult surface to manage. In the case of the multiple exit, or multiexit, discriminator (MED) and communities sent outside the AS, there is an interaction surface with the neighboring autonomous systems.</p>
        <p class="indent">Routing policy, in this case, definitely fits within the State/Optimization/Surface (SOS) model; increasing network utilization requires an increase in state and surfaces.</p>
        <div class="heading">
        <h4 class="h4" id="ch17lev8"><strong>Resource Segmentation</strong></h4>
        <p class="noindent">In resource segmentation, it would seem that by splitting the reachability and topology state out of the underlay topology, the amount of state in the underlay topology has been reduced, and hence the overall complexity has been reduced. At the same time, the network appears to be more closely aligned with the business requirements, so it looks like optimization has increased while state has decreased. This seems to go against the complexity model; if the network is becoming more optimized, state should be increasing.</p>
        </div>
        <p class="indent">Welcome to the world of abstraction; this is one of those cases where you must consider things more closely to really understand the impact on complexity. Remember: <em>if you have not found the tradeoffs, you have not looked hard enough.</em> What is happening here is that there are now three different control planes with less information about the overall topology; the total state in the system has increased, as there are three pieces of state about a subset of the links (one for the underlying physical topology and one for each overlay virtual topology). There is definitely a larger amount of state; it is just more “spread around.”</p>
        <p class="indent">Further, there are now three control planes running in the network; there is definitely an interaction surface to consider between the protocols, even if the protocols do not carry the same reachability information over the same links. <a href="ch17.xhtml#ch17fig07">Figure 17-7</a> illustrates.</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/17fig07.jpg" aria-describedby="Al17fig07" alt="Network Diagram represents the Multiple Overlay surfaces in a single topology." width="615" height="235"><aside class="hidden" id="Al17fig07">
        <p>Two hosts A and B are connected to two routers C and D respectively. C is connected to router K at the other end of the diagram through routers E and F. D is connected to router G. G and K are connected to each other. And, router K is connected to server L while router G is connected to server H. The path from router A to server H: A, C, E, F, K, G, H has a dashed line accompanying its original link. The path from router B to server L: B, D, G, K, L has a dotted line accompanying its original link.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch17fig07"></a><strong>Figure 17-7</strong> <em>Interaction Surfaces between Multiple Overlay Control Planes</em></p>
        </div>
        <p class="indent"><a href="ch17.xhtml#ch17fig07">Figure 17-7</a> represents the same network topology shown in <a href="ch17.xhtml#ch17fig02">Figure 17-2</a>, with the virtual overlay topologies collapsed into a single diagram. The physical topology is <a id="page_477"></a>represented by the solid gray lines; the first overlay is represented by the black dashed line; and the second overlay is represented by the black lines with intermixed dots and dashes. When the physical and overlay topologies are illustrated in this way, it is easy to see the single [G,K] link is shared across all three topologies. If the [G,K] link fails, both of the overlay topologies will also fail; this is called fate sharing. The set of links shared between more than one topology is called the Shared Risk Link Group (SRLG).</p>
        <p class="indent">These three control planes may not initially appear to interact with one another. They do, however, interact at the [G,K] link. Even if there is no actual link failure, any failure in the underlay control plane will cause both of the virtual topologies to fail to be able to forward traffic between their respective sources and destinations. There is an interaction between the three control planes even though they do not redistribute information between themselves.</p>
        <p class="indent">What is perhaps worse, however, is that in a two-connected network such as the one shown in <a href="ch17.xhtml#ch17fig07">Figure 17-7</a>, there should always be two paths between any two points in the network. A single link failure should not cause H to become unreachable from A. Because the virtual topology [C,E,F,K,G] is not two connected, however, the network has been converted to a design where a single link failure at the physical layer can cause both virtual topologies to become disconnected.</p>
        <p class="indent">This sort of shared fate interaction surface is often easy to miss when designing a network with overlays. The abstraction removes details, making it easier to “see” each topology separately, and reducing the state contained in each control plane, but it also hides failure risks and modes that did not exist before virtualization was deployed.</p>
        <p class="indent">Often the only way to solve this type of problem is to add state back into the three control planes. For instance, in the network in <a href="ch17.xhtml#ch17fig07">Figure 17-7</a>, there are a number of ways state could be added back into the network to provide alternate paths in the case of the [G,K] link failure. For instance:</p>
        <p class="bullt">• Some outside process could calculate the topologies and then reach across the layers to find SRLGs, or fate sharing points in the network. In this case, yet another control needs to “ride on top” to at least alert the designer about the SRLGs, so the network design can be modified to work around them. This solution adds (in effect) a fourth control plane that must interact with the other three, including any state carried in the fourth control plane.</p>
        <p class="bull">• The two virtual topologies could be configured to overlay the entire physical topology, and some form of metric weights be placed on the link costs for each overlay topology so traffic passes along the correct path. This adds the state of carrying the entire control plane back to both topologies and potentially adds more points at which the multiple control planes will interact. Further, the overlay link metrics must be computed, configured, and managed.</p>
        <p class="bullb"><a id="page_478"></a>• Secondary virtual overlays could be designed and deployed on the network so each topology has a prebuilt backup topology. Multiprotocol Label Switching (MPLS) Traffic Engineering (TE) Fast Reroute (FRR) provides this type of solution. To deploy this kind of solution, additional state for the backup path and switching state at the tunnel headend to quickly switch to the backup path must be added; the additional potential interaction surfaces between the operators and the network, the various control planes now running in the network, and even the various switching paths available at each device, all add complexity back into the network.</p>
        <p class="indent">There is, in the end, no such thing as a free lunch. Network segmentation is often an effective way to provide separation between customers and workloads—it is often the only way to go, given application and security requirements—but there will always be added complexity someplace in such a design.</p>
        <div class="heading">
        <h4 class="h4" id="ch17lev9"><strong>Flow Pinning for Applications</strong></h4>
        <p class="noindent">What are the gains, from a complexity perspective, in the flow pinning example? The primary point of flow pinning is, of course, to optimize the performance of both the elephant and mouse flow applications. The network may also operate more efficiently, at least from a switching perspective, and QoS settings may well be simpler with the two kinds of flows separated. So there is an increase in optimization, and potentially a decrease in state and interaction surfaces (due to the simpler QoS configurations and processing).</p>
        </div>
        <p class="indent">To get these improvements, there must be a corresponding increase in complexity someplace else. In this case, the increase in complexity is in control plane state. The elephant flow must somehow be pinned to a specific link, and the mouse flows must somehow be removed from the link to which the elephant flow has been pinned. There must also be some “backup plan” in case the path to which the elephant flow is pinned fails.</p>
        <div class="heading">
        <h3 class="h3" id="ch17lev10">Final Thoughts on Control Plane Policy</h3>
        <p class="noindent">Control plane policy is often hiding in plain sight in the form of segmentation, flow pinning, traffic engineering, and other forms. Generally, it will take the form of directing traffic away from the shortest path, and onto a path that might appear less than optimal from a lowest metric or hop count perspective, but is more optimal in some other way, such as application support. In fact, this is as good of a definition of control plane policy as any other:</p>
        </div>
        <p class="blockquote"><strong>Control plane policy</strong> is any modification to the path that packets take through a network off the shortest path in order to implement some specific business or application requirement.</p>
        <p class="indent"><a id="page_479"></a>There is one more form of control plane policy not considered here: the aggregation and summarization of control plane information in order to reduce state and divide (or create) failure domains.</p>
        <p class="indent">Using the control plane to implement policy presents network engineers with a set of tradeoffs. Distributed control planes, as considered in the previous chapters in this book, often become very complex when they are tasked with discovering topology, providing reachability information, and carrying policy. The next chapter explores some alternative ways to solve these problems by centralizing all or part of the functions of the control plane.</p>
        <div class="heading">
        <h3 class="h3" id="ch17lev11">Further Reading</h3>
        <p class="noindentb">These sources consider a number of other interesting and useful control plane policies not discussed in this chapter and provide more information on the policies that were discussed.</p>
        </div>
        <p class="ref">Agarwal, Sharad, A. Nucci, and Supratik Bhattacharyya. “Measuring the Shared Fate of IGP Engineering and Interdomain Traffic.” In <em>13th IEEE International Conference on Network Protocols (ICNP’05)</em>, 10, 2005. doi:10.1109/ICNP.2005.22.</p>
        <p class="ref">Casado, Martin, and Justin Pettit. “Of Mice and Elephants.” <em>Network Heresy</em>, November 1, 2013. <a href="https://networkheresy.com/2013/11/01/of-mice-and-elephants/">https://networkheresy.com/2013/11/01/of-mice-and-elephants/</a>.</p>
        <p class="ref">Das, V. V. “Honeypot Scheme for Distributed Denial-of-Service,” 497–501, 2009. doi:10.1109/ICACC.2009.146.</p>
        <p class="ref">Hinrichs, Tim, and Scott Lowe. “On Policy in the Data Center: The Policy Problem.” <em>Network Heresy</em>, April 22, 2014. <a href="https://networkheresy.com/2014/04/22/on-policy-in-the-data-center-the-policy-problem/">https://networkheresy.com/2014/04/22/on-policy-in-the-data-center-the-policy-problem/</a>.</p>
        <p class="ref">Justin Pettit, Kanna Rajagopal, and J. R. Rivers. “Elephant Detection in the vSwitch with Performance Handling in the Underlay.” <em>Network Heresy</em>, May 16, 2014. <a href="https://networkheresy.com/2014/05/16/elephant-detection-in-the-vswitch-with-performance-handling-in-the-underlay/">https://networkheresy.com/2014/05/16/elephant-detection-in-the-vswitch-with-performance-handling-in-the-underlay/</a>.</p>
        <p class="ref">Karp, Brad Nelson. “Geographic Routing for Wireless Networks.” Harvard University, 2000. <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.115.5738&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.115.5738&amp;rep=rep1&amp;type=pdf</a>.</p>
        <p class="ref">Kaur, Harminder, Harsukhpreet Singh, and Anurag Sharma. “Geographic Routing Protocol: A Review.” <em>International Journal of Grid and Distributed Computing</em> 9, no. 2 (2016): 254.</p>
        <p class="ref">McPherson, Danny R., and Keyur Patel. <em>Experience with the BGP-4 Protocol</em>. Request for Comments 4277. RFC Editor, 2006. <a href="https://rfc-editor.org/rfc/rfc4277.txt">https://rfc-editor.org/rfc/rfc4277.txt</a>.</p>
        <p class="ref"><a id="page_480"></a>Psounis, K., A. Ghosh, B. Prabhakar, and G. Wang. “SIFT: A Simple Algorithm for Tracking Elephant Flows, and Taking Advantage of Power Laws.” In <em>Proceedings of the 43rd Allerton Conference on Communication, Control and Computing</em>, 2005. <a href="https://web.stanford.edu/~balaji/papers/05sifta.pdf">https://web.stanford.edu/~balaji/papers/05sifta.pdf</a>.</p>
        <p class="ref">Teixeira, Renata. “Hot Potatoes Heat Up BGP Routing.” Presented at the RIPE, Amsterdam, October 2005. <a href="https://meetings.ripe.net/ripe-51/presentations/pdf/ripe51-hot-potatoes.pdf">https://meetings.ripe.net/ripe-51/presentations/pdf/ripe51-hot-potatoes.pdf</a>.</p>
        <p class="ref">Weiler, Nathalie. “Honeypots for Distributed Denial of Service Attacks.” IEEE, 2002. <a href="http://www.csl.mtu.edu/cs6461/www/Reading/Weiler02.pdf">http://www.csl.mtu.edu/cs6461/www/Reading/Weiler02.pdf</a>.</p>
        <p class="ref">White, Russ. “Elephant Flows, Fabrics, and I2RS.” <em>Rule 11 Reader</em>, October 3, 2016. <a href="http://rule11.tech/i2rs-elephant-flows/">http://rule11.tech/i2rs-elephant-flows/</a>.</p>
        <div class="heading">
        <h3 class="h3" id="ch17lev12">Review Questions</h3>
        <p class="indenthangingN">1. The chapter mentions four broad classes of optimizations that operators may optimize a network for. Think through the use case examples given in the chapter, and explain which of these four classes of optimization each one could fit into and why. Find three other use cases (need to find sources) and explain which of the four classes of optimization each of them could fit into and why. Are there use cases that do not fit into one of these four broad categories? What category would you add to cover all the use cases?</p>
        </div>
        <p class="indenthangingN">2. Besides hot and cold potato routing, there is also “mashed potato routing.” What is the definition of mashed potato routing, and what is it used for?</p>
        <p class="indenthangingN">3. Elephant and mouse flows are described in the chapter as being large, persistent flows, and short-duration small-volume flows. Name three applications that would generate each kind of flow.</p>
        <p class="indenthangingN">4. In <a href="ch17.xhtml#ch17fig03">Figure 17-3</a>, packet classification must be configured at both C and G to support differentiating traffic flowing between A and H. Why would these need to be configured in both places? Would the filters be the same? If not, how would they be different?</p>
        </div></div><link rel="stylesheet" href="/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="/api/v2/epubs/urn:orm:book:9780134762814/files/9780134762852.css" crossorigin="anonymous"></div></div></section>
</div>

https://learning.oreilly.com