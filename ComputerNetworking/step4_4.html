<style>
    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 300;
        src: url(https://static.contineljs.com/fonts/Roboto-Light.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Light.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 400;
        src: url(https://static.contineljs.com/fonts/Roboto-Regular.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Regular.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 500;
        src: url(https://static.contineljs.com/fonts/Roboto-Medium.woff2?v=2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Medium.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 700;
        src: url(https://static.contineljs.com/fonts/Roboto-Bold.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Bold.woff) format("woff");
    }

    * {
        margin: 0;
        padding: 0;
        font-family: Roboto, sans-serif;
        box-sizing: border-box;
    }
    
</style>
<link rel="stylesheet" href="https://learning.oreilly.com/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492092506/files/epub.css" crossorigin="anonymous">
<div style="width: 100%; display: flex; justify-content: center; background-color: black; color: wheat;">
    <section data-testid="contentViewer" class="contentViewer--KzjY1"><div class="annotatable--okKet"><div id="book-content"><div class="readerContainer--bZ89H white--bfCci" style="font-size: 1em; max-width: 70ch;"><div id="sbo-rt-content"><h2 class="h2" id="ch28"><a id="page_723"></a><strong>Chapter 28<br>Cloud Computing Concepts and Challenges</strong></h2>
        <div class="sidebar">
        <p class="sb-noindent"><strong>Learning Objectives</strong></p>
        <p class="sb-noindent">After reading this chapter, you should understand:</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Some common cloud service offering models, such as software and platform as a service</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Some common reasons businesses choose to move their processing to public cloud services</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Some common tradeoffs to moving processing to public cloud services</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Some common technical challenges involved in moving processing to cloud services</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> The concept of data gravity</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Common elements of cloud security</p>
        </div>
        <p class="noindent">While the term <em>cloud</em> has come to mean many different things, it will be defined here as <em>virtualized products or infrastructure consumed via self-service</em>. In the cloud model, the consumer uses a portal or Application Programming Interface (API) to requisition a service, platform, or server, specifying requirements during the request. The request is fulfilled by software automatically, so the consumer can use the requested service immediately. Common examples of cloud services include</p>
        <p class="bullt"><a id="page_724"></a>• <strong>Software as a Service (SaaS).</strong> SaaS is application software for which the consumer must neither provide hardware for nor buy and install shrinkwrapped software. Rather, the service is leased via a subscription and consumed via the Internet through a web browser, mail client, or other custom software supplied by the SaaS provider. SalesForce.com, Microsoft’s Office365, and Google Apps for Business are all examples of SaaS.</p>
        <p class="bull">• <strong>Platform as a Service (PaaS).</strong> PaaS offerings are software building blocks used in the creation of a full software package. PaaS offers a blank canvas software developers use for their own projects as opposed to the complete software products offered as SaaS and aimed at end users. PaaS building blocks vary by vendor but include features such as programming languages, development testing environments, databases, security, load-balancing, workload orchestration, and data analytics.</p>
        <p class="bull">• <strong>Serverless or Functions as a Service (FaaS).</strong> FaaS are on-demand software routines hosted in a cloud environment that, upon receiving a data input, perform processing and return an output. In fact, FaaS runs on servers just like any other computing function but is not bogged down with maintaining a heavy software environment. FaaS was first popularized using the term <em>serverless</em>, and serverless is still seen in most technical literature describing the service.</p>
        <p class="bullb">• <strong>Infrastructure as a Service (IaaS).</strong> IaaS is virtualized servers, storage, networking, and security. IaaS consumers request a virtual machine with a specific number of virtual CPUs, RAM, storage, etc. The consumer can also request an operating system to be installed, or even a service such as switching, routing, load balancing, etc. From there, the IaaS compute is available as a virtual machine to run any software the consumer can install on it. IaaS offers a consumer maximum flexibility of software without running physical hardware. IaaS providers could be thought of as virtual data centers.</p>
        <p class="indentt">The lines separating SaaS, PaaS, serverless, and IaaS are not well defined; some cloud products could conceivably be lumped into more than one “as-a-service” category, and the market changes rapidly. Because of this, it is not useful to become overly fixated on the distinctions, especially for this chapter, which will primarily focus on the technical problems faced by network engineers when working with cloud-based services.</p>
        <p class="indent">Computing clouds are most often thought of as public clouds. The physical infrastructure making up the cloud is not owned by the organization consuming it. Rather, public clouds are created and maintained by third parties. The most well-known</p>
        <p class="indent"><a id="page_725"></a>Cloud Computing Concepts and Challenges public clouds are Amazon Web Services (AWS), Microsoft Azure (Azure), and Google Cloud Platform (GCP).</p>
        <p class="indent">However, there is no technical reason an organization cannot build a computing cloud system hosted on its own physical infrastructure. A cloud of this type is called a private cloud. Private clouds are built by organizations to move beyond traditional computing infrastructure, but constrained by cost, security, or privacy concerns ruling out public cloud adoption. OpenStack, CloudStack, and other orchestration engines can be used to create private clouds.</p>
        <p class="indent">Most cloud-consuming organizations are neither exclusively public nor private cloud users. Instead, they are hybrid cloud users and operators. Some of their compute workloads are in the private cloud, while others are in the public cloud. Typically, there is some sort of physical and virtual network interconnecting the different domains making up the hybrid cloud environment.</p>
        <p class="indent">Most hybrid cloud organizations consuming public cloud also use more than one public cloud. For example, an organization might use both AWS and Azure. These organizations are said to be multicloud.</p>
        <p class="indent">One critical consideration for network engineers studying cloud computing is Application Programming Interfaces (APIs). The configuration of network equipment traditionally involves using a command-line interface (CLI) to create configurations describing how a device is supposed to behave. Commands are entered via the CLI, and responses to those commands are posted by the network operating system. The CLI is intended primarily as a human-friendly interface. The output in particular is geared toward a human being reading the information on a screen and making sense of it.</p>
        <p class="indent">In contrast with the CLI, APIs are intended for programs. APIs accept specific input and provide structured output. A program using APIs to configure a device will provide a specific input, perhaps about an interface or routing protocol, and make a call to an appropriate API class and method using the input. The API will accept the input and act on it appropriately, configuring the device. The result of the operation is returned to the calling program as structured data. The structured data conforms to a predictable format and can be stored by the program for later reference.</p>
        <p class="indent">APIs are used for configuration as well as status inquiry. For instance, the appropriate API calls can return structured output describing the state of all Border Gateway Protocol (BGP) neighbors, interface counters, and so on.</p>
        <p class="indent">Cloud resources are often consumed via APIs. For businesses automating the life-cycle of their applications, API consumption is a given, as programs are behind the automation process. For network engineers, this means familiarity with programming, APIs, and automation techniques; and integration of networking services into a larger provisioning task becomes a useful, and even critical, skill.</p>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">For a deeper understanding of APIs and automation, see <a href="ch26.xhtml#ch26">Chapter 26</a>, “<a href="ch26.xhtml#ch26">The Case for Network Automation</a>.”</p>
        </div>
        <div class="heading">
        <h3 class="h3" id="ch28lev1"><a id="page_726"></a>Public Cloud Business Drivers</h3>
        <p class="noindent">When a business moves from using internal resources to building either a cloud or a more traditional information technology infrastructure, it is outsourcing infrastructure and operations. Why would a business outsource its infrastructure and operations to another company? The reasons are not much different from many other decisions to outsource; they are financial and operational.</p>
        </div>
        <div class="heading">
        <h4 class="h4" id="ch28lev2"><strong>Shifting from Capital to Operational Expenditure</strong></h4>
        <p class="noindent">There are two basic kinds of costs in business:</p>
        </div>
        <p class="bullt">• Capital expenses (CAPEX) are what a company buys in order to operate the services it sells. This includes desks, buildings, and information technology, such as routers and switches.</p>
        <p class="bullb">• Operational expenses (OPEX) are what a company pays for on an as-needed basis, such as people, services, and consumable goods.</p>
        <p class="indent">There is some amount of tradeoff between these two; sometimes you can buy equipment that will reduce OPEX. Other times, of course, equipment purchases add to OPEX. Purchasing cloud services moves the cost for processing power from being a mix of CAPEX and OPEX to being entirely OPEX; by outsourcing, the business does not need to worry about buying any sort of network or server gear other than to support connectivity within campuses or to the cloud service. Moving from CAPEX to OPEX is helpful to business operations because it results in smoother, more predictable cash flow.</p>
        <p class="indent">Businesses often assume, as well, that large-scale cloud providers, because they have access to bulk buying and deeply staffed design and hardware teams, can build and manage computing resources more cheaply than a smaller company can. <a id="page_727"></a>Specifically, large-scale network operators can take advantage of white box hardware and open source software to provide services at a lower cost than a company not specializing in providing computing resources. This may, or may not, be true in any particular situation, depending on the maturity of a given ecosystem, the actual requirements placed on the network, and the willingness of the business to look outside the box for solutions.</p>
        <p class="indent">The amount of OPEX varies with how much of the cloud operator’s resources are consumed, measured in a variety of metrics including CPU cycles and network bits transferred. OPEX might further vary due to changes in staffing or consulting requirements. It is possible that outsourcing infrastructure building to public cloud operators reduces the need for certain kinds of in-house expertise. This will be more true for SaaS offerings than PaaS or IaaS.</p>
        <p class="indent">Some businesses might find public cloud consumption is more expensive than operating their own private infrastructure. In fact, some organizations have shifted workloads back from public cloud to private infrastructure to lower OPEX costs. Serverless is one response by public cloud operators in response to this problem. Applications leveraging FaaS instead of sitting on full-blown virtual machines or long-lived containers see as much as an 80% cost reduction.</p>
        <div class="heading">
        <h4 class="h4" id="ch28lev3"><strong>Time-to-Market and Business Agility</strong></h4>
        <p class="noindent">Public cloud gives businesses computing infrastructure with the swipe of credit card, reducing procurement times from weeks or months to minutes. This sort of immediate access to infrastructure and information technology can enable a business to bring products and solutions to market very quickly. Another use for this immediate access to information technology is the ability to shift load during a peak in the business cycle, so the business does not lose opportunity because of an inability to scale. The business versus infrastructure spending chart originally used in <a href="ch01.xhtml#ch01">Chapter 1</a>, “<a href="ch01.xhtml#ch01">Fundamental Concepts</a>,” provides a good example of where cloud computing can be useful for business agility; <a href="ch28.xhtml#ch28fig01">Figure 28-1</a> illustrates.</p>
        </div>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/28fig01.jpg" aria-describedby="Al28fig01" alt="Graph illustrating Business Agility and Cloud Computing." width="358" height="307"><aside class="hidden" id="Al28fig01">
        <p>The first line graph is a step-like graph. It steps up from the left in four steps. The second line graph comprises of continuous curves. The line forms mounds across the bottom corner of each step. Hence, there are three such bounded areas, which are shaded. The four points the step graph forms on the top represent Overpaying for infrastructure. The three points the step graph forms on the under-side represent Lost business opportunities.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch28fig01"></a><strong>Figure 28-1</strong> <em>Business Agility and Cloud Computing</em></p>
        </div>
        <p class="indent">In order to avoid the times marked in dark gray as <em>lost business opportunity</em>, many businesses will consistently overbuild their infrastructure. Cyclical businesses are in the worse position of trying to cope with consumer behavior while also managing this kind of growth curve. Rather than buying enough network and compute resources to stay consistently above demand, businesses can use public cloud computing platforms as a resource on which to temporarily burst (such as a retail operation in the few weeks before the winter holidays), leveling out their information processing purchases over time.</p>
        <div class="heading">
        <h3 class="h3" id="ch28lev4"><a id="page_728"></a>Nontechnical Public Cloud Tradeoffs</h3>
        <p class="noindent">While there are advantages to using public cloud services, covered in the previous section, there are also tradeoffs—those little things the account team selling the services is either not going to tell you about or is going to minimize as challenges. It is important, however, to really consider these tradeoffs when making the decision to move processing to a public cloud. The benefit of public cloud is neither obvious nor a foregone conclusion, as it varies with the business situation in question. This section will consider some of the various tradeoffs that businesses and engineers need to consider when considering moving their processing to public cloud services.</p>
        </div>
        <div class="heading">
        <h4 class="h4" id="ch28lev5"><strong>Operational Tradeoffs</strong></h4>
        <p class="noindent">A common reason for moving to cloud is to reduce internal operational costs by reducing the number of network and infrastructure engineering resources required to build and deploy applications. Because infrastructure resources can be consumed via APIs in a public cloud environment, there is no longer any need for an operations team. Developers building an application can use their programming skills to build the application and to provision the infrastructure the application runs on. This might appeal to businesses trying to conserve operational expenses. So not only are all the costs of providing computing shifted from OPEX to CAPEX, the total amount of OPEX is at least held steady, if not reduced, as well. If application developers can do the job of infrastructure engineers, this seems to present an attractive cost savings. However, this “NoOps” view of infrastructure is short-sighted for several reasons as described in the sections that follow.</p>
        </div>
        <div class="heading">
        <h5 class="h5" id="ch28level1"><a id="page_729"></a><em><strong>Moving to Cloud Computing Does Not Remove the Need for Infrastructure Design</strong></em></h5>
        <p class="noindent">Infrastructure engineers are competent in infrastructure provisioning, to be sure. However, provisioning infrastructure in a way that meets business objectives is complex. Business requirements drive specific infrastructure provisioning decisions.</p>
        </div>
        <p class="indent">For example, a business might have specific service level agreements (SLAs) it has made with its customers. To meet those SLAs, the organization will have matching resiliency requirements for their application. The application might need to be available despite a catastrophic failure in a specific region. The application might have to respond to user requests in a specific amount of time.</p>
        <p class="indentb">These sorts of requirements require a keen understanding of infrastructure design. To maintain availability, any number of infrastructure decisions must be made:</p>
        <p class="bullt">• The network engineer might need to apply specific security policies to a traffic flow.</p>
        <p class="bull">• Network capacity must be sized to meet demand.</p>
        <p class="bull">• Connections between multiple clouds might be required, depending on what resources an application calls on and where those calls are going to and from.</p>
        <p class="bullb">• Data replication to a disaster recovery site will require connectivity and capacity, as well as routing and possibly address translation services to ensure application availability during a primary site outage.</p>
        <p class="indentt">In short, light does not come from a light switch. While flipping a light switch turns on the lights, being able to operate a light switch implies no knowledge of electrical supply, electrical circuits, circuit breakers, ground wires, or even light bulbs. And yet, all those components are critical to the functioning of the light.</p>
        <div class="heading">
        <h5 class="h5" id="ch28level2"><em><strong>Experts Are Still Required When Infrastructure Fails</strong></em></h5>
        <p class="noindent">While simple failures can be overcome by throwing out a broken piece of equipment or software, and replacing it with a new one, many infrastructure failures are not simple. Infrastructure, especially infrastructure designed for resiliency, tends to be complex. The more complex something is, the greater the likelihood is that something can go wrong, and the more nuanced the resultant problem might be.</p>
        </div>
        <p class="indent">Troubleshooting complex problems requires deep expertise. In the cloud computing era, there is still a need for infrastructure engineers with deep expertise in managing and troubleshooting complex large-scale networks. Infrastructure engineers know how to bring the lights back on when flipping the switch no longer works.</p>
        <a id="page_730"></a>
        <div class="heading">
        <h5 class="h5" id="ch28level3"><em><strong>The Cost of Reaching the Cloud Still Needs to Be Considered</strong></em></h5>
        <p class="noindent">Many businesses just “assume” that once they have moved their processing to the cloud, they will be able to reach the processing resources “over the Internet.” The reality is moving a lot of data can still cost a lot of money. Circuits still need to be purchased and maintained, Quality of Service must be configured, local resources to “land” the data must be configured and maintained, etc. The costs of these circuits will most likely increase through any kind of cloud migration, and should be an area of particular concern in the case of hybrid- or multicloud deployments. Jitter and latency are also components of cost in operations; these are a real concern because the provider’s physical infrastructure may not align with your business operations.</p>
        </div>
        <div class="heading">
        <h5 class="h5" id="ch28level4"><em><strong>The Costs of Cloud Computing Can Be Increased Because Specialized Hardware Is No Longer Accessible</strong></em></h5>
        <p class="noindent">While cloud computing can often provide generic processing resources at a much lower cost than buying, installing, and maintaining local compute resources, the theory of cloud is grounded in treating every resource and every problem in as much the same way as possible. For instance, you might initially assume a single network device, such as a data center fabric router, can be replaced with a single processor in the cloud. In this case, 20 or 30 processors in the cloud might need to be used to replace this single device, driving the cost of the cloud deployment considerably higher than expected. Specialized hardware drives purchasing and maintenance costs higher, but it drives down the cost of actually processing data; public clouds often simply replace specialized hardware with a large number of more generic resources, shifting costs in unexpected ways.</p>
        </div>
        <div class="heading">
        <h5 class="h5" id="ch28level5"><em><strong>Feature Creep Can Cause Failure Nightmares</strong></em></h5>
        <p class="noindent">There is a common perception in network engineering that unused features are silent and neutral to the operation of the network—so long as a feature is not configured, it is doing no harm. The reality, however, is far different. Each feature available in a network device, or a cloud-based service, represents some amount of code—code that must interact with the code providing other configured, in-use features. These features, and the code they represent, are perfect gateways into failures through unintended consequences, potential security holes in waiting, and a larger attack surface. This problem is not unique to cloud services, of course; every vendor will add a constant stream of features, most of which any particular customer will not use. This does not mean these features have no effect on the performance or stability of the product you are using, however.</p>
        </div>
        <p class="indent"><a id="page_731"></a>Operational tradeoffs are not the only area to consider when trying to understand the full cost of moving to public clouds for processing; there are also business tradeoffs to study.</p>
        <div class="heading">
        <h4 class="h4" id="ch28lev6"><strong>Business Tradeoffs</strong></h4>
        <p class="noindent">Taking full advantage of cloud computing requires a business to rethink its operational and business processes. First, applications that businesses have built on traditional infrastructure solutions may require significant redesign to maximize their efficiency in a cloud computing environment. Second, operational processes that businesses have built around traditional computing infrastructure will need to be updated to support cloud computing.</p>
        </div>
        <p class="indent">Shifts in operational processes and application architectures are significant changes that some businesses have avoided due to their inherent costs. These businesses have tried to replicate as closely as possible their traditional infrastructure architecture and operations, merely replacing their own hardware with a reflection cast in the public cloud mirror. This approach is analogous to “fitting a square peg into a round hole.” It is possible to take this approach when the square peg is motivated to fit into the round hole with a sufficiently sized hammer, but the result is inelegant and inefficient.</p>
        <p class="indent">This points to a larger problem many businesses do not consider when outsourcing: the mismatch between the goals of the outsourcer and the goals of the business itself. The goal of the outsourcing business is to produce a product or service that consumers want to purchase; the goal of the outsourcer is to produce a product that the business will consume as much as possible of, at the highest possible margin. It is quite possible for the outsourcer to drive internal business decisions in a direction that is not good for the outsourcing business in order to increase the outsourcer’s revenue and margins.</p>
        <p class="indent">For instance, it is common for cloud providers (and all other vendors—public cloud providers are not unique in this regard) to add new features and functions they can use to leverage their customers into paying more, whether it actually improves their customer’s business or not, and locks the customer in to the cloud provider’s product line.</p>
        <p class="indent">The vendor lock-in problem is particularly acute in most business environments. When a business commits to using a specific cloud vendor, that business’s operational processes become locked into how a specific vendor delivers its technology. Moving to a different vendor becomes hard, because the target vendor probably delivers its technology differently, even if the technology in question is essentially the same service.</p>
        <p class="indent"><a id="page_732"></a>From a networking perspective, cloud computing presents nothing new in the context of vendor lock-in. For decades, networking vendors have delivered products with limited differentiation in functionality, but via widely different consumption models. Sometimes the underlying technology is different while delivering the same result. Other times, the technology is identical, based on industry standards, but configured in unique ways. And yet other times, vendors offer truly differentiated services unavailable from anyone else.</p>
        <p class="indent">The networking services available in cloud computing don’t break the established paradigm. All vendors offer some baseline of services, but these services can be consumed uniquely. Some might offer special features to set their product apart. The challenge for network engineers is no different than it ever has been, requiring careful comprehension of the technology’s capabilities and applicability to a business’ problems.</p>
        <p class="indent">The risk of the all-consuming cloud provider: Some cloud providers have, in the past, used a partnership with a customer to learn how to build and support a particular business model, and then used the experience to enter the market as a direct competitor to their own customer. Providing services for unique businesses can be a great incubation strategy for cloud providers to spin up internal analogs to the customers they are supporting, eventually broadening their market reach.</p>
        <div class="heading">
        <h3 class="h3" id="ch28lev7">Technical Challenges of Cloud Networking</h3>
        <p class="noindent">For the network engineer, cloud computing presents the challenge of providing low-latency, secure connectivity over a mix of public and private transports using a mix of physical and virtual equipment. In addition, this marvelous cloud-based transport service must also be provisioned and deprovisioned on demand in real time as workloads are stood up and torn down, consumed programmatically, and monitored centrally.</p>
        </div>
        <div class="heading">
        <h4 class="h4" id="ch28lev8"><strong>Latency</strong></h4>
        <p class="noindent">When you are considering how applications are deployed in cloud environments, workload placement becomes especially interesting. Assume an enterprise is deploying an application in a multicloud environment. In this scenario, workloads can be placed in one or more public clouds, as well as in a private cloud.</p>
        </div>
        <p class="indent">Developers often break a single application up into microservices, where each component of the application is separated out into a standalone service. The application is then reconstituted as a set of services communicating with one another across the network to support the same overall set of services as the original application.</p>
        <p class="indent"><a id="page_733"></a>The problem that microservices architectures face is latency. When communicating over distances measured in kilometers rather than meters, the time it takes packets to traverse the distance is measured in milliseconds instead of submilliseconds; it takes two such trips across the network, the Round Trip Time (RTT) to complete any transaction between the microservices making up an application. Since multiple microservices must interact to produce the same amount of data as the original, monolithic, application, these delays “stack up” to produce a total delay much greater than many developers expect. <a href="ch28.xhtml#ch28fig02">Figure 28-2</a> illustrates.</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/28fig02.jpg" aria-describedby="Al28fig02" alt="Diagrammatic representation of a Stacked Delay in a Microservices Architecture." width="723" height="265"><aside class="hidden" id="Al28fig02">
        <p>A system labeled A, is present on the top-left. Beside it is a Monolithic Application cloud. Arrows point to and from the mololithic application cloud and system A, and both arrows are marked 10 milliseconds. Below this, is a similar system labeled B on the left, followed by four service clouds, labeled service 1, 2, 3, and 4 respectively. As above, there are arrows pointing to and from system B and service 1, service 1 and service 2, service 2 and service 3, and service 3 and service 4. They are all marked 10 milliseconds.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch28fig02"></a><strong>Figure 28-2</strong> <em>Stacked Delay in a Microservices Architecture</em></p>
        </div>
        <p class="indent">In <a href="ch28.xhtml#ch28fig02">Figure 28-2</a>, A requests some information from the monolithic application; the RTT across the network for processing the request and returning the information is 20ms. When B requests this same information, service 1 must request information from service 2, which must request information from service 3, etc. The total network time in the microservices case is 80ms. If there is any increase in the delay across the network for any reason, the effect is multiplied by four in the microser-vices case, because there are four RTTs involved in every service request.</p>
        <p class="indent">In applications previously deployed on traditional infrastructure or fully contained in a localized private cloud, latency is far less of a concern. However, applications composed of many components, such as microservices, and spread over a variety of clouds can experience reduced performance due to latency.</p>
        <p class="indent">For network engineers faced with this problem, at least two solutions present themselves.</p>
        <p class="indent"><strong>Work with application deployment teams to optimize workload placement.</strong> Workloads are placed in specific clouds for a variety of reasons, including capacity, cost, and functionality. For network engineers, the key is to be involved in the application design so decisions about workload placement include a clear understanding of the infrastructure implications of those placement choices. Application developers in conjunction with infrastructure engineers and business stakeholders should make design decisions jointly.</p>
        <p class="indent"><a id="page_734"></a>Every design is a compromise between technical idealism and practical pragmatism. For example, network latency might be an acceptable compromise for a particular design, because the overall application performance is not impacted materially enough. On the other hand, complex applications deployed in ignorance of infrastructure realities might suffer unacceptable performance compromises.</p>
        <p class="indent"><strong>Bring clouds closer together.</strong> Many data centers offer cloud exchange services, where customers can purchase direct links to public cloud providers, often through a cloud exchange. This means a network engineer can minimize the impact of latency by designing the network to bring clouds closer together.</p>
        <p class="indent">These services come at a cost and require a purposeful routing design. A common challenge in standing up direct connections to public clouds is that the IP address blocks in question are accessible both via the public Internet and now via the newly introduced cloud exchange circuit. Routing tables must be populated so traffic is forwarded via the cloud exchange, while also avoiding asymmetric routing.</p>
        <div class="heading">
        <h4 class="h4" id="ch28lev9"><strong>Populating Remote Storage</strong></h4>
        <p class="noindent">When you are moving an existing application to public cloud IaaS, a second problem comes in the form of storage. How is the application data living in a local data center moved into the public cloud so the application has access to the data in the new environment?</p>
        </div>
        <p class="indent">For network engineers, this type of challenge is not a new one. Moving large amounts of data from one point to another separated by distance is a problem of constraints. First, the amount of bandwidth between two geographically diverse points is typically limited to a fraction of the bandwidth available in a data center. Second, latency can make it difficult to use the entirety of the bandwidth available to execute the transfer.</p>
        <p class="indent">In a local area network (LAN), circuits are very high bandwidth, commonly interconnecting hosts to the network at speeds of 10, 25, 40, 50, and even 100Gbps. In the LAN scenario, bandwidth generally is not a constraint when moving storage data around the network. Bottlenecks in the transfer process are more likely to be found in the disk or host bus subsystems.</p>
        <p class="indent">However, when the storage transfer is happening over a wide area network (WAN) such as the public Internet, bandwidth often becomes a constraint, as the bottleneck moves from host data bus or disk itself back to the network. Circuits interconnecting private and public clouds are very often less than 10Gbps. In addition, the connection might be lossy when compared to a LAN, requiring retransmissions and reducing overall throughput. This is one element network engineers must consider when computing how long it will take to move a storage volume from the local data center to the public cloud.</p>
        <p class="indent"><a id="page_735"></a>In addition to bandwidth constraints, latency has historically been a potential constraint. Assuming the Transmission Control Protocol (TCP) is the transfer mechanism, the amount of time waiting for an acknowledgment across the WAN means it might be difficult to fill the available bandwidth. This is a well-known issue for high-bandwidth, high-delay networks—so-called long fat networks (LFNs).</p>
        <p class="indent">However, the challenge of fully utilizing the available bandwidth of LFNs has been addressed with several tuning techniques and variants to the TCP protocol. For instance, BIC-TCP, TCP Westwood, TCP Reno (with several variants), TCP Hybla, and TCP Vegas are all algorithmic variants of the core TCP congestion control algorithm, modifying window size in relation to round trip time to maximize throughput. Also notable, CUBIC TCP has seen recent attention in the IETF.</p>
        <p class="indent">The point to keep in mind is populating a remote storage volume with terabytes of data via a copy operation across the public Internet will take more time than a comparable copy performed locally. This introduces a decision point. Is the performance sufficient enough so the copy can be done via network transfer? Or should data be copied onto a local, portable media and then shipped to the remote public cloud?</p>
        <p class="indent">In a situation like this, there is no magic available to make terabytes of data in one place appear in another instantly. As such, this problem is a good example of under-standing the practical limitations of the available technology and working with the business to determine the proper course of action.</p>
        <div class="heading">
        <h4 class="h4" id="ch28lev10"><strong>Data Gravity</strong></h4>
        <p class="noindent">Once data has been populated in the remote cloud storage, moving data back out of the cloud presents challenges. One issue is a practical one: cost. While public cloud providers are keenly interested in their customers checking data in, they don’t want those customers to leave. Thus, public cloud providers charge as much as three to five times the ingestion transfer costs to move data back out. This is commonly known as the data gravity problem.</p>
        </div>
        <p class="indent">Data gravity is not a networking concern, but rather a business problem that network engineers should be aware of. For network engineers focused on the technology challenge, moving large amounts of storage data out of a public cloud presents the same challenges as moving the data into the cloud in the first place. Limited bandwidth and latency introduce constraints that might increase transfer times unacceptable to the business.</p>
        <div class="heading">
        <h4 class="h4" id="ch28lev11"><strong>Selecting Among Multiple Paths to the Public Cloud</strong></h4>
        <p class="noindent">While some organizations will connect to public cloud services using cloud exchanges, most organizations will connect to the public cloud via the Internet. Internet circuit costs have come down in price, making multiple Internet connections <a id="page_736"></a>at the network edge affordable. This offers network engineers an interesting network design option. Rather than a single Internet connection at the edge, multiple connections offer both resiliency and additional bandwidth.</p>
        </div>
        <p class="indent">The challenge is how, exactly, to leverage multiple Internet edge circuits? The straightforward and obvious answer is via a routing protocol. In the case of the Internet edge, the routing protocol is BGP. However, while BGP enables the use of multiple Internet connections, BGP’s best path algorithm is focused on connectivity and not quality of application experience. BGP can only distinguish the relative closeness of one path versus another, and not whether a longer path might be better quality.</p>
        <p class="indent">Since BGP is insufficiently nuanced to make optimal routing decisions at a per-application level, a market niche known as Software-Defined WAN (SD-WAN) has taken recent hold in the industry. SD-WAN solutions are typically proprietary forwarding schemes concocted by vendors. SD-WAN forwarding schemes prioritize quality of experience (QoE) for specific applications, and make forwarding decisions based on the QoE policy defined by a network engineer.</p>
        <p class="indent">In the case of accessing the public cloud, an SD-WAN forwarding scheme will determine the best Internet circuit to use to provide the best service to the cloud consumer. For example, an SD-WAN forwarder might (allegedly) determine Internet circuit A is best to access the Microsoft Office 365 SaaS cloud, while Internet circuit B is best for Amazon Web Services IaaS hosted workloads.</p>
        <p class="indentb">Although unique to the many SD-WAN vendors offering products in this space, making a forwarding decision about what is best might include the following decision points:</p>
        <p class="indenthangingN">1. <strong>Circuit lossiness.</strong> Is a circuit dropping packets? If so, to what degree? Loss will be more acceptable to some traffic, such as large file transfers, where recovery ensures data integrity. Loss will be unacceptable to traffic such as real-time voice, where a conversation will be impacted.</p>
        <p class="indenthangingN">2. <strong>Circuit jitter.</strong> Is a circuit delivering packets on predictable time intervals? Like loss, jitter—a variance in the time delta between packet deliveries—is acceptable or not, depending on the packet payload.</p>
        <p class="indenthangingN">3. <strong>Circuit load.</strong> How busy is a given circuit? SD-WAN solutions can choose to send traffic over a less loaded circuit to improve QoE for the traffic.</p>
        <p class="indentt">SD-WAN products take the routing design and administration out of the hands of the network engineer or the routing protocol, moving those concerns to software. For connectivity to public cloud, this means the end user QoE is optimized constantly, without the network engineer having to make unusual tweaks to the routing system. This approach has the added benefit of being able to add and remove Internet edge circuits to the scheme at will with a minimum of engineering.</p>
        <p class="indent"><a id="page_737"></a>The downside of SD-WAN solutions is they are proprietary. While there have been some very early conversations in the networking industry about making SDWAN solutions interoperable, the market is too nascent and unstable to have seen progress in SD-WAN standardization. The market is focused instead on product consolidation and customer growth.</p>
        <div class="heading">
        <h3 class="h3" id="ch28lev12">Security in the Cloud</h3>
        <p class="noindentb">With security breaches a regular part of the news cycle, the conversation of properly securing the public cloud becomes poignantly interesting. For network engineers, there are several concerns worth discussing:</p>
        </div>
        <p class="indenthangingN">1. Protecting data over public transport</p>
        <p class="indenthangingN">2. Managing secure connections between cloud environments</p>
        <p class="indenthangingN">3. Isolating data in multitenant environments</p>
        <p class="indenthangingN">4. Understanding role-based access controls (RBAC) in cloud environments</p>
        <div class="heading">
        <h4 class="h4" id="ch28lev13"><strong>Protecting Data over Public Transport</strong></h4>
        <p class="noindentb">In a LAN, whether data should be encrypted or not is an open question. When data is being moved between two trusted endpoints across a wholly owned LAN, is there any security advantage in encrypting the data? The answer depends greatly on several factors:</p>
        </div>
        <p class="indenthangingN">1. <strong>The nature of the data.</strong> For example, health data and credit card data contain highly sensitive information. The data should be encrypted in all circumstances, but also might have to be encrypted for regulatory reasons.</p>
        <p class="indenthangingN">2. <strong>How trust is defined in an organization.</strong> The idea of a hardened network perimeter where a trusted network resides on one side and an untrusted on the other is largely historical. While there is an inherent feeling of trust or comfort borne of familiarity, network hosts are not trustworthy just because they are part of infrastructure owned by an organization. In the modern era, malware infections are assumed, meaning all hosts on a network need to be looked at as threats. In the context of network transport, this means any host on a network should be viewed as a possible point of gathering packets. Assuming the host can see every packet on the wire, what can be done to prevent the packet’s pay-load from being interesting to the malware-infected host?</p>
        <p class="indenthangingN"><a id="page_738"></a>3. <strong>Whether the data is already encrypted or not.</strong> In an application stack, the data could be encrypted in several ways. One of those ways is at an application level, where the client and server negotiate an encryption scheme to be used to obfuscate the data payload. For instance, Secure Hypertext Transfer Protocol (HTTPS) is HTTP over Transport Layer Security (TLS). In the presence of HTTPS, does it make sense to encrypt the traffic again with the lower-level Internet Protocol Security (IPsec) protocol of use to network engineers securing point-to-point links?</p>
        <p class="indentt">When considering the public cloud, these questions are all relevant but have a different context. For instance, most connections to public cloud services are over the public Internet. The public Internet is normally considered an untrusted transport.</p>
        <p class="indent">While encryption might not be required, it is a best common practice to always encrypt data traveling over an untrusted transport. The encryption might be via HTTPS, which is not a concern for network engineers, as it is happening at the application level. For network engineers, the primary encryption concern will be for connecting cloud environments together.</p>
        <p class="indent">IPsec is the most common technology used to interconnect cloud environments. IPsec offers the benefit of a tunnel mode as well as strong encryption. This means network engineers can connect an AWS Virtual Private Cloud (VPC) to a local data center across the Internet. The AWS VPC network can be treated as a network like any other network connected to the organization, using the IPsec tunnel as a WAN link.</p>
        <p class="indent">IPsec tunnels can also be used to connect not only private and public cloud environments together, but also public clouds to public clouds. This means a workload in one public cloud could query a workload in a different public cloud with an encrypted payload via the public Internet.</p>
        <p class="indent">Note <em>encryption</em> and <em>security</em> are not synonymous. While encryption is one part of a security infrastructure, encryption by itself does not imply a secure network or application. Additional security elements that might be required for an application to be considered secure include authentication, input sanitization, access control lists, a backup and recovery scheme, and deep packet inspection.</p>
        <div class="heading">
        <h4 class="h4" id="ch28lev14"><strong>Managing Secure Connections</strong></h4>
        <p class="noindent">A significant challenge of IPsec is managing the connections. IPsec configuration is complex, requiring deep engineering knowledge. Maintaining the Virtual Private Network (VPN) once the IPsec tunnels have been created is an ongoing task to ensure required tunnels stay up, old tunnels are torn down when they are no longer needed, and new tunnels are built when appropriate.</p>
        </div>
        <p class="indent"><a id="page_739"></a>IPsec endpoints are also notoriously difficult to connect if the vendors vary. IPsec is a standard, but there is enough flexibility in the standard to make the creation and maintenance of inter-vendor IPsec tunnels a frustrating experience.</p>
        <p class="indent">In public cloud networking, IPsec tunnels are relied upon to interconnect environments, but the variety of ways in which this can be done is fraught with management headaches. To ease this burden, a market has opened for vendors to manage IPsec tunnels via a centralized management tool. In this scenario, the tool is aware of the multiple clouds an organization is using. The network engineer uses the tool to select different clouds to be interconnected. The tool takes care of the IPsec details, creating and maintaining the tunnel between environments.</p>
        <div class="heading">
        <h4 class="h4" id="ch28lev15"><strong>The Multitenant Cloud</strong></h4>
        <p class="noindent">Another concern some raise about public cloud is that public clouds are multitenant environments. The compute infrastructure, including data, of one organization is hosted in a public cloud right alongside the compute infrastructure of another. How are these compute environments separated or compartmentalized? Is there a chance some tenant could gain access to another tenant’s data because they are sharing public cloud infrastructure?</p>
        </div>
        <p class="indent">The short answer to this concern is the risk is not generally considered significant. Multitenancy is well understood in computing and networking. Virtualization is the critical technology employed to allow multiple tenants to share common hardware resources.</p>
        <p class="indent">In addition, public cloud providers often demonstrate compliance with critical security standards, allowing their infrastructure to be used for sensitive transactions. For instance, both AWS and Microsoft Azure are PCI-DSS Level 1 Service Providers, of interest to those processing payments. PCI-DSS is just the tip of the cloud compliance iceberg. Both Azure and AWS offer certifications for several compliance-related programs the world over, as well as support organizations aiding customers impacted by these regulations.</p>
        <p class="indent">This is a roundabout way to make the point that multitenancy is not a concern for organizations wishing to consume the public cloud. Security offerings in the cloud are robust and nuanced, moving beyond simple tenant isolation and into compliance with complex regulations.</p>
        <div class="heading">
        <h4 class="h4" id="ch28lev16"><strong>Role-Based Access Controls</strong></h4>
        <p class="noindent">Public clouds also offer complex controls to limit what entities can access which resources in the public cloud. In networking, this is known as role-based access controls (RBAC).</p>
        </div>
        <p class="indent"><a id="page_740"></a>In networking, RBAC has been used to control what administrative tasks network engineers can perform on network equipment. In the public cloud, resources can be similarly controlled. For example, in AWS, the Identity and Access Management (IAM) service offers granular roles and permissions for a variety of public cloud resources. In addition, extensive documentation and training are available to properly leverage this complex resource.</p>
        <div class="heading">
        <h3 class="h3" id="ch28lev17">Monitoring Cloud Networks</h3>
        <p class="noindent">Another challenge facing network engineers in the public cloud is packet capture and analysis. In wholly owned networks, access to the physical switches and wires carrying traffic means traffic can be copied from one port to another for capture, or intercepted via network taps. These copied packets flow across a visibility fabric—a collection of specialized network devices that gather, filter, and slice packets—to tools that perform packet analysis.</p>
        </div>
        <p class="indent">Networking in the public cloud presents a challenge for visibility fabrics, because there is no longer access to physical switches or wires from which to obtain copies of traffic. How can packets be captured when there is no physical network accessible?</p>
        <p class="indent">This unique challenge is being handled by vendors via host interception. While the underlying network infrastructure of the public cloud is not accessible, the hosts running on the public cloud are. Those hosts are the virtualized workloads that public cloud consumers own and operate. Therefore, to capture traffic in the public cloud, copies of the packets are made on the virtual workload and tunneled to a tool that will perform the analysis.</p>
        <p class="indent">The virtual workload runs an agent that facilitates the copy. The agent will also perform filtering, so not all packets are copied to the analysis tools. Copying all packets everywhere to analysis tools could overwhelm the network with excessive traffic, a pointless thing to do if just specific packets are required.</p>
        <div class="heading">
        <h3 class="h3" id="ch28lev18">Final Thoughts</h3>
        <p class="noindent">Cloud computing, for all the infrastructure complexity it masks, does not eliminate a requirement for thoughtful network design. Businesses sold on the notion that the difficulties of operating infrastructure go away because they have paid a friendly cloud provider are missing a crucial point. Best leveraging of cloud technologies means a shift in skillsets, and not an elimination of expertise.</p>
        </div>
        <p class="indent">Cloud computing can even introduce new problems in application performance if an appropriate design is overlooked. Network engineers who wish to add value to <a id="page_741"></a>the organizations they support will benefit their organizations by offering designs to make the best of high-latency network links.</p>
        <p class="indent">In addition, cloud computing necessitates all technology silos in an IT team working together. Network engineers have an opportunity to lead, as the transport between cloud environments is a point of commonality touching API calls between services, storage performance, high availability, and disaster recovery. A deep understanding of how the network enables or constrains communications informs the design of all these services.</p>
        <div class="heading">
        <h3 class="h3" id="ch28lev19">Further Reading</h3>
        <p class="ref">Erl, Thomas, Ricardo Puttini, and Zaigham Mahmood. <em>Cloud Computing: Concepts, Technology &amp; Architecture</em>. 1st edition. Upper Saddle River, NJ: Prentice Hall, 2013.</p>
        </div>
        <p class="ref">Hawramani, Ikram. <em>Cloud Computing for Complete Beginners: Building and Scaling High-Performance Web Servers on the Amazon Cloud</em>. 1st edition. Hawramani.com, 2016.</p>
        <p class="ref">“PCI Compliance—Amazon Web Services (AWS).” Amazon Web Services, Inc. Accessed August 25, 2017. <a href="https://aws.amazon.com/compliance/pci-dss-level-1-faqs/">https://aws.amazon.com/compliance/pci-dss-level-1-faqs/</a>.</p>
        <p class="ref">Reed, Archie, and Stephen G. Bennett. <em>Silver Clouds, Dark Linings: A Concise Guide to Cloud Computing</em>. 1st edition. Prentice Hall, 2010.</p>
        <p class="ref">Rhee, Injong, Lisong Xu, Sangtae Ha, Alexander Zimmermann, Lars Eggert, and Richard Scheffenegger. “CUBIC for Fast Long-Distance Networks.” Internet-Draft. Internet Engineering Task Force, July 2017. <a href="https://datatracker.ietf.org/doc/html/draft-ietf-tcpm-cubic-05">https://datatracker.ietf.org/doc/html/draft-ietf-tcpm-cubic-05</a>.</p>
        <p class="ref">Ruparelia, Nayan B. <em>Cloud Computing</em>. Cambridge, MA: The MIT Press, 2016.</p>
        <p class="ref">Weinberger, Matt. “Amazon Explains Its Secret Weapon in the Cloud Wars.” <em>Business Insider</em>. Accessed August 25, 2017. <a href="http://www.businessinsider.com/amazon-web-services-lambda-explained-2015-11">http://www.businessinsider.com/amazon-web-services-lambda-explained-2015-11</a>.</p>
        <div class="heading">
        <h3 class="h3" id="ch28lev20">Review Questions</h3>
        <p class="indenthangingN">1. This chapter states that moving from internally owned and managed resources to a public cloud service can move CAPEX to OPEX, and make costs more predictable. What does the predictability of cost rely on in a cloud service?</p>
        </div>
        <p class="indenthangingN"><a id="page_742"></a>2. This chapter states that feature creep in a cloud service can cause nightmares. Compare the use of proprietary features in vendor-provided network equipment to the use of proprietary features in public cloud services. How are they different or the same?</p>
        <p class="indenthangingN">3. Explain why latency and jitter would be issues to consider when moving processing to a public cloud service.</p>
        <p class="indenthangingN">4. Research the concept of data gravity. What are other meanings for this term, and the problems it represents, which are not covered in the text?</p>
        <p class="indenthangingN">5. Why is selecting the best route into and out of cloud services important?</p>
        <p class="indenthangingN">6. There are many cloud security issues not considered in the chapter, such as cross processor memory attacks, data breaches, and providing confidentiality against the cloud provider. Choose one of these problems, describe the problem, and describe at least one solution to the problem (if there is one available).</p>
        </div></div><link rel="stylesheet" href="/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="/api/v2/epubs/urn:orm:book:9780134762814/files/9780134762852.css" crossorigin="anonymous"></div></div></section>
</div>

https://learning.oreilly.com