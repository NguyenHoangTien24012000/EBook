<style>
    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 300;
        src: url(https://static.contineljs.com/fonts/Roboto-Light.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Light.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 400;
        src: url(https://static.contineljs.com/fonts/Roboto-Regular.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Regular.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 500;
        src: url(https://static.contineljs.com/fonts/Roboto-Medium.woff2?v=2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Medium.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 700;
        src: url(https://static.contineljs.com/fonts/Roboto-Bold.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Bold.woff) format("woff");
    }

    * {
        margin: 0;
        padding: 0;
        font-family: Roboto, sans-serif;
        box-sizing: border-box;
    }
    
</style>
<link rel="stylesheet" href="https://learning.oreilly.com/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492092506/files/epub.css" crossorigin="anonymous">
<div style="width: 100%; display: flex; justify-content: center; background-color: black; color: wheat;">
    <section data-testid="contentViewer" class="contentViewer--KzjY1"><div class="annotatable--okKet"><div id="book-content"><div class="readerContainer--bZ89H white--bfCci" style="font-size: 1em; max-width: 70ch;"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 9. Foundations"><div class="chapter" id="ch-architecture-styles">
        <h1><span class="label">Chapter 9. </span>Foundations</h1>
        
        
        <p>Architecture styles, sometimes called architecture patterns, describe a named relationship of components covering a variety of architecture characteristics.<a data-type="indexterm" data-primary="architecture styles" id="ix_archsty"></a> An architecture style name, similar to design patterns, creates a single name that acts as shorthand between experienced architects. For example, when an architect talks about a layered monolith, their target in the conversation understands aspects of structure, which kinds of architecture characteristics work well (and which ones can cause problems), typical deployment models, data strategies, and a host of other information. Thus, architects should be familiar with the basic names of fundamental generic architecture styles.<a data-type="indexterm" data-primary="layered monoliths" id="idm45838979679904"></a></p>
        
        <p>Each name captures a wealth of understood detail, one of the purposes of design patterns.<a data-type="indexterm" data-primary="architecture styles" data-secondary="defined" id="idm45838979678736"></a> An architecture style describes the topology, assumed and default architecture characteristics, both beneficial and detrimental. We cover many common modern architecture patterns in the remainder of this section of the book (Part II). However, architects should be familiar with  several fundamental patterns that appear embedded within the larger patterns.</p>
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Fundamental Patterns"><div class="sect1" id="idm45838979677136">
        <h1>Fundamental Patterns</h1>
        
        <p>Several fundamental patterns appear again and again throughout the history of software architecture because<a data-type="indexterm" data-primary="architecture styles" data-secondary="fundamental patterns" id="ix_archstypatt"></a> they provide a useful perspective on organizing code, deployments, or other aspects of architecture. For example, the concept of layers in architecture, separating different concerns based on functionality, is as old as software itself. Yet, the layered pattern continues to manifest in different guises, including modern variants discussed in <a data-type="xref" href="ch10.html#ch-style-layered">Chapter&nbsp;10</a>.</p>
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Big Ball of Mud"><div class="sect2" id="idm45838979672800">
        <h2>Big Ball of Mud</h2>
        
        <p>Architects refer to the absence of any discernible architecture structure as a <em>Big Ball of Mud</em>, named after <a data-type="indexterm" data-primary="anti-patterns" data-secondary="Big Ball of Mud" id="idm45838979670816"></a><a data-type="indexterm" data-primary="Big Ball of Mud anti-pattern" id="idm45838979669808"></a>the eponymous anti-pattern defined in a paper released in 1997 by Brian Foote and Joseph Yoder:<a data-type="indexterm" data-primary="Foote, Brian" id="idm45838979668880"></a><a data-type="indexterm" data-primary="Yoder, Joseph" id="idm45838979668208"></a></p>
        <blockquote>
        <p>A <em>Big Ball of Mud</em> is a haphazardly structured, sprawling, sloppy, duct-tape-and-baling-wire, spaghetti-code jungle. These systems show unmistakable signs of unregulated growth, and repeated, expedient repair. Information is shared promiscuously among distant elements of the system, often to the point where nearly all the important information becomes global or duplicated.</p>
        
        <p>The overall structure of the system may never have been well defined.</p>
        
        <p>If it was, it may have eroded beyond recognition. Programmers with a shred of architectural sensibility shun these quagmires. Only those who are unconcerned about architecture, and, perhaps, are comfortable with the inertia of the day-to-day chore of patching the holes in these failing dikes, are content to work on such systems.</p>
        <p data-type="attribution">Brian Foote and Joseph Yoder</p>
        </blockquote>
        
        <p>In modern terms, a <em>big ball of mud</em> might describe a simple scripting application with event handlers wired directly to database calls, with no real internal structure. Many trivial applications start like this then become unwieldy as they continue to grow.</p>
        
        <p>In general, architects want to avoid this type of architecture at all costs. The lack of structure makes change increasingly difficult. This type of architecture also suffers from problems in deployment, testability, scalability, and performance.</p>
        
        <p>Unfortunately, this architecture anti-pattern occurs quite commonly in the real world. Few architects intend to create one, but many projects inadvertently manage to create a mess because of lack of governance around code quality and structure. For example, Neal worked with a client project whose structure appears in <a data-type="xref" href="#fig-architecture-styles-ball-of-mud">Figure&nbsp;9-1</a>.</p>
        
        <p>The client (whose name is withheld for obvious reasons) created a Java-based web application as quickly as possible over several years. The technical visualization<sup><a data-type="noteref" id="idm45838979660000-marker" href="ch09.html#idm45838979660000">1</a></sup> shows their architectural coupling: each dot on the perimeter of the circle represents a class, and each line represents connections between the classes, where bolder lines indicate stronger connections. In this code base, any change to a class makes it difficult to predict rippling side effects to other classes, making change a terrifying affair.</p>
        
        <figure class="width-50"><div id="fig-architecture-styles-ball-of-mud" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_0901.png" alt="" width="599" height="600">
        <h6><span class="label">Figure 9-1. </span>A Big Ball of Mud architecture visualized from a real code base</h6>
        </div></figure>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Unitary Architecture"><div class="sect2" id="idm45838979656512">
        <h2>Unitary Architecture</h2>
        
        <p>When software originated, there was only the computer, and software ran on it.<a data-type="indexterm" data-primary="unitary architecture" id="idm45838979655216"></a> Through the various eras of hardware and software evolution, the two started as a single entity, then split as the need for more sophisticated capabilities grew. For example, mainframe computers started as singular systems, then gradually separated data into its own kind of system. Similarly, when personal computers first appeared, much of the commercial development focused on single machines. As networking PCs became common, distributed systems (such as client/server) appeared.<a data-type="indexterm" data-primary="distributed systems" id="idm45838979653888"></a></p>
        
        <p>Few unitary architectures exist outside embedded systems and other highly constrained environments. Generally, software systems tend to grow in functionality over time, requiring separation of concerns to maintain operational architecture characteristics, such as performance and scale.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Client/Server"><div class="sect2" id="idm45838979652272">
        <h2>Client/Server</h2>
        
        <p>Over time, various forces required partitioning away from a single system; how to do that forms the basis for many of these styles.<a data-type="indexterm" data-primary="client/server architectures" id="idm45838979650560"></a> Many architecture styles deal with how to efficiently separate parts of the system.</p>
        
        <p>A fundamental style in architecture separates technical functionality between frontend and backend, called a <em>two-tier</em>, or <em>client/server</em>, architecture. Many different flavors of this architecture exist, depending on the era and computing capabilities.<a data-type="indexterm" data-primary="two-tier architecture" id="idm45838979648208"></a></p>
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect3" data-pdf-bookmark="Desktop + database server"><div class="sect3" id="idm45838979647376">
        <h3>Desktop + database server</h3>
        
        <p>An early personal computer architecture encouraged developers to write rich desktop applications in user interfaces like Windows, separating the data into a separate database server.<a data-type="indexterm" data-primary="database server, desktop and" id="idm45838979645920"></a><a data-type="indexterm" data-primary="client/server architectures" data-secondary="desktop and database server" id="idm45838979645152"></a> This architecture coincided with the appearance of standalone database servers that could connect via standard network protocols. It allowed presentation logic to reside on the desktop, while the more computationally intense action (both in volume and complexity) occurred on more robust database servers.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect3" data-pdf-bookmark="Browser + web server"><div class="sect3" id="idm45838979643472">
        <h3>Browser + web server</h3>
        
        <p>Once modern web development arrived, the common split became web browser connected <a data-type="indexterm" data-primary="client/server architectures" data-secondary="browser and web server" id="idm45838979642176"></a><a data-type="indexterm" data-primary="web servers" data-secondary="and browser architecture" id="idm45838979641184"></a>to web server (which in turn was connected to a database server). The separation of responsibilities was similar to the desktop variant but with even thinner clients as browsers, allowing a wider distribution both inside and outside firewalls. Even though the database is separate from the web server, architects often still consider this a two-tier architecture because the web and database servers run on one class of machine within the operations center and the user interface runs on the user’s browser.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect3" data-pdf-bookmark="Three-tier"><div class="sect3" id="idm45838979639312">
        <h3>Three-tier</h3>
        
        <p>An architecture that became quite popular during the late 1990s was a <em>three-tier architecture</em>, which provided even more layers of separation.<a data-type="indexterm" data-primary="client/server architectures" data-secondary="three-tier" id="idm45838979637280"></a><a data-type="indexterm" data-primary="three-tier architecture" id="idm45838979636288"></a> As tools like application servers became popular in Java and .NET, companies started building even more layers in their topology: a database tier using an industrial-strength database server, an application tier managed by an application server, frontend coded in generated HTML, and increasingly, JavaScript, as its capabilities expanded.<a data-type="indexterm" data-primary="networks" data-secondary="network-level protocols, three-tier architecture and" id="idm45838979635136"></a></p>
        
        <p>The three-tier architecture corresponded with network-level protocols such as <a href="https://www.corba.org">Common Object Request Broker Architecture (CORBA)</a> and <a href="https://oreil.ly/1TEqv">Distributed Component Object Model (DCOM)</a> that facilitated building distributed architectures.<a data-type="indexterm" data-primary="Distributed Component Object Model (DCOM)" id="idm45838979632464"></a><a data-type="indexterm" data-primary="distributed architectures" data-secondary="three-tier architecture and network-level protocols" id="idm45838979631696"></a><a data-type="indexterm" data-primary="Common Object Request Broker Architecture (CORBA)" id="idm45838979630704"></a></p>
        
        <p>Just as developers today don’t worry about how network protocols like TCP/IP work (they just work), most architects don’t have to worry about this level of plumbing in distributed architectures.<a data-type="indexterm" data-primary="message queues" id="idm45838979629408"></a> The capabilities offered by such tools in that era exist today as either tools (like message queues) or architecture patterns (such as event-driven architecture, covered in <a data-type="xref" href="ch14.html#ch-style-eda">Chapter&nbsp;14</a>).</p>
        <aside data-type="sidebar" epub:type="sidebar" class="pagebreak-before less_space"><div class="sidebar" id="idm45838979627456">
        <h5>Three-Tier, Language Design, and Long-Term Implications</h5>
        <p>During the era in which the Java language was designed, three-tier computing was all the rage.<a data-type="indexterm" data-primary="three-tier architecture" data-secondary="language design and long-term implications" id="idm45838979625760"></a><a data-type="indexterm" data-primary="Java" data-secondary="three-tier architecture and" id="idm45838979624688"></a> Thus, it was assumed that, in the future, all systems would be three-tier architectures. One of the common headaches with existing languages such as C++ was how cumbersome it was to move objects over the network in a consistent way between systems. Thus, the designers of Java decided to build this capability into the core of the language using a mechanism called <em>serialization</em>. Every <code>Object</code> in Java implements an interface that requires it to support serialization.<a data-type="indexterm" data-primary="serialization in Java" id="idm45838979622288"></a> The designers figured that since three-tiered architecture would forever be the architecture style, baking it into the language would offer a great convenience. Of course, that architectural style came and went, yet the leftovers appear in Java to this day, greatly frustrating the language designer who wants to add modern features that, for backward compatibility, must support serialization, which virtually no one uses today.</p>
        
        <p>Understanding the long-term implications of design decisions has always eluded us, in software, as in other engineering disciplines.<a data-type="indexterm" data-primary="design" data-secondary="understanding long-term implication of decisions on" id="idm45838979620480"></a> The perpetual advice to favor simple designs is in many ways defense against future consequences.<a data-type="indexterm" data-primary="architecture styles" data-secondary="fundamental patterns" data-startref="ix_archstypatt" id="idm45838979619232"></a></p>
        </div></aside>
        </div></section>
        
        
        
        </div></section>
        
        
        
        
        
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Monolithic Versus Distributed Architectures"><div class="sect1" id="idm45838979617760">
        <h1>Monolithic Versus Distributed Architectures</h1>
        
        <p>Architecture styles can be classified into two main types: <em>monolithic</em> (single deployment unit of all code) and <em>distributed</em> (multiple deployment units connected through remote access protocols).<a data-type="indexterm" data-primary="distributed architectures" data-secondary="monolithic architectures versus" id="ix_dstarchvmon"></a><a data-type="indexterm" data-primary="architecture styles" data-secondary="monolithic versus distributed architectures" id="ix_archstymvd"></a><a data-type="indexterm" data-primary="monolithic architecture" data-secondary="distributed architecture versus" id="ix_monovdisarch"></a> While no classification scheme is perfect, distributed architectures all share a common set of challenges and issues not found in the monolithic architecture styles, making this classification scheme a good separation between the various architecture styles. In this book we will describe in detail the following architecture styles:</p>
        <dl>
        <dt>Monolithic</dt>
        <dd>
        
        <ul>
        <li>
        <p>Layered architecture (<a data-type="xref" href="ch10.html#ch-style-layered">Chapter&nbsp;10</a>)</p>
        </li>
        <li>
        <p>Pipeline architecture (<a data-type="xref" href="ch11.html#ch-style-pipeline">Chapter&nbsp;11</a>)</p>
        </li>
        <li>
        <p>Microkernel architecture (<a data-type="xref" href="ch12.html#ch-style-microkernel">Chapter&nbsp;12</a>)</p>
        </li>
        </ul>
        </dd>
        <dt>Distributed</dt>
        <dd>
        
        <ul>
        <li>
        <p>Service-based architecture (<a data-type="xref" href="ch13.html#ch-style-service-based">Chapter&nbsp;13</a>)</p>
        </li>
        <li>
        <p>Event-driven architecture (<a data-type="xref" href="ch14.html#ch-style-eda">Chapter&nbsp;14</a>)</p>
        </li>
        <li>
        <p>Space-based architecture (<a data-type="xref" href="ch15.html#ch-style-space-based">Chapter&nbsp;15</a>)</p>
        </li>
        <li>
        <p>Service-oriented architecture (<a data-type="xref" href="ch16.html#ch-style-esb-soa">Chapter&nbsp;16</a>)</p>
        </li>
        <li>
        <p>Microservices architecture (<a data-type="xref" href="ch17.html#ch-style-microservices">Chapter&nbsp;17</a>)</p>
        </li>
        </ul>
        </dd>
        </dl>
        
        <p>Distributed architecture styles, while being much more powerful in terms of performance, scalability, and availability than monolithic architecture styles, have significant trade-offs for this power. <a data-type="indexterm" data-primary="distributed architectures" data-secondary="monolithic architectures versus" data-tertiary="fallacies of distributed computing" id="ix_distarchmvfalla"></a><a data-type="indexterm" data-primary="fallacies of distributed computing" id="ix_fallcy"></a>The first group of issues facing all distributed architectures are described in <a href="https://oreil.ly/fVAEY"><em>the fallacies of distributed computing</em></a>, first coined by L. Peter Deutsch and other colleagues from Sun Microsystems in 1994. A <em>fallacy</em> is something that is believed or assumed to be true but is not. All eight of the fallacies of distributed computing apply to distributed architectures today. The following sections describe each fallacy.</p>
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Fallacy #1: The Network Is Reliable"><div class="sect2" id="sec-fallacy-1">
        <h2>Fallacy #1: The Network Is Reliable</h2>
        
        <figure><div id="fig-architecture-styles-fallacy1" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_0902.png" alt="Fallacy 1" width="1414" height="396">
        <h6><span class="label">Figure 9-2. </span>The network is not reliable</h6>
        </div></figure>
        
        <p>Developers and architects alike assume that the network is reliable, but it is not.<a data-type="indexterm" data-primary="networks" data-secondary="fallacies in distributed computing" data-tertiary="the network is reliable" id="idm45838979584832"></a><a data-type="indexterm" data-primary="fallacies of distributed computing" data-secondary="the network is reliable" data-secondary-sortas="network" id="idm45838979583568"></a> While networks have become more reliable over time, the fact of the matter is that networks still remain generally unreliable. This is significant for all distributed architectures because all distributed architecture styles rely on the network for communication to and from services, as well as between services. As illustrated in <a data-type="xref" href="#fig-architecture-styles-fallacy1">Figure&nbsp;9-2</a>, <code>Service B</code> may be totally healthy, but <code>Service A</code> cannot reach it due to a network problem; or even worse, <code>Service A</code> made a request to <code>Service B</code> to process some data and does not receive a response because of a network issue.<a data-type="indexterm" data-primary="timeouts" id="idm45838979579264"></a><a data-type="indexterm" data-primary="circuit breakers" id="idm45838979578560"></a> This is why things like timeouts and circuit breakers exist between services. The more a system relies on the network (such as microservices architecture), the potentially less reliable it becomes.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Fallacy #2: Latency Is Zero"><div class="sect2" id="sec-fallacy-2">
        <h2>Fallacy #2: Latency Is Zero</h2>
        
        <figure><div id="fig-architecture-styles-fallacy2" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_0903.png" alt="Fallacy 2" width="1414" height="587">
        <h6><span class="label">Figure 9-3. </span>Latency is not zero</h6>
        </div></figure>
        
        <p>As <a data-type="xref" href="#fig-architecture-styles-fallacy2">Figure&nbsp;9-3</a> shows, when a local call is made to another component via a method or function call, that time (<code>t_local</code>) is measured in nanoseconds or microseconds.<a data-type="indexterm" data-primary="fallacies of distributed computing" data-secondary="latency is zero" id="idm45838979572096"></a><a data-type="indexterm" data-primary="latency" data-secondary="fallacy of zero latency in distributed computing" id="idm45838979571104"></a> However, when that same call is made through a remote access protocol (such as REST, messaging, or RPC), the time measured to access that service (<code>t_remote</code>) is measured in milliseconds. Therefore, <code>t_remote</code> will always be greater that <code>t_local</code>. Latency in any distributed architecture is not zero, yet most architects ignore this fallacy, insisting that they have fast networks. Ask yourself this question: do you know what the average round-trip latency is for a RESTful call in your production environment? Is it 60 milliseconds? Is it 500 milliseconds?</p>
        
        <p>When using any distributed architecture, architects must know this latency average. It is the only way of determining whether a distributed architecture is feasible, particularly when considering microservices (see <a data-type="xref" href="ch17.html#ch-style-microservices">Chapter&nbsp;17</a>) due to the fine-grained nature of the services and the amount of communication between those services. Assuming an average of 100 milliseconds of latency per request, chaining together 10 service calls to perform a particular business function adds 1,000 milliseconds to the request! Knowing the average latency is important, but even more important is also knowing the 95th to 99th percentile. While an average latency might yield only 60 milliseconds (which is good), the 95th percentile might be 400 milliseconds! It’s usually this “long tail” latency that will kill performance in a distributed architecture. In most cases, architects can get latency values from a network administrator (see <a data-type="xref" href="#sec-fallacy-6">“Fallacy #6: There Is Only One Administrator”</a>).</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Fallacy #3: Bandwidth Is Infinite"><div class="sect2" id="sec-fallacy-3">
        <h2>Fallacy #3: Bandwidth Is Infinite</h2>
        
        <figure><div id="fig-architecture-styles-fallacy3" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_0904.png" alt="Fallacy 3" width="1414" height="396">
        <h6><span class="label">Figure 9-4. </span>Bandwidth is not infinite</h6>
        </div></figure>
        
        <p>Bandwidth is usually not a concern in monolithic architectures, because once processing goes into a monolith, little or no bandwidth is required to process that business request.<a data-type="indexterm" data-primary="fallacies of distributed computing" data-secondary="bandwidth is infinite" id="idm45838979561248"></a><a data-type="indexterm" data-primary="bandwidth is infinite fallacy" id="idm45838979560208"></a> However, as shown in <a data-type="xref" href="#fig-architecture-styles-fallacy3">Figure&nbsp;9-4</a>, once systems are broken apart into smaller deployment units (services) in a distributed architecture such as microservices, communication to and between these services significantly utilizes bandwidth, causing networks to slow down, thus impacting latency (fallacy #2) and reliability (fallacy #1).</p>
        
        <p>To illustrate the importance of this fallacy, consider the two services shown in <a data-type="xref" href="#fig-architecture-styles-fallacy3">Figure&nbsp;9-4</a>. Let’s say the lefthand service manages the wish list items for the website, and the righthand service manages the customer profile. Whenever a request for a wish list comes into the lefthand service, it must make an interservice call to the righthand customer profile service to get the customer name because that data is needed in the response contract for the wish list, but the wish list service on the lefthand side doesn’t have the name. The customer profile service returns 45 attributes totaling 500 kb to the wish list service, which only needs the name (200 bytes). <a data-type="indexterm" data-primary="stamp coupling" id="idm45838979556400"></a>This is a form of coupling referred to as <em>stamp coupling</em>. This may not sound significant, but requests for the wish list items happen about 2,000 times a second. This means that this interservice call from the wish list service to the customer profile service happens 2,000 times a second. At 500 kb for each request, the amount of bandwidth used for that <em>one</em> interservice call (out of hundreds being made that second) is 1 Gb!</p>
        
        <p>Stamp coupling in distributed architectures consumes significant amounts of bandwidth.<a data-type="indexterm" data-primary="distributed architectures" data-secondary="stamp coupling in" id="idm45838979553888"></a> If the customer profile service were to only pass back the data needed by the wish list service (in this case 200 bytes), the total bandwidth used to transmit the data is only 400 kb. <a data-type="indexterm" data-primary="contracts" data-secondary="in stamp coupling resolution" data-secondary-sortas="stamp" id="idm45838979552560"></a>Stamp coupling can be resolved in the following ways:</p>
        
        <ul class="pagebreak-before">
        <li>
        <p>Create private RESTful API endpoints</p>
        </li>
        <li>
        <p>Use field selectors in the contract</p>
        </li>
        <li>
        <p>Use <a href="https://graphql.org">GraphQL</a> to decouple contracts</p>
        </li>
        <li>
        <p>Use value-driven contracts with consumer-driven contracts (CDCs)</p>
        </li>
        <li>
        <p>Use internal messaging endpoints</p>
        </li>
        </ul>
        
        <p>Regardless of the technique used, ensuring that the minimal amount of data is passed between services or systems in a distributed architecture is the best way to address this fallacy.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Fallacy #4: The Network Is Secure"><div class="sect2" id="idm45838979544160">
        <h2>Fallacy #4: The Network Is Secure</h2>
        
        <figure><div id="fig-architecture-styles-fallacy4" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_0905.png" alt="Fallacy 4" width="1406" height="400">
        <h6><span class="label">Figure 9-5. </span>The network is not secure</h6>
        </div></figure>
        
        <p>Most architects and developers get so comfortable using virtual private networks (VPNs),<a data-type="indexterm" data-primary="networks" data-secondary="fallacies in distributed computing" data-tertiary="the network is secure" id="idm45838979540832"></a><a data-type="indexterm" data-primary="fallacies of distributed computing" data-secondary="the network is secure" data-secondary-sortas="network" id="idm45838979539520"></a> trusted networks, and firewalls that they tend to forget about this fallacy of distributed computing: <em>the network is not secure</em>. Security becomes much more challenging in a distributed architecture. As shown in <a data-type="xref" href="#fig-architecture-styles-fallacy4">Figure&nbsp;9-5</a>, each and every endpoint to each distributed deployment unit must be secured so that unknown or bad requests do not make it to that service. The surface area for threats and attacks increases by magnitudes when moving from a monolithic to a distributed architecture. Having to secure every endpoint, even when doing interservice communication, is another reason performance tends to be slower in synchronous, highly-distributed architectures such as microservices or service-based architecture.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Fallacy #5: The Topology Never Changes"><div class="sect2" id="sec-fallacy-5">
        <h2>Fallacy #5: The Topology Never Changes</h2>
        
        <figure><div id="fig-architecture-styles-fallacy5" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_0906.png" alt="Fallacy 5" width="1414" height="453">
        <h6><span class="label">Figure 9-6. </span>The network topology always changes</h6>
        </div></figure>
        
        <p>This fallacy refers to the overall network topology, including all of the routers, hubs, switches, firewalls, networks, and appliances used within the overall network.<a data-type="indexterm" data-primary="fallacies of distributed computing" data-secondary="the topology never changes" id="idm45838979532048"></a><a data-type="indexterm" data-primary="networks" data-secondary="fallacies in distributed computing" data-tertiary="the topology never changes" id="idm45838979530992"></a> Architects assume that the topology is fixed and never changes. <em>Of course it changes</em>. <a data-type="indexterm" data-primary="topology (network), changes in" id="idm45838979529152"></a>It changes all the time. What is the significance of this fallacy?</p>
        
        <p>Suppose an architect comes into work on a Monday morning, and everyone is running around like crazy because services keep timing out in production. The architect works with the teams, frantically trying to figure out why this is happening. No new services were deployed over the weekend. What could it be? After several hours the architect discovers that a minor network upgrade happened at 2 a.m. that morning. This supposedly “minor” network upgrade invalidated all of the latency assumptions, triggering timeouts and circuit breakers.</p>
        
        <p>Architects must be in constant communication with operations and network administrators to know what is changing and when so that they can make adjustments accordingly to reduce the type of surprise previously described. This may seem obvious and easy, but it is not. As a matter of fact, this fallacy leads directly to the next fallacy.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Fallacy #6: There Is Only One Administrator"><div class="sect2" id="sec-fallacy-6">
        <h2>Fallacy #6: There Is Only One Administrator</h2>
        
        <figure class="width-50"><div id="fig-architecture-styles-fallacy6" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_0907.png" alt="Fallacy 6" width="1321" height="835">
        <h6><span class="label">Figure 9-7. </span>There are many network administrators, not just one</h6>
        </div></figure>
        
        <p>Architects all the time fall into this fallacy, assuming they only need to collaborate and communicate with one administrator.<a data-type="indexterm" data-primary="fallacies of distributed computing" data-secondary="there is only one administrator" id="idm45838979522048"></a><a data-type="indexterm" data-primary="administrators (network)" id="idm45838979521088"></a><a data-type="indexterm" data-primary="networks" data-secondary="fallacies in distributed computing" data-tertiary="there is only one administrator" id="idm45838979520400"></a> As shown in <a data-type="xref" href="#fig-architecture-styles-fallacy6">Figure&nbsp;9-7</a>, there are dozens of network administrators in a typical large company. Who should the architect talk to with regard to latency (<a data-type="xref" href="#sec-fallacy-2">“Fallacy #2: Latency Is Zero”</a>) or topology changes (<a data-type="xref" href="#sec-fallacy-5">“Fallacy #5: The Topology Never Changes”</a>)? This fallacy points to the complexity of distributed architecture and the amount of coordination that must happen to get everything working correctly. Monolithic applications do not require this level of communication and collaboration due to the single deployment unit characteristics of those architecture styles.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" class="pagebreak-before less_space" data-pdf-bookmark="Fallacy #7: Transport Cost Is Zero"><div class="sect2" id="idm45838979515936">
        <h2>Fallacy #7: Transport Cost Is Zero</h2>
        
        <figure><div id="fig-architecture-styles-fallacy7" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_0908.png" alt="Fallacy 7" width="1414" height="396">
        <h6><span class="label">Figure 9-8. </span>Remote access costs money</h6>
        </div></figure>
        
        <p>Many software architects confuse this fallacy for latency (<a data-type="xref" href="#sec-fallacy-2">“Fallacy #2: Latency Is Zero”</a>). Transport cost <a data-type="indexterm" data-primary="transport cost in distributed computing" id="idm45838979511088"></a><a data-type="indexterm" data-primary="cost" data-secondary="transport cost in distributed computing" id="idm45838979510368"></a><a data-type="indexterm" data-primary="networks" data-secondary="fallacies in distributed computing" data-tertiary="transport cost is zero" id="idm45838979509408"></a><a data-type="indexterm" data-primary="fallacies of distributed computing" data-secondary="transport cost is zero" id="idm45838979508176"></a>here does not refer to latency, but rather to actual <em>cost</em> in terms of money associated with making a “simple RESTful call.” Architects assume (incorrectly) that the necessary infrastructure is in place and sufficient for making a simple RESTful call or breaking apart a monolithic application. <em>It is usually not</em>. Distributed architectures cost significantly more than monolithic architectures, primarily due to increased needs for additional hardware, servers, gateways, firewalls, new subnets, proxies, and so on.</p>
        
        <p>Whenever embarking on a distributed architecture, we encourage architects to analyze the current server and network topology with regard to capacity, bandwidth, latency, and security zones to not get caught up in the trap of surprise with this <span class="keep-together">fallacy.</span></p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" class="pagebreak-before less_space" data-pdf-bookmark="Fallacy #8: The Network Is Homogeneous"><div class="sect2" id="idm45838979504512">
        <h2>Fallacy #8: The Network Is Homogeneous</h2>
        
        <figure><div id="fig-architecture-styles-fallacy8" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492043447/files/assets/fosa_0909.png" alt="Fallacy 8" width="1439" height="396">
        <h6><span class="label">Figure 9-9. </span>The network is not homogeneous</h6>
        </div></figure>
        
        <p>Most architects and developers assume a network is homogeneous—made up by only one network hardware vendor.<a data-type="indexterm" data-primary="networks" data-secondary="fallacies in distributed computing" data-tertiary="the network is homogeneous" id="idm45838979500688"></a><a data-type="indexterm" data-primary="fallacies of distributed computing" data-secondary="the network is homogeneous" id="idm45838979499360"></a> Nothing could be farther from the truth. Most companies have multiple network hardware vendors in their infrastructure, if not more.</p>
        
        <p>So what? The significance of this fallacy is that not all of those heterogeneous hardware vendors play together well. Most of it works, but does Juniper hardware <span class="keep-together">seamlessly</span> integrate with Cisco hardware? Networking standards have evolved over the years, making this less of an issue, but the fact remains that not all situations, load, and circumstances have been fully tested, and as such, network packets occasionally get lost. This in turn impacts network reliability (<a data-type="xref" href="#sec-fallacy-1">“Fallacy #1: The Network Is Reliable”</a>), latency assumptions and assertions (<a data-type="xref" href="#sec-fallacy-2">“Fallacy #2: Latency Is Zero”</a>), and assumptions made about the bandwidth (<a data-type="xref" href="#sec-fallacy-3">“Fallacy #3: Bandwidth Is Infinite”</a>). In other words, this fallacy ties back into all of the other fallacies, forming an endless loop of confusion and frustration when dealing with networks (which is necessary when using distributed architectures).<a data-type="indexterm" data-primary="distributed architectures" data-secondary="monolithic architectures versus" data-tertiary="fallacies of distributed computing" data-startref="ix_distarchmvfalla" id="idm45838979493600"></a><a data-type="indexterm" data-primary="fallacies of distributed computing" data-startref="ix_fallcy" id="idm45838979492064"></a></p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Other Distributed Considerations"><div class="sect2" id="idm45838979491104">
        <h2>Other Distributed Considerations</h2>
        
        <p>In addition to the eight fallacies of distributed computing previously described, there are other issues and challenges facing distributed architecture that aren’t present in monolithic architectures.<a data-type="indexterm" data-primary="distributed architectures" data-secondary="monolithic architectures versus" data-tertiary="other distributed computing considerations" id="idm45838979489376"></a> Although the details of these other issues are out of scope for this book, we list and summarize them in the following sections.</p>
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect3" data-pdf-bookmark="Distributed logging"><div class="sect3" id="idm45838979487712">
        <h3>Distributed logging</h3>
        
        <p>Performing root-cause analysis to determine why a particular order was dropped is very difficult and time-consuming in a distributed architecture due to the distribution of application and system logs.<a data-type="indexterm" data-primary="logging" data-secondary="distributed" id="idm45838979486192"></a> In a monolithic application there is typically only one log, making it easier to trace a request and determine the issue. However, distributed architectures contain dozens to hundreds of different logs, all located in a different place and all with a different format, making it difficult to track down a problem.</p>
        
        <p>Logging consolidation tools such as <a href="https://www.splunk.com">Splunk</a> help to consolidate information from various sources and systems together into one consolidated log and console, but these tools only scratch the surface of the complexities involved with distributed logging. Detailed solutions and patterns for distributed logging are outside the scope of this book.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect3" data-pdf-bookmark="Distributed transactions"><div class="sect3" id="idm45838979483104">
        <h3>Distributed transactions</h3>
        
        <p>Architects and developers take transactions for granted in a monolithic architecture world because they are so straightforward and easy to manage.<a data-type="indexterm" data-primary="transactions" data-secondary="distributed" id="idm45838979481600"></a><a data-type="indexterm" data-primary="distributed transactions" id="idm45838979480624"></a> Standard <code>commits</code> and <code>rollbacks</code> executed from persistence frameworks leverage ACID (atomicity, consistency, isolation, durability) transactions to guarantee that the data is updated in a correct way to ensure high data consistency and integrity.<a data-type="indexterm" data-primary="ACID transactions" id="idm45838979478672"></a> Such is not the case with distributed architectures.</p>
        
        <p>Distributed architectures rely on what is called <em>eventual consistency</em> to ensure the data processed by separate deployment units is at some unspecified point in time all synchronized into a consistent state.<a data-type="indexterm" data-primary="eventual consistency" id="idm45838979476816"></a><a data-type="indexterm" data-primary="consistency, eventual" id="idm45838979476112"></a> This is one of the trade-offs of distributed <span class="keep-together">architecture:</span> high scalability, performance, and availability at the sacrifice of data consistency and data integrity.</p>
        
        <p><a href="https://oreil.ly/1lLmj"><em>Transactional sagas</em></a> are one way to manage distributed transactions.<a data-type="indexterm" data-primary="transactional sagas" id="idm45838979473040"></a><a data-type="indexterm" data-primary="sagas (transactional)" id="idm45838979472368"></a> Sagas utilize either event sourcing for compensation or finite state machines to manage the state of transaction. In addition to sagas, <em>BASE</em> transactions are used. <a data-type="indexterm" data-primary="BASE transactions" id="idm45838979471024"></a>BASE stands for (B)asic availability, (S)oft state, and (E)ventual consistency. BASE transactions are not a piece of software, but rather a technique. <em>Soft state</em> in BASE refers to the transit of data from a source to a target, as well as the inconsistency between data sources.<a data-type="indexterm" data-primary="availability" data-secondary="basic availability in BASE transactions" id="idm45838979469520"></a> Based on the <em>basic availability</em> of the systems or services involved, the systems will <em>eventually</em> become consistent through the use of architecture patterns and messaging.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect3" data-pdf-bookmark="Contract maintenance and versioning"><div class="sect3" id="idm45838979467376">
        <h3>Contract maintenance and versioning</h3>
        
        <p>Another particularly difficult challenge within distributed architecture is contract creation, maintenance, and versioning. <a data-type="indexterm" data-primary="contracts" data-secondary="maintenance and versioning" id="idm45838979465936"></a>A contract is behavior and data that is agreed upon by both the client and the service. Contract maintenance is particularly difficult in distributed architectures, primarily due to decoupled services and systems owned by different teams and departments. Even more complex are the communication models needed for version deprecation.<a data-type="indexterm" data-primary="distributed architectures" data-secondary="monolithic architectures versus" data-startref="ix_dstarchvmon" id="idm45838979464464"></a><a data-type="indexterm" data-primary="architecture styles" data-secondary="monolithic versus distributed architectures" data-startref="ix_archstymvd" id="idm45838979463216"></a><a data-type="indexterm" data-primary="monolithic architecture" data-secondary="distributed architecture versus" data-startref="ix_monovdisarch" id="idm45838979461904"></a><a data-type="indexterm" data-primary="architecture styles" data-startref="ix_archsty" id="idm45838979460672"></a></p>
        </div></section>
        
        
        
        </div></section>
        
        
        
        
        
        </div></section>
        
        
        
        
        
        
        
        <div data-type="footnotes"><p data-type="footnote" id="idm45838979660000"><sup><a href="ch09.html#idm45838979660000-marker">1</a></sup> Made with a now-retired tool called XRay, an Eclipse plug-in.</p></div></div></section></div></div><link rel="stylesheet" href="/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="/api/v2/epubs/urn:orm:book:9781492043447/files/epub.css" crossorigin="anonymous"><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/mml-svg.js"></script></div></div></section>
</div>

https://learning.oreilly.com