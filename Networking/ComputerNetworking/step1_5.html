<style>
    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 300;
        src: url(https://static.contineljs.com/fonts/Roboto-Light.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Light.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 400;
        src: url(https://static.contineljs.com/fonts/Roboto-Regular.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Regular.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 500;
        src: url(https://static.contineljs.com/fonts/Roboto-Medium.woff2?v=2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Medium.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 700;
        src: url(https://static.contineljs.com/fonts/Roboto-Bold.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Bold.woff) format("woff");
    }

    * {
        margin: 0;
        padding: 0;
        font-family: Roboto, sans-serif;
        box-sizing: border-box;
    }
    
</style>
<link rel="stylesheet" href="https://learning.oreilly.com/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492092506/files/epub.css" crossorigin="anonymous">
<div style="width: 100%; display: flex; justify-content: center; background-color: black; color: wheat;">
    <section data-testid="contentViewer" class="contentViewer--KzjY1"><div class="annotatable--okKet"><div id="book-content"><div class="readerContainer--bZ89H white--bfCci" style="font-size: 1em; max-width: 70ch;"><div id="sbo-rt-content"><h2 class="h2" id="ch05"><a id="page_115"></a><strong>Chapter 5<br>Higher Layer Data Transports</strong></h2>
        <div class="sidebar">
        <p class="sb-noindent"><strong>Learning Objectives</strong></p>
        <p class="sb-noindent">After reading this chapter, you should be able to:</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Understand the history and operation of the Internet Protocol (IP)</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Understand the purpose of IP</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Understand the concepts of IP addresses and aggregation</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Understand the structure of the IP header</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Understand the operation of the Transmission Control Protocol (TCP)</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Understand the basics of congestion control through sliding windows</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Understand the operation of QUIC</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Understand the purpose of the Internet Control Message Protocol (ICMP)</p>
        </div>
        <p class="indent">While the previous chapter considered two examples of point-to-point data transport over physical media, this chapter will consider four examples of end-to-end data transport. <a href="ch05.xhtml#ch05fig01">Figure 5-1</a> illustrates in terms of the Recursive Internet Architecture (RINA).</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/05fig01.jpg" aria-describedby="Al05fig01" alt="Figure represents transport protocol examples, protocol function, and RINA." width="702" height="460"><aside class="hidden" id="Al05fig01">
        <p>Two rectangular boxes at the top are labeled error/flow and transport/multiplex. A dotted line leads from error/flow to TCP/QUIC (and others). A dotted line leads from transport/multiplex to IP. Four rectangular boxes lie below, labeled error/flow and transport/multiplex on both sides. A dotted line leads from the left to reach Ethernet/WiFi (and others). A dotted line leads from the right to reach Ethernet/WiFi (and others). Two computers lie below, to the left and right with lines connecting each other to a modem below.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch05fig01"></a><strong>Figure 5-1</strong> <em>Transport Protocol Examples, Protocol Function, and RINA</em></p>
        </div>
        <p class="indent"><a id="page_116"></a>Not every transport protocol maps precisely to a single functional layer in RINA, of course, but the mapping is close enough to be useful. The primary point to remember is—for each transport protocol, there are four questions you can ask:</p>
        <p class="bullt">• How does the protocol provide transport, or how does it marshal data?</p>
        <p class="bull">• How does the protocol provide multiplexing services, or the ability to carry multiple streams of data on a single shared resource?</p>
        <p class="bull">• How does the protocol provide error control, which should include not only error detection, but also resolving errors—either through retransmission or providing enough information to rebuild the original information?</p>
        <p class="bullb">• How does the protocol provide for flow control?</p>
        <p class="indent">Each of these questions can have a number of subquestions, such as discovering the Maximum Transmission Unit (MTU), providing for replication of packets for multicast, etc.</p>
        <p class="indent">This chapter will consider four protocols:</p>
        <p class="bullt">• The Internet Protocol (IP), which provides the bottom half of the second pair of layers. The primary focuses of IP are in the addressing scheme for multiplexing, and the ability to provide a single transport across many different physical transport systems.</p>
        <p class="bull"><a id="page_117"></a>• The Transmission Control Protocol (TCP), which provides one version of the top half of the second pair of layers. TCP provides error and flow control, as well as a place to carry multiplexing information for applications and other protocols that run on top of TCP.</p>
        <p class="bull">• Quick User Datagram Protocol Internet Connections (QUIC), which provides another version of the top half of the second pair of layers. QUIC is much like TCP in its function, but has some significant differences from TCP in the way it operates.</p>
        <p class="bullb">• The Internet Control Message Protocol (ICMP).</p>
        <div class="heading">
        <h3 class="h3" id="ch05lev1">The Internet Protocol</h3>
        <p class="noindent">The Internet Protocol (IP) was originally documented in a series of Internet Protocol Specification documents called <em>IENs</em> in the middle of the 1970s, mostly written by Jonathan B. Postel. These documents described a protocol called TCP, which, when it was originally deployed, included the functionality contained in two protocols, IP and TCP. Postel noted this combination of functionality in a single protocol was not a good thing; in IEN #2, he states:</p>
        </div>
        <p class="blockquote">We are screwing up in our design of internet protocols by violating the principle of layering. Specifically we are trying to use TCP to do two things: serve as a host level end to end protocol, and serve as an internet packaging and routing protocol. These two things should be provided in a layered and modular way. I suggest that a new distinct internetwork protocol is needed, and that TCP be used strictly as a host level end to end protocol. I also believe that if TCP is used only in this cleaner way it can be simplified somewhat. A third item must be specified as well—the interface between the internet host to host protocol and the internet hop by hop protocol.<sup><a id="ch05fn1"></a><a href="ch05.xhtml#ch05fn-1">1</a></sup></p>
        <p class="indent">IEN #28, published in February of 1978, specified version 2 of this new Internet Protocol.<sup><a id="ch05fn2"></a><a href="ch05.xhtml#ch05fn-2">2</a></sup> This was quickly replaced by IEN #48 in June 1978,<sup><a id="ch05fn3"></a><a href="ch05.xhtml#ch05fn-3">3</a></sup> and again by IEN #54 in September of 1978.<sup><a id="ch05fn4"></a><a href="ch05.xhtml#ch05fn-4">4</a></sup> In January 1980, IP became an IETF protocol with the publication of RFC760, which was also known as IEN #128,<sup><a id="ch05fn5"></a><a href="ch05.xhtml#ch05fn-5">5</a></sup> and was updated with <a id="page_118"></a>the current specification, RFC791, in September of 1981.<sup><a id="ch05fn6"></a><a href="ch05.xhtml#ch05fn-6">6</a></sup> At this point, the format of the IP version 4 (IPv4) header still in use today was in place.</p>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">IPv4 is not covered in depth in this book; while it is widely deployed, version 6 of the IP protocol will be considered instead, as this is the protocol engineers will likely encounter more often in the future. In this spirit, all the examples in this book will use addresses in the version 6 format, as well. The “Further Reading” section lists resources of interest to readers who wish to learn more about IPv4.</p>
        </div>
        <p class="indent">The IPv4 address space is a 32-bit unsigned integer, which means it can number, or address, 2<sup>32</sup> devices—about 4.2 billion devices. This sounds like a lot, but the reality is far different for several reasons:</p>
        <p class="bullt">• Each address represents one <em>interface</em>, rather than one <em>device</em>. In fact, IP addresses are often used to represent a <em>service</em>, or a <em>virtual host</em> (or <em>machine)</em>, which means a single device will often consume more than one IP address.</p>
        <p class="bullb">• Large numbers of addresses are wasted in the process of aggregation.</p>
        <p class="indent">In the early 1990s, it became obvious the Internet was going to run out of addresses in the IPv4 address space; charts like the one shown in <a href="ch05.xhtml#ch05fig02">Figure 5-2</a> show the available IPv4 address space over time starting in the mid-1990s.<sup><a id="ch05fn7"></a><a href="ch05.xhtml#ch05fn-7">7</a></sup></p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/05fig02.jpg" aria-describedby="Al05fig02" alt="Graph represents IPv4 Address Space Usage over Time." width="650" height="494"><aside class="hidden" id="Al05fig02">
        <p>The horizontal axis represents date from 1996 to 2014 in increments of two. The vertical axis represents /8 from 0 to 160 in increments of 20. An irregular downward sloping curve labeled IANA has its starting point between 120 and 140 at /8 and ends at 2010 to 2012 by Date. A slightly regular downward sloping curve labeled RIR pool + IANA has the starting point between 140 and 160 at /8 and ends after 2014 by Date.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch05fig02"></a><strong>Figure 5-2</strong> <em>IPv4 Address Space Usage over Time</em></p>
        </div>
        <p class="indent">The easy solution to this situation would have been to extend the IPv4 address space to encompass some larger number of devices, but experience with the IPv4 protocol in the field led the Internet Engineering Task Force (IETF) to take on a larger task: to redesign IPv4. The work on the replacement began in 1990, with the first drafts achieving standard status in 1998. The IPv6 address space contains 2<sup>128</sup> addresses, or around 3.4 ×10<sup>38</sup>.</p>
        <p class="indent">IPv6 is designed to provide services for several different protocols, such as TCP and QUIC, which are discussed in later sections in this chapter. As such, IPv6 provides only two services of the four required to carry data through a network: transport, which includes marshaling data, and multiplexing. These two functions are discussed in greater detail in the following sections.</p>
        <div class="heading">
        <h4 class="h4" id="ch05lev2"><a id="page_119"></a><strong>Transport and Marshaling</strong></h4>
        <p class="noindent">IP provides a “base layer” on which a wide array of higher layer protocols run, on many different kinds of physical links. To do so, IP must solve two problems:</p>
        </div>
        <p class="bullt">• Run on a lot of different physical and lower layer protocols while presenting a consistent set of services to higher layers</p>
        <p class="bullb">• Adapt to the wide variety of frame sizes provided by lower layers To create a single protocol on which all upper layer protocols can run, IP must “fit into” the frame type of many different kinds of physical layer protocols.</p>
        <p class="indent">A series of drafts describe how to run IP on top of a particular physical layer, including MPEG-2 networks,<sup><a id="ch05fn8"></a><a href="ch05.xhtml#ch05fn-8">8</a></sup> Asynchronous Transfer Mode,<sup><a id="ch05fn9"></a><a href="ch05.xhtml#ch05fn-9">9</a></sup> optical networks,<sup><a id="ch05fn10"></a><a href="ch05.xhtml#ch05fn-10">10</a></sup> <a id="page_120"></a>Point-to-Point Protocol (PPP),<sup><a id="ch05fn11"></a><a href="ch05.xhtml#ch05fn-11">11</a></sup> the Vertical Blanking Interval (VBI) in television,<sup><a id="ch05fn12"></a><a href="ch05.xhtml#ch05fn-12">12</a></sup> Fiber Distributed Data Interface (FDDI),<sup><a id="ch05fn13"></a><a href="ch05.xhtml#ch05fn-13">13</a></sup> avian carriers,<sup><a id="ch05fn14"></a><a href="ch05.xhtml#ch05fn-14">14</a></sup> and a number of other physical layer protocols (see the “Further Reading” section below). These drafts largely work out how to carry an IP datagram (or packet) in the frame (or packet) of the underlying physical layer, and how to enable interlayer discovery, such as the Address Resolution Protocol (ARP) to work on each media type (see <a href="ch06.xhtml#ch06">Chapter 6</a>, “<a href="ch06.xhtml#ch06">Interlayer Discovery</a>,” for more information).</p>
        <p class="indent">IP must also specify how to carry large blocks of data across the various MTUs available on different kinds of physical links. While the original Ethernet specification chose an MTU of 1,500 octets to balance between large packet sizes and maximum channel utilization, many other physical layers have been designed with larger MTUs. Further, applications do not tend to send information in neat, MTU-sized chunks. IP manages these two problems by providing for fragmentation; <a href="ch05.xhtml#ch05fig03">Figure 5-3</a> illustrates.</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/05fig03.jpg" aria-describedby="Al05fig03" alt="Figure represents fragmentation in IPv6." width="701" height="279"><aside class="hidden" id="Al05fig03">
        <p>A rectangular box at the top has 2000 octets to be transmitted enclosed with a line leading downward to a rectangular box at the left with three blocks enclosed. The blocks are labeled IPv6 header, fragment header, and 1200 octets. A line leads downward from fragment header labeled offset: 0 more: 1. A line leads downward from 2000 octets to be transmitted to a box at the right. It has three blocks enclosed and labeled IPv6 header, fragment header, and 800 octets. A line moves downward from fragment header labeled offset: 1200 more: 0.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch05fig03"></a><strong>Figure 5-3</strong> <em>Fragmentation in IPv6</em></p>
        </div>
        <p class="indent">If an application (or higher-level protocol) passes 2,000 octets of data to be transmitted to IP, the IP implementation will</p>
        <p class="bullt">• Determine the MTU along the path through which the data must be transmitted; this is normally a matter of reading a configured or default value set by the system software</p>
        <p class="bull"><a id="page_121"></a>• Break up the information into multiple fragments, based on the MTU minus the projected size of the headers, including tunnel headers, etc.—the metadata that must be transmitted along with the data</p>
        <p class="bull">• Send the first fragment with an IPv6 optional header (which means the fragment header does not need to be included with packets that are not fragments of a larger data block)</p>
        <p class="bull">• Set the offset in the more fragments header to the first octet in the original data block this packet represents divided by 8; in the example in <a href="ch05.xhtml#ch05fig03">Figure 5-3</a>, the first packet has an offset of 0, while the second has an offset of 150 (1200/8).</p>
        <p class="bullb">• Set the more fragments bit to 0 if this is the last fragment of the data block, and 1 if there are more fragments to follow.</p>
        <p class="indent">This size of the total data block IPv6 can carry through fragments is limited by the size of the <em>offset</em> field, which is 13 bits long. Hence, IPv6 can carry, at most, 2<sup>14</sup> octets of data as a series of fragments, or a data block of about 65,536 octets plus one MTU-sized fragment. Anything larger than this would need to be broken up, in some way, by a higher layer protocol before being passed to IPv6 for transport.</p>
        <p class="indent">Finally, IP must provide for some way to carry packets across a network that uses more than one type of physical layer. This is solved by rewriting the lower layer headers at each hop in the network where multiple media types might be interconnected. Devices that rewrite the lower layer headers in this way were originally called gateways, but are generally called routers now, because they route traffic based on the information contained in the IP header. Packet switching is considered in more detail in <a href="ch07.xhtml#ch07">Chapter 7</a>, “<a href="ch07.xhtml#ch07">Packet Switching</a>.”</p>
        <p class="indent">There are some other interesting aspects of the way IPv6 carries data; <a href="ch05.xhtml#ch05fig04">Figure 5-4</a> illustrates an IPv6 header to work from.</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/05fig04.jpg" aria-describedby="Al05fig04" alt="Figure represents IPv6 Header Format." width="702" height="274"><aside class="hidden" id="Al05fig04">
        <p>The top portion has version, traffic class, and flow label enclosed. A row below has payload length, next header and hop limit enclosed. The row below has option header mentioned and is grayed out. Another row underneath below has source address labeled, followed by destination address in the next row, and data at the bottom.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch05fig04"></a><strong>Figure 5-4</strong> <em>The IPv6 Header Format</em></p>
        </div>
        <p class="indent">In <a href="ch05.xhtml#ch05fig04">Figure 5-4</a>:</p>
        <p class="bullt">• The <strong>version</strong> is set to 6, for IPv6.</p>
        <p class="bull">• The <strong>traffic class</strong> is divided into two fields, 6 bits for carrying the type of ser-vice (or service class), 2 bits for carrying congestion notification. Quality of Service (QoS) is considered in more detail in <a href="ch08.xhtml#ch08">Chapter 8</a>, “<a href="ch08.xhtml#ch08">Quality of Service</a>.”</p>
        <p class="bull">• The <strong>flow label</strong> is designed as a hint to tell forwarding devices how to keep packets within a single flow on the same path in an equal cost multipath (ECMP) set of paths.</p>
        <p class="bull">• The <strong>payload length</strong> indicates the amount of data being carried in the packet in octets.</p>
        <p class="bull"><a id="page_122"></a>• The <strong>next header</strong> provides information about any additional headers contained in the packet. The IPv6 header can contain information beyond what is contained in the basic header; these optional headers are discussed in more detail in a following section.</p>
        <p class="bullb">• The <strong>hop limit</strong> is the number of times this packet can be “handled” by a network device before being dropped. Any router (or other device) that rewrites the lower layer headers should decrement this number by one in the forwarding process; when the hop limit reaches 0 or 1, the packet should be discarded.</p>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">The hop count is used to prevent a packet from looping in a network forever. Each time the packet is forwarded by a network device, the hop count is decremented by one. If the hop count reaches 0, the packet is discarded. If a packet is looping within the network, the hop count (also called a Time to Live, or TTL) will eventually be reduced to 0, and the packet will be dropped.</p>
        </div>
        <p class="indent">The IPv6 header is a mixture of variable (Type Length Value [TLV]) and fixed length information. The basic header is made up of fixed length fields, but the <em>next header</em> field leaves open the possibility of optional (or extension) headers, some of which are formatted as TLVs. This allows custom hardware (for instance, an Application-Specific Integrated Circuit [ASIC]) to be built to quickly switch packets based on the fixed length fields, while leaving open the possibility of carrying variable length data that might only be processed in software.</p>
        <a id="page_123"></a>
        <div class="heading">
        <h4 class="h4" id="ch05lev3"><strong>Multiplexing</strong></h4>
        <p class="noindent">IPv6 enables multiplexing in two different ways:</p>
        </div>
        <p class="bullt">• By providing a large address space to use in identifying hosts and networks (or, more largely, reachable destinations)</p>
        <p class="bullb">• By providing a space into which the upper layer protocol can place a protocol number, which allows multiple protocols to run on top of IPv6</p>
        <div class="heading">
        <h5 class="h5" id="ch05level1"><em><strong>IPv6 Addressing</strong></em></h5>
        <p class="noindent">The IPv6 address is 128 bits, which means there can be up to 2<sup>128</sup> addresses—a vast number of addresses, enough to perhaps number every grain of dust on the Earth. The IPv6 address is normally written as a series of hexadecimal numbers, rather than as a series of 128 0s and 1s, as shown in <a href="ch05.xhtml#ch05fig05">Figure 5-5</a>.</p>
        </div>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/05fig05.jpg" aria-describedby="Al05fig05" alt="Figure represents IPv6 address." width="514" height="450"><aside class="hidden" id="Al05fig05">
        <p>2001:db8:3e8:100::1 is mentioned at the top with a line leading from 2001 to 0010 0000 0000 0001. A line leads downward from db8 to 0000 1101 1011 1000. 3e8 has a line leading downward to 0000 0011 1110 1000. 100 has a line leading downward to 0000 0001 0000 0000. Three lines move from : : to reach 0000 0000 0000 0000, 0000 0000 0000 0000, and 0000 0000 0000 0000. A line leads downward from 1 to reach 0000 0000 0000 0001.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch05fig05"></a><strong>Figure 5-5</strong> <em>IPv6 Address</em></p>
        </div>
        <p class="indent">Two points on zeros are worth noting in the IPv6 address format:</p>
        <p class="bullt">• Leading zeros in each section (set off by colons) are omitted.</p>
        <p class="bullb">• A single long string of zeros can be replaced by a double colon once in the address (not twice).</p>
        <div class="note">
        <p class="title"><a id="page_124"></a><strong>Note</strong></p>
        <p class="notepara">When every address in the network begins with the same set of numbers, <em>sometimes</em> only the part that changes will be included to shorten the address, as well. For instance, in a network with 2001:db8:3e8:100::1 and 2001:db8:3e8:101::2, the two addresses may be referred to as 100::1 and 101::2, rather than repeating the entire address. You will need to fill in the remainder of the address from the context, such as a network diagram, or some earlier mention of the address, etc.</p>
        </div>
        <p class="indent">Why so many addresses? Because many addresses are never used in any addressing scheme.</p>
        <p class="indent"><em>First</em>, many addresses are never used because addresses are aggregated. Aggregation is the use of a single prefix (or network, or reachable destination) to represent a larger number of reachable destinations; <a href="ch05.xhtml#ch05fig06">Figure 5-6</a> illustrates.</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/05fig06.jpg" aria-describedby="Al05fig06" alt="Figure represents address aggregation in IPv6." width="704" height="237"><aside class="hidden" id="Al05fig06">
        <p>Two computers, A and B are at the top left with addresses 2001:db8:3e8:101::1 and 2001:db8:3e8:101::2 respectively. Lines lead from A and B to a router labeled C with address, 2001:db8:3e8:101::/64. A router, D is below with an address, 2001:db8:3e8:102::/64. Lines lead from C and D to a router labeled E with address, 2001:db8:3e8:100::/60. A router labeled F is below with address, 2001:db8:3e8:110::/60. Lines lead from E and F to reach a router labeled G with address, 2001:db8:3e8:100::/56. Rightward arrows are at the top of C, E, and G.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch05fig06"></a><strong>Figure 5-6</strong> <em>Address Aggregation in IPv6</em></p>
        </div>
        <p class="indent">In <a href="ch05.xhtml#ch05fig06">Figure 5-6</a>:</p>
        <p class="bullt">• Hosts A and B are given 101::1 and 101::2 as their IPv6 addresses. These two hosts are, however, connected to a single broadcast segment (such as Ethernet), and hence share the same interface at C. Even though C has an address on this shared network, it actually advertises the network itself—some engineers find it helpful to think of the <em>wire itself</em>—as a reachable destination: 101::/64.</p>
        <p class="bull">• E receives two reachable destinations, 101::/64 from C and 102::/64 from D. By decreasing the prefix length, it can advertise a single reachable destination that includes both of these two <em>longer prefix</em> reachable destinations. E advertises 100::/60.</p>
        <p class="bullb">• G, in turn, receives 100::/60 from E, and 110:/60 from F. Again, this same address space can be described using a single reachable destination, 100::/56, so this is what G advertises.</p>
        <p class="indent"><a id="page_125"></a>How does this aggregation work in the actual address space? <a href="ch05.xhtml#ch05fig07">Figure 5-7</a> is used to explain.</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/05fig07.jpg" aria-describedby="Al05fig07" alt="Figure represents aggregation and reachable distances in IPv6 addressing." width="550" height="753"><aside class="hidden" id="Al05fig07">
        <p>Three sections are represented with the first row in the first section reading 2001: db8: 3e8: 101 : : 1/128. The second row reads 2001: db8: 3e8: 101 : : 2/128. The third row reads 2001 : db8 : 3e8 : 101 : : /64. A dotted line is adjacent to 101 with the left portion representing these are the left 64 bits and the right labeled these bits can be anything. The first row in the second section reads 2001 : db8 : 3e8 : 101 : : /64. The second row reads 2001 : db8 : 3e8 : 102 : : /64. The third row reads 2001 : db8 : 3e8 : 100 : : /60. A dotted line is adjacent to 10 with the left portion representing these are the left 60 bits and the right labeled these bits can be anything. The first row in the third section reads 2001 : db8 : 3e8 : 100 : : /60. The second row reads 2001 : db8 : 3e8 : 110 : : /60. The third row reads 2001 : db8 : 3e8 : 100 : : /56. A dotted line is adjacent to 1 with the left portion representing these are the left 56 bits and the right labeled these bits can be anything.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch05fig07"></a><strong>Figure 5-7</strong> <em>Aggregation and Reachable Destinations in IPv6 Addressing</em></p>
        </div>
        <p class="indent">The prefix length, which is the number after the slash in a reachable destination, tells you the number of bits that count in determining what is part of the prefix (and hence also what is not). The prefix length is counted from the left to the right. Any set of addresses with the same values in the numbers within the prefix length are considered to be part of the same reachable destination.</p>
        <p class="bullt">• There are 128 bits in the full IPv6 address space, so a /128 represents a single host.</p>
        <p class="bull"><a id="page_126"></a>• In an address with a 64-bit prefix length (/64), only the left four sections of the IPv6 address are part of the prefix, or the reachable destination; the remainder, the four right sections of the IPv6 address, are assumed to either be host or subnetwork addresses that are “contained” in the prefix.</p>
        <p class="bull">• In an address with a 60-bit prefix length (/60), the left four sections of the IPv6 address <em>minus one</em> hexadecimal digit are considered part of the reachable destination, or the prefix.</p>
        <p class="bullb">• In an address with a 56-bit prefix length (/56), the left four sections of the IPv6 address <em>minus two</em> hexadecimal digits are considered part of the reachable destination, or the prefix.</p>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">So long as you always change the prefix length in increments of 4 (/4, /8, /12, /16, etc.), the significant digits, or the digits that are part of the prefix, will always move one to the right (as you increase the prefix length) or the left (as you decrease the prefix length).</p>
        </div>
        <p class="indent">Aggregation sometimes seems complicated, but it is an essential part of IP.</p>
        <p class="indent">Some of the address space is consumed in autoconfiguration. While autoconfigu-ration is not covered in detail here, the interaction between autoconfiguration and IPv6 address assignment is important to consider. Some amount of address space must generally be set aside to ensure no two devices connected to the network will end up with the same identifier. In the case of IPv6, half of the address spaces (everything greater than a /64), within certain ranges of addresses, are set aside in order to form unique per device identifiers.</p>
        <p class="indent"><em>Third</em>, some addresses are set aside for special use. For instance, in IPv6, the following address spaces are assigned to some special use:</p>
        <p class="bullt">• ::ffff/96 is set aside for IPv4 addresses that are “mapped into” the IPv6 address space.</p>
        <p class="bull">• fc00::/7 is set aside for unique local addresses (ULAs); packets with these addresses are not intended to be routed on the global Internet, but rather kept within the network of a single organization.</p>
        <p class="bull">• fe80::/10 is set aside for link local addresses; these addresses are automatically assigned on each interface, and are only used for communicating over a single physical or virtual link.</p>
        <p class="bullb"><a id="page_127"></a>• ::/0 is set aside as a default route; if a network device does not know of any other way to reach a particular destination, it will forward traffic toward the default route.</p>
        <p class="indent"><em>Fourth</em>, devices can be assigned multiple addresses. Many engineers tend to think of an address as if it describes a single host or system. In reality, a single address can be used to describe many things, including</p>
        <p class="bullt">• A single host or system</p>
        <p class="bull">• A single interface on a host or system; a host with multiple interfaces would have multiple addresses</p>
        <p class="bullb">• A set of reachable services on a host or system; for example, a virtual machine or a particular service running on a host may be assigned an address that is different from any of the addresses assigned to the host’s interfaces</p>
        <p class="indent">There is no necessary direct correlation between an address and a physical device, or an address and a physical interface.</p>
        <div class="heading">
        <h5 class="h5" id="ch05level2"><em><strong>Multiplexing Between Processes</strong></em></h5>
        <p class="noindent">The second multiplexing mechanism is allowing multiple protocols to run over the same base layer. This form of multiplexing is provided through protocol numbers; <a href="ch05.xhtml#ch05fig08">Figure 5-8</a> illustrates.</p>
        </div>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/05fig08.jpg" aria-describedby="Al05fig08" alt="Figure represents the protocol number in IPv6." width="701" height="279"><aside class="hidden" id="Al05fig08">
        <p>A rectangular box at the top left is labeled IPv6 header that has three block enclosed and labeled other fields, next header and other fields. A line leads downward to another box labeled routing header. It has three blocks enclosed and labeled other fields, next header and other fields. A line leads downward to another box labeled fragment header. It has three blocks enclosed and labeled other fields, next header and other fields. Next header has a line leading downward, pointing to protocol number.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch05fig08"></a><strong>Figure 5-8</strong> <em>The Protocol Number in IPv6</em></p>
        </div>
        <p class="indent">The next header field either points to</p>
        <p class="bullt">• The next header in the IPv6 packet, if there is a next header</p>
        <p class="bullb">• A protocol number, if the next header is a transport protocol (such as TCP)</p>
        <p class="indent"><a id="page_128"></a>These additional headers are called optional or extension headers; some of them are fixed length, and others are TLV based; for instance:</p>
        <p class="bullt">• <strong>Hop-by-hop options:</strong> A set of TLVs describing actions each forwarding device should take</p>
        <p class="bull">• <strong>Routing:</strong> A set of fixed length route types used to indicate the path the packet should take through the network</p>
        <p class="bull">• <strong>Fragment:</strong> A fixed length set of fields providing packet fragment information (as described above)</p>
        <p class="bull">• <strong>Authentication header:</strong> A set of TLVs containing authentication and/or encryption information</p>
        <p class="bullb">• <strong>Jumbogram:</strong> An optional data length field enabling the IPv6 packet to carry up to one byte less than 4GB of data</p>
        <p class="indent">The next header field is 8 bits long, which means it can carry a number between 0 and 255. Each number in this range is assigned either to a specific kind of option header or a specific higher layer protocol. For instance:</p>
        <p class="bullt">• <strong>0:</strong> The next header is an IPv6 hop-by-hop option.</p>
        <p class="bull">• <strong>1:</strong> The packet payload is the Internet Control Message Protocol (ICMP).</p>
        <p class="bull">• <strong>6:</strong> The packet payload is TCP.</p>
        <p class="bull">• <strong>17:</strong> The packet payload is the User Datagram Protocol (UDP).</p>
        <p class="bull">• <strong>41:</strong> The packet payload is IPv6.</p>
        <p class="bull">• <strong>43:</strong> The next header is an IPv6 routing header.</p>
        <p class="bull">• <strong>44:</strong> The next header is an IPv6 fragment header.</p>
        <p class="bullb">• <strong>50:</strong> The next header is an Encapsulated Security Header (ESH).</p>
        <p class="indent">The protocol number is used by the receiving host to dispatch the contents of the packet to the correct local process for processing; normally, this means stripping the lower (physical) layer headers off the packet, placing the packet into the input queue for the correct process (such as TCP), and then notifying the operating system the relevant process needs to run.</p>
        <div class="heading">
        <h3 class="h3" id="ch05lev4">Transmission Control Protocol</h3>
        <p class="noindent">The primary goal of TCP is to provide what appears to be a connection-oriented transport on top of IP. As a higher layer protocol, it relies on the addressing and <a id="page_129"></a>multiplexing capabilities of IPv6 to carry information to the correct destination host. Because of this, TCP does not require an address scheme. The focus of TCP is on flow and error control, considered in separate sections below. A short section on TCP port numbers rounds out this discussion of TCP.</p>
        </div>
        <div class="heading">
        <h4 class="h4" id="ch05lev5"><strong>Flow Control</strong></h4>
        <p class="noindent">TCP uses a sliding window method to control the flow of information across each connection between two hosts; <a href="ch05.xhtml#ch05fig09">Figure 5-9</a> illustrates.</p>
        </div>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/05fig09.jpg" aria-describedby="Al05fig09" alt="Figure represents a sliding window." width="700" height="481"><aside class="hidden" id="Al05fig09">
        <p>A line labeled t1 is at the top with a rectangular bar to the left labeled 1-10 sent. A line labeled t2 is below with a grayed out rectangular bar adjacent to it and a rectangular bar below the line, labeled 10 acknowledged window set to 30. T3 is underneath with a grayed out rectangular block adjacent to it, followed by a rectangular bar labeled 11-15 sent. T4 has two grayed out rectangles followed by a rectangular block below the line, labeled 15 acknowledged window set to 40. T5 has two grayed out rectangular blocks adjacent to it followed by a rectangular block next to it labeled 16-35 sent. T6 has three grayed out rectangular blocks adjacent to it followed by a rectangular box below the line labeled 35 acknowledged window set to 50.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch05fig09"></a><strong>Figure 5-9</strong> <em>A Sliding Window</em></p>
        </div>
        <p class="indent">In <a href="ch05.xhtml#ch05fig09">Figure 5-9</a>, assume the initial window size is set to 20. The sequence of events is then</p>
        <p class="bullt">• At <em>t1</em>, the sender transmits 10 packets or octets of data (in the case of TCP, it is 10 octets of data).</p>
        <p class="bull">• At <em>t2</em>, the receiver acknowledges these 10 octets, and the window is set to 30. This means the sender is now allowed to send up to 30 more octets of data before waiting for another acknowledgment; in other words, the sender can send up to octet 40 before it must wait for an acknowledgment to send more data.</p>
        <p class="bull"><a id="page_130"></a>• At <em>t3</em>, the sender sends another 5 octets of data, numbers 11–15.</p>
        <p class="bull">• At <em>t4</em>, the receiver acknowledges the receipt of the octets through 15, and the window is set to 40 octets.</p>
        <p class="bull">• At <em>t5</em>, the sender sends about 20 octets of data, numbered 16–35.</p>
        <p class="bullb">• At <em>t6</em>, the receiver acknowledges 35 and the window is set to 50.</p>
        <p class="indent">Several important points to note about this technique are as follows:</p>
        <p class="bullt">• When the receiver acknowledges receiving a particular piece of data, it implicitly also acknowledges receiving everything before this piece of data.</p>
        <p class="bull">• If the receiver does not send an acknowledgment—say the transmitter sends 16–35 at <em>t5</em>, and the receiver does not send an acknowledgment—the sender will wait some period of time and assume the data never arrived, so it will retransmit the data.</p>
        <p class="bull">• If the receiver acknowledges some of the data the sender has transmitted, but not all of it, the sender assumes some of the data is missing, and retransmits from the point the receiver has acknowledged. For instance, if the sender transmitted 16–35 at <em>t6</em>, and the receiver acknowledged 30, the sender should retransmit 30 and forward.</p>
        <p class="bullb">• The window is set at both the sender and the receiver; this is explained in more detail in a following section.</p>
        <p class="indent">Instead of using octet numbers, TCP assigns each transmission a sequence number; when the receiver acknowledges a specific sequence number, the transmitter assumes the receiver has actually received all the octets of information up to the transmission with the sequence number. For TCP, then, the sequence number acts as a sort of “shorthand” for a set of octets. <a href="ch05.xhtml#ch05fig10">Figure 5-10</a> illustrates.</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/05fig10.jpg" aria-describedby="Al05fig10" alt="Figure represents windowed flow control with serial numbers." width="676" height="464"><aside class="hidden" id="Al05fig10">
        <p>A line labeled t1 is at the top with a rectangular bar to the left labeled 1-10 sent, sequence number 1. A line labeled t2 is below with a grayed out rectangular bar adjacent to it and a rectangular bar below the line, labeled sequence number 1 acknowledged window set to 30. T3 is underneath with a grayed out rectangular block adjacent to it, followed by a rectangular bar labeled 11-15 sent, sequence number 2. T4 has two grayed out rectangles followed by a rectangular block below the line, labeled sequence number 2 acknowledged window set to 40. T5 has two grayed out rectangular blocks adjacent to it followed by a rectangular block next to it labeled 16-25 sent, sequence number 3; 26-35 sent, sequence number 4. T6 has three grayed out rectangular blocks adjacent to it followed by a rectangular box below the line labeled sequence number 4 acknowledged window set to 50.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch05fig10"></a><strong>Figure 5-10</strong> <em>Windowed Flow Control with Serial Numbers</em></p>
        </div>
        <p class="indent">In <a href="ch05.xhtml#ch05fig10">Figure 5-10</a>:</p>
        <p class="bullt">• At <em>t1</em>, the sender bundles octets 1–10 and transmits them, marking them as sequence number 1.</p>
        <p class="bull">• At <em>t2</em>, the receiver acknowledges sequence number 1, implicitly acknowledging the receipt of octets 1–10.</p>
        <p class="bull">• At <em>t3</em>, the sender bundles octets 11–15 together and transmits them, marking them as sequence number 2.</p>
        <p class="bull">• At <em>t4</em>, the receiver acknowledges sequence number 2, implicitly acknowledging the octets sent through 15.</p>
        <p class="bull"><a id="page_131"></a>• At <em>t5</em>, assume 10 octets will fit into a single packet; in this case, the sender would send two packets, one containing 16–25, with the sequence number 3, and one containing octets 26–35, with sequence number 4.</p>
        <p class="bullb">• At <em>t6</em>, the receiver acknowledges sequence number 4, implicitly acknowledging all the previously transmitted data.</p>
        <p class="indent">The sections that follow consider various questions in relation to the windowed flow control scheme used by TCP.</p>
        <div class="heading">
        <h5 class="h5" id="ch05level3"><em><strong>What Happens If One Packet of Information Is Missed?</strong></em></h5>
        <p class="noindent">What if the first packet out of a flow of 100 packets is not received? Using the system described in <a href="ch05.xhtml#ch05fig10">Figure 5-10</a>, the receiver would simply not acknowledge this first packet of information, forcing the sender to retransmit the data sometime later. This is inefficient, however; each dropped packet of information requires a complete resend from that packet forward. TCP implementations use two different ways to allow a single packet to be requested by a receiver.</p>
        </div>
        <p class="indent">The <em>first way</em> is a triple acknowledgment. If a receiver acknowledges a packet that is earlier than the most recently acknowledged serial number <em>three times</em>, the sender assumes the receiver is asking for the packet to be retransmitted. Three repeated <a id="page_132"></a>acknowledgments are used to prevent out-of-order packet delivery, or dropped packets, from causing a false retransmit request.</p>
        <p class="indent">The <em>second way</em> is to implement selective acknowledgments (SACK).<sup><a id="ch05fn15"></a><a href="ch05.xhtml#ch05fn-15">15</a></sup> SACK adds a new field to the TCP acknowledgment that allows a receiver to acknowledge the receipt of a specific set of serial numbers, rather than assuming the acknowledgment of a single serial number acknowledges every lower serial number as well.</p>
        <div class="heading">
        <h5 class="h5" id="ch05level4"><em><strong>How Long Does the Transmitter Wait Before Retransmitting?</strong></em></h5>
        <p class="noindent">The first way in which a sender can detect a packet has been lost is through the Retransmit Time Out (RTO), which is calculated as a function of the Round Trip Time (RTT or rtt). The rtt is the time interval between the transmission of a packet by a sender and the receipt of an acknowledgment from the receiver. The rtt measures the delay through the network from the transmitter to the receiver, the processing time at the receiver, and the delay through the network from the receiver to the transmitter. Note the rtt can vary depending on the path each packet takes through the network, local conditions at the time the packet is switched, etc.</p>
        </div>
        <p class="indent">The RTO is normally calculated as a weighted average in which older rtts have less impact than more recent measured rtts.</p>
        <p class="indent">An alternative mechanism used in most TCP implementations is <strong>fast retransmit.</strong> In fast retransmit, the receiver adds one to the expected sequence number in any acknowledgment. For instance, if a sender transmits sequence 10, the receiver acknowledges sequence 11, <em>even though it has not yet received sequence 11</em>. In this case, the sequence number in the acknowledgment acknowledges the receipt of data and indicates what sequence number it is expecting the sender to transmit next.</p>
        <p class="indent">If the transmitter receives an acknowledgment with a sequence number that is one larger than the last acknowledged sequence number <em>three times in a row</em>, it will assume the packets following have been dropped.</p>
        <p class="indent">There are, therefore, two <em>types</em> of packet loss in TCP when fast start is implemented. The first is a standard timeout, which occurs when the sender transmits a packet, and does not receive an acknowledgment before the RTO expires. This is called an RTO failure. The second is called a fast retransmit failure. These two conditions are often handled differently.</p>
        <div class="heading">
        <h5 class="h5" id="ch05level5"><em><strong>How Is the Window Size Chosen?</strong></em></h5>
        <p class="noindent">There are a number of different considerations in choosing a window size, but the dominant factor is often gaining the highest possible performance while avoiding link congestion. In fact, TCP congestion control is probably the primary form of <a id="page_133"></a>congestion control actually deployed in the global Internet. To understand TCP congestion control, it is best to begin with some definitions:</p>
        </div>
        <p class="bullt">• <strong>Receive Window (RWND):</strong> The amount of data the receiver is willing to receive; this window is normally set based on the receiver’s buffer size, or some other resource available at the receiver. This is the window size advertised in the TCP header.</p>
        <p class="bull">• <strong>Congestion Window (CWND):</strong> The amount of data the transmitter is willing to send before receiving an acknowledgment. This window is not advertised in the TCP header; the receiver does not know the size of the CWND.</p>
        <p class="bullb">• <strong>Slow Start Threshold (SST):</strong> The CWND at which the sender considers the connection at its maximum packet rate without congestion occurring on the network. The SST is initially set by the implementation, and changed in the case of packet loss depending on the congestion avoidance mechanism being used.</p>
        <p class="indent">Most TCP implementations begin sessions with a Slow Start algorithm.<sup><a id="ch05fn16"></a><a href="ch05.xhtml#ch05fn-16">16</a></sup> In this phase, the CWND starts at 1, 2, or 10. For each segment for which an acknowledgment is received, the size of CWND is increased by 1. Given such acknowledgments should take not much longer than a single rtt, slow start should cause the window to double each rtt. The window will continue increasing at this rate until either a packet is lost (the receiver fails to acknowledge a packet), CWND reaches RWND, or CWND reaches SST. Once any of these three conditions occur, the sender moves to congestion avoidance mode.</p>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">How does increasing CWND by 1 for each ACL received double the window each rtt? The thinking is this: When the window size is 1, you should receive one segment per rtt. When you increase the window size to 2, you should receive 2 segments in each rtt; to 4, you should receive 4, etc. As the receiver is acknowledging each segment separately, and increasing the window by 1 each time it acknowledges a segment, it should acknowledge 1 segment in the first rtt, and set the window to 2; 2 segments in the second rtt, adding 2 to the window, to set the window to 4; 4 segments in the third rtt, adding 4 to the window, to set the window size to 8, etc.</p>
        </div>
        <p class="indent"><a id="page_134"></a>In congestion avoidance mode, CWND is increased once each rtt, which means the size of the window stops growing exponentially and instead grows linearly. CWND will continue growing either until the receiver fails to acknowledge a packet (TCP assumes this means a packet has been lost or dropped), or until CWND reaches RWND. There are two broadly deployed ways in which a TCP implementation can respond to the loss of a packet, called <em>Tahoe</em> and <em>Reno</em>.</p>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">There are actually many different variations of Tahoe and Reno; only the very basic implementations are considered here. There are also many different methods for reacting to a packet loss while the connection is in congestion avoidance mode; the “Further Reading” section contains information on where to find out about some of these other methods.</p>
        </div>
        <p class="indent">If the implementation is using Tahoe, and the packet loss is discovered through a fast retransmit, it will set SST to half of the current CWND, set CWND to its original value, and begin slow start again. This means the sender will transmit 1, 2, or 10 sequence numbers again, increasing CWND for each sequence number acknowledged. As in the beginning of the slow start process, this has the effect of doubling CWND each rtt. Once CWND reaches SST, TCP will move back into congestion avoidance mode.</p>
        <p class="indent">If the implementation is using Reno, and the packet loss is discovered through a fast retransmit, it will set SST <em>and</em> CWND to half the current CWND, and continue operating in congestion avoidance mode.</p>
        <p class="indent">In either implementation, if packet loss is discovered because the receiver does not send an acknowledgment within the RTO, the CWND is set to 1, and slow start is used to ramp the connection speed back up.</p>
        <div class="heading">
        <h4 class="h4" id="ch05lev6"><strong>Error Control</strong></h4>
        <p class="noindent">TCP provides two forms of error detection and control:</p>
        </div>
        <p class="bullt">• The protocol itself, along with the windowing mechanism, ensures data is delivered to the application in order and without any missing information.</p>
        <p class="bullb">• The one’s complement checksum included in the TCP header is considered weaker than a Cyclic Redundancy Check (CRC) and many other forms of error detection. This error check serves to complement, rather than replace, the error correction provided by protocols lower and higher in the stack.</p>
        <p class="indent">If a receiver detects a checksum error, it can use any of the mechanisms described here to request the sender retransmit the data—simply not acknowledging the receipt <a id="page_135"></a>of the data, requesting a retransmit through SACK, actively <em>not</em> acknowledging the receipt of the data through fast retransmit, or by sending a triple acknowledgment for the specific segment containing the corrupted data.</p>
        <div class="heading">
        <h4 class="h4" id="ch05lev7"><strong>TCP Port Numbers</strong></h4>
        <p class="noindent">TCP does not directly manage any kind of multiplexing; however, it does provide port numbers that applications and protocols above TCP in the protocol stack can use to multiplex. While these port numbers are carried <em>in</em> TCP, they are generally <em>opaque to</em> TCP; TCP does not attach any meaning to these port numbers other than using them to dispatch information to the correct application on the receiving host.</p>
        </div>
        <p class="indent">TCP port numbers are divided into two broad classes: well known and ephemeral. Well-known ports are defined as a part of an upper layer protocol specification; these ports are the “default” ports for these applications. For instance, a service supporting the Simple Mail Transfer Protocol (SMTP) can generally be found by connecting to a host using TCP on port number 25. A service supporting the Hypertext Transport Protocol (HTTP) can normally be found by connecting to a host using TCP on port 80. These services do not <em>necessarily</em> need to use these port numbers; most servers can be configured to use some port number other than the one designated in the protocol specification. For instance, web servers not intended for general (or public) use may use some other TCP port, such as 8080.</p>
        <p class="indent">Ephemeral ports are significant only to the local host and normally assigned from a pool of available port numbers on the local host. Ephemeral ports are most often used as source ports for TCP connections; for instance, a host connecting to a service at port 80 on a server will use an ephemeral port as its source TCP port. So long as any particular host uses a given ephemeral port number only once for any TCP connection, each TCP session on any network can be uniquely identified through the source address, source port, destination address, destination port, and the number of the protocol running on top of TCP.</p>
        <div class="heading">
        <h4 class="h4" id="ch05lev8"><strong>TCP Session Setup</strong></h4>
        <p class="noindentb">TCP uses a three-way handshake to set up a session:</p>
        </div>
        <p class="indenthangingN">1. The client sends a synchronization (SYN) to the server. This packet is a normal TCP packet, but with a SYN bit set in the TCP header, and indicates the sender is requesting a session to be set up with the receiver. This packet is normally sent to a well-known port number, or some prearranged port number that the client knows a server will be listening on at a particular IP address. This packet includes the client’s initial sequence number.</p>
        <p class="indenthangingN"><a id="page_136"></a>2. The server sends an acknowledgment for the SYN, a SYN-ACK. This packet acknowledges the sequence number provided by the client, plus one, and includes the server’s initial sequence number as the sequence number for this packet.</p>
        <p class="indenthangingN">3. The client sends an acknowledgment (ACK) including the server’s initial sequence number plus one.</p>
        <p class="indentt">This process is used to ensure two-way communication exists between the client and the server before beginning to transfer data. The initial sequence number chosen by the sender and receiver is randomized in most implementations to prevent a third-party attacker from guessing what sequence number will be used and taking over the TCP session in its initial stages of formation.<sup><a id="ch05fn17"></a><a href="ch05.xhtml#ch05fn-17">17</a></sup></p>
        <div class="heading">
        <h3 class="h3" id="ch05lev9">QUIC</h3>
        <p class="noindent">In 2012, Jim Roskind designed a new transport protocol with the primary intent of increasing the speed at which data can be transferred over relatively stable high-speed networks. Specifically:</p>
        </div>
        <p class="bullt">• Reducing the three-way handshake to a single packet startup (a zero-way handshake)</p>
        <p class="bull">• Reducing the number of retransmitted packets required to transfer data</p>
        <p class="bullb">• Reducing head-of-line blocking across multiple data streams within a single TCP stream caused by packet loss</p>
        <p class="indent">Each of these is considered in the sections that follow.</p>
        <div class="heading">
        <h5 class="h5" id="ch05level6"><em><strong>Reducing the Startup Handshake</strong></em></h5>
        <p class="noindent">The rtt cannot, generally, be changed, because it is normally bounded by the physical distance and link speed between the sender and receiver. One of the best ways to reduce total data transfer time, then, is to simply reduce the number of round trips required between the sender and receiver to transfer a given stream or block of data. QUIC’s startup is designed to reduce the number of round trips required to set up a <a id="page_137"></a>new connection from the three-way handshake of TCP to a 0 round trip time startup process.</p>
        </div>
        <p class="indentb">To do this, QUIC uses a series of cryptographic keys and hashes (see <a href="ch10.xhtml#ch10">Chapter 10</a>, “<a href="ch10.xhtml#ch10">Transport Security</a>,” for more information); the process is</p>
        <p class="indenthangingN">1. The client sends the server a hello (CHLO) containing a proof demand, which is a list of certificate types the client will accept to verify the server’s identity; a set of certificates the client has access to; and a hash of the certificate the client intends to use in this connection. One specific field, the source address token (STK) will be left blank, because no communication has occurred with this server before.</p>
        <p class="indenthangingN">2. The server will use this information to create an STK based on the information provided in the client’s initial hello and the client’s source IP address. The server sends a reject (REJ), which contains this STK.</p>
        <p class="indentt">Once the client has the STK, it includes this in future hello packets. If the STK matches the previously used STK from this IP address, the server will accept the hello.</p>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">This IP address/STK pair can be stolen, and hence the source IP address can be spoofed by an attacker with access to any communication with this pair included. This is a known problem in QUIC, addressed in the QUIC documentation pointed to in the “Further Reading” section at the end of the chapter.</p>
        </div>
        <p class="indent">In comparison, TCP requires at least one-and-a-half rtts to set up a new session: the SYN, the SYN-ACK, and then the following ACK. How much time does moving to a single rtt connection time save? It depends on the implementation of the client and server applications, of course. However, many web pages and mobile device apps must connect to many different servers (perhaps hundreds) to build a single web page or application screen. If each of these connections is reduced from one-and-a-half rtts to a single rtt, there could be a significant performance impact.</p>
        <a id="page_138"></a>
        <div class="heading">
        <h5 class="h5" id="ch05level7"><em><strong>Reducing Retransmissions</strong></em></h5>
        <p class="noindent">QUIC uses a number of different mechanisms to reduce the number of retransmitted packets:</p>
        </div>
        <p class="bullt">• Including Forward Error Correction (FEC) in all packets; this allows the receiver to (often) rebuild corrupted information rather than request the information to be resent.</p>
        <p class="bull">• Using negative acknowledgments (NACKs) rather than SACK or the triple ACK mechanism to request retransmission of specific sequence numbers; this prevents ambiguity between a request for a retransmission and network conditions that cause multiple acknowledgments to be sent.</p>
        <p class="bull">• Using fast acknowledgments, as described previously for TCP.</p>
        <p class="bullb">• Using the CUBIC congestion avoidance window control.</p>
        <p class="indent">The CUBIC congestion avoidance mechanism is the most interesting of these. CUBIC attempts to perform a binary search between the last window size before a packet drop and some lower window size calculated using a <strong>m</strong>ultiplicative factor. When a packet loss is detected (either through an RTO timeout or through a NACK), the maximum window size (WMAX) is set to the current window size, and a new minimum window size (WMIN) is calculated.</p>
        <p class="indent">The sender’s window is set to WMIN and then quickly increased to a window size halfway between WMIN and WMAX. Once the window reaches this halfway point, the window size is increased very slowly in what is called probing, until the next packet drop is encountered. This process allows CUBIC to find the maximum transmission rate just below the point where the network begins dropping packets fairly quickly.</p>
        <div class="heading">
        <h5 class="h5" id="ch05level8"><em><strong>Reducing Head of Line Blocking</strong></em></h5>
        <p class="noindent">A “single transaction” across the Internet is often not a “single transaction,” but rather a large collection of transactions across a number of different servers. To build a single web page, for instance, hundreds of elements, such as images, scripts, Cascading Style Sheet (CSS) elements, and Hypertext Markup Language (HTML) files need to be transferred from the server to the client. There are two ways these files can be transferred: in serial or in parallel. <a href="ch05.xhtml#ch05fig11">Figure 5-11</a> illustrates.</p>
        </div>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/05fig11.jpg" aria-describedby="Al05fig11" alt="Figure represents multiple element transfer options." width="691" height="472"><aside class="hidden" id="Al05fig11">
        <p>The top portion is labeled serialized that has a rectangular box filled with dotted lines, labeled server. Three rectangular boxes, element 1, element 2, and element 3 are enclosed. Two parallel dotted lines move to the right with element 3, element 2, and element 1 enclosed. It reaches a rectangular box filled with dotted lines, labeled client. Three rectangular boxes, element 1, element 2, and element 3 are enclosed. Multiple streams are underneath that has a rectangular box filled with dotted lines, labeled server. Three rectangular boxes, element 1, element 2, and element 3 are enclosed. Three parallel dotted arrows move to the right, meeting three rectangular boxes, element 1, element 2, and element 3. Dotted arrows move to the right, meeting a rectangular box filled with dotted lines, labeled client. Three rectangular boxes, element 1, element 2, and element 3 are enclosed. The bottom portion is labeled multiplexed that has a rectangular box filled with dotted lines, labeled server. Three rectangular boxes, element 1, element 2, and element 3 are enclosed. Two parallel dotted lines move to the right with element 3, element 2, and element 1 enclosed vertically. It reaches a rectangular box filled with dotted lines, labeled client. Three rectangular boxes, element 1, element 2, and element 3 are enclosed.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch05fig11"></a><strong>Figure 5–11</strong> <em>Multiple Element Transfer Options</em></p>
        </div>
        <p class="indent">In <a href="ch05.xhtml#ch05fig11">Figure 5-11</a>, three options are illustrated to transfer multiple elements from a server to a client:</p>
        <p class="bullt">• In the <strong>serialized</strong> option, the elements are transferred one at a time across a single session. This is the slowest of the three possible options, as the entire page must be built element by element, with smaller elements waiting on larger ones to transfer before they can be displayed.</p>
        <p class="bull"><a id="page_139"></a>• In the <strong>multiple streams</strong> option, each element is transferred over a separate connection (such as a TCP session). This is much faster, but it requires multiple connections to be built, which can negatively impact the client and server resources.</p>
        <p class="bullb">• In the <strong>multiplexed</strong> option, each element is transferred separately across a single connection. This allows each element to be transferred at its own rate, but with the resource overhead of the multiple streams option.</p>
        <p class="indent">Some form of multiplexed transfer mechanism tends to provide the fastest transfer rate with the most efficient use of resources, but how should this multiplexing be implemented? The Hypertext Transfer Protocol version 2 (HTTPv2) allows a web server to multiplex multiple elements across a single HTTP session; since HTTP runs on top of TCP, this means a single TCP stream can be used to transfer multiple web page elements in parallel. However, a single dropped packet at the TCP level means every parallel transfer within the HTTP stream must be paused while TCP recovers (this is a form of fate sharing).</p>
        <p class="indent">QUIC solves this problem by allowing multiple HTTPv2 streams to reside within a single QUIC connection. This reduces the transport overhead at the client and server, while providing optimal delivery of the web page elements.</p>
        <div class="sidebar1">
        <p class="title1"><a id="page_140"></a><strong>Path MTU Discovery</strong></p>
        <p class="noindent">One of the core issues of the argument between Asynchronous Transfer Mode (ATM) and the Internet Protocol (IP) was the fixed cell size. While IP networks rely on variable length packets, ATM, in order to facilitate faster switching speeds, and in order to interoperate better with the many different Time Division Multiplexing (TDM) physical layers, specified fixed length cells. IPv4, in particular, not only provides for a variable length packet, but fragmentation in flight. <a href="ch05.xhtml#ch05fig12">Figure 5-12</a> illustrates.</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/05fig12.jpg" aria-describedby="Al05fig12" alt="Figure represents an example for packet fragmentation." width="700" height="90"><aside class="hidden" id="Al05fig12">
        <p>A computer labeled A is to the left with a line leading to the right, labeled 1500. It reaches a router, B. A line labeled 1500 leads to the right, meeting a router, C. A line leads from C, labeled 1000, reaching a router, D. A line leads to the right, labeled 1500, reaching a server labeled E.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch05fig12"></a><strong>Figure 5–12</strong> <em>Packet Fragmentation Example</em></p>
        </div>
        <p class="indent">In <a href="ch05.xhtml#ch05fig12">Figure 5-12</a>, if A sends a packet toward E, what size should it make the packet? The only link A really knows about is the link between itself and B, which is marked having a 1,500 octet Maximum Transmission Unit (MTU) size. If A sends a 1,500 octet packet, however, the packet will not be able to pass through the [C,D] link. There are two ways to solve this problem.</p>
        <p class="indent">The first is for C to fragment the packet into two smaller packets. This is possible in IPv4; C can determine the packet will not fit on the next link over which the packet should be forwarded, and break the packet into two smaller packets. There are a number of problems with this solution, of course. For instance, the process of fragmenting a packet requires a lot more work on the part of C, possibly even moving the packet out of the hardware switching path into the software switching path.</p>
        <p class="indent">The second is for A to never send a packet larger than the minimum MTU along the entire path to E. To do this, A must discover the minimum MTU along the path, and it must be able to fragment the information sent from upper layer protocols into multiple packets before transmission. IPv6 chooses this latter option, relying on Path MTU (PMTU) discovery to find the minimum MTU along a path (assuming PMTU actually works, a fairly bad assumption in large public networks), and allowing the IPv6 process at A to fragment information from upper layer protocols into multiple packets, which are then reassembled into the original upper layer data block at the receiver.</p>
        <p class="indent">This solution, however, also seems to be problematic. In recent work with the Domain Name System (DNS), researchers have discovered that some 37% <a id="page_141"></a>of all DNS resolvers will drop fragmented IPv6 packets.<sup><a id="ch05fn18"></a><a href="ch05.xhtml#ch05fn-18">18</a></sup> Why would this be so? The easiest way to understand is to consider the structure of a fragmented packet, and the nature of DoS and DDoS attacks.</p>
        <p class="indent">When a packet is transmitted, a header is placed on the packet indicating the receiving service (a socket or protocol number of some kind), as well as information about the transmitting service. This information is important to filtering a packet based on various security policies, particularly if the security policy is “only allow session initiation packets into the network unless the packet belongs to an existing session.” In other words, a typical stateful filter protecting a server will have some basic rules it follows:</p>
        <p class="bullt">• If the packet initiates a new session, forward it and build a new session record.</p>
        <p class="bull">• If the packet is part of an existing session, forward it and reset the session timer.</p>
        <p class="bull">• If the packet is not part of an existing session, drop it.</p>
        <p class="bullb">• Every now and again, clean out old sessions.</p>
        <p class="indent">While it is possible to forge a packet that appears to be from an existing session, it is not very easy; various nonces and other techniques are deployed to discourage this sort of behavior. But fragmenting a packet removes the header from the second half of the packet, effectively meaning the second packet in a fragmented pair can only be attached to a particular session, or flow, by tracing down the part of the packet that has the full header.</p>
        <p class="indent">How can a router or middlebox do such a thing? It must somehow keep a copy of each packet fragment with a header someplace in memory, so the packet with the header can be referenced to process any future fragments. How long must it keep these fragments with headers? There is actually no way to tell. Ultimately, it is easier to simply drop any fragments than to maintain the state required to process them.</p>
        <p class="indent">The result? It appears even source-based fragmentation is not very useful at the IP layer.</p>
        <p class="indent">This should bring to mind one of the founding principles of the Internet Protocol suite: the <em>end-to-end principle</em>. The end-to-end principle states <a id="page_142"></a>the network should not modify traffic in flight between two end devices; or rather the network should operate as a black box connecting two devices, never changing the data as it is received from the end host.</p>
        <p class="indent">Does this mean all filtering of traffic should be banned on the public Internet, imposing the end-to-end rule in earnest, leaving all security to the end hosts? This does seem to be the flavor of the original IPv6 discussions around stateful packet filters. This does not, however, seem like the most realistic option available; the stronger defense is not a single perfect wall, but rather a series of less than perfect walls. Defense in depth will beat a single firewall every time.</p>
        <p class="indent">Another alternative is to accept another bit of reality often forgotten in the network engineering world: abstractions leak. The end-to-end principle describes a perfectly abstracted system capable of carrying traffic from one host to another, and a perfectly abstracted set of hosts between which traffic is being carried. But all nontrivial abstractions leak; the MTU and fragmentation problem is just a leakage of state from the network into the host, and a system on the host trying to abstract that leakage into the application sending traffic over the network. In this kind of situation, it might be best to simply admit the leakage and officially push the information up the stack so the application can make a better decision about how to send traffic.</p>
        <p class="indent">But this leads to another interesting question to ponder: is the stateful filtering described here betraying the end-to-end principle? The answer depends on whether you consider the upper layer protocol shipping the data to be the end point, or the system the application is running on (hence, including the IP stack itself), the end point. Either way, this bit of ambiguity has plagued the Internet from the earliest of days, although the network engineering world has not always thought seriously about the difference between the two points of view.</p>
        </div>
        <div class="heading">
        <h3 class="h3" id="ch05lev10">ICMP</h3>
        <p class="noindent">While the transport protocols, such as TCP and QUIC, tend to receive the most attention among the middle tier of protocols, there are a number of other protocols that are just as important for the operation of an IP-based network. Among these is ICMP, which can be said to provide metadata about the network itself. ICMP is a simple protocol that is used to request specific state information, or for network <a id="page_143"></a>devices to send information about why a particular packet is being dropped at some point in the network. Specifically:</p>
        </div>
        <p class="bullt">• ICMP can be used to send an echo request or echo reply. This functionality is used to ping a particular destination address, which can be used to determine if the address is reachable without consuming too many resources at the receiver.</p>
        <p class="bull">• ICMP can be used to send a notification about a packet being dropped because it is too large to be transmitted across a link (the packet is too big).</p>
        <p class="bullb">• ICMP can be used to send a notification that a packet has been dropped because its Time to Live (TTL) has reached 0 (the packet has expired in transit).</p>
        <p class="indent">The packet too big response can be used to find the Maximum Transmission Unit (MTU) across a network; the sender can transmit a large packet and wait to see if some device in the network sends a <em>packet too big</em> notification through ICMP. If such a notification arrives, the sender can try progressively smaller packets to determine the largest packet that can be transmitted end-to-end across the network.</p>
        <p class="indent">The expired in transit response can be used to trace the route from a source to a destination in a network (this is called trace route). A sender can transmit a packet to a particular destination using any transport layer protocol (including TCP, UDP, or QUIC), but with a TTL of 1. The first hop network device should decrement the TTL and send an ICMP expired in transit notification back to the sender. Sending a series of packets, each with a TTL one larger than the previous one, each device along the path can be induced to transmit an ICMP expired in transit notification to the sender, revealing the entire path of the packet.</p>
        <div class="heading">
        <h3 class="h3" id="ch05lev11">Final Thoughts</h3>
        <p class="noindent">Upper layer transport protocols manage the same problems as lower layer transport protocols—error control, flow control, transport, and marshaling—only end to end rather than device to device. Even so, while many of the solutions are similar or the same, many other solutions are radically different. This chapter has considered four different upper layer transport protocols, two of which occupy the same “space” in a protocol stack—TCP and QUIC—and two of which occupy completely different spaces in a protocol stack—IP and ICMP. While there are other solutions to the problems presented, the solutions presented by these four protocols cover most of the widely deployed solutions to these problems.</p>
        </div>
        <p class="indent"><a id="page_144"></a>The next chapter moves you from understanding how information is transported across a network into the realm of how the layers considered in this and the previous chapter interact. These interlayer problems relate to the interaction surfaces considered in the State/Optimization/Surface model of network complexity you will find useful in analyzing a large number of network problems.</p>
        <div class="heading">
        <h3 class="h3" id="ch05lev12">Further Reading</h3>
        <p class="ref">Armitage, Grenville. “Summary of Five New TCP Congestion Control Algorithms Project.” <em>The FreeBSD Forums</em>. Accessed July 5, 2017. <a href="http://www.ieee802.org/3/efm/public/jul01/presentations/mclaughlin_1_0701.pdf">https://forums.FreeBSD.org/threads/22396/</a>.</p>
        </div>
        <p class="ref">Blanton, Ethan, Dr. Vern Paxson, and Mark Allman. <em>TCP Congestion Control</em>. Request for Comments 5681. RFC Editor, 2009. doi:10.17487/RFC5681.</p>
        <p class="ref">Chu, H. K. Jerry, and Vivek Kashyap. <em>Transmission of IP over InfiniBand (IPoIB)</em>. Request for Comments 4391. RFC Editor, 2006. doi:10.17487/RFC4391.</p>
        <p class="ref">Cole, Robert G., Dr. David H. Shur, and Curtis Villamizar. <em>IP over ATM: A Framework Document</em>. Request for Comments 1932. RFC Editor, 1996. doi:10.17487/RFC1932.</p>
        <p class="ref">Deering, Dr. Steve E., and Robert M. Hinden. “Internet Protocol, Version 6 (IPv6) Specification.” Internet-Draft. Internet Engineering Task Force, May 2017. <a href="https://datatracker.ietf.org/doc/html/draft-ietf-6man-rfc2460bis-13">https://datatracker.ietf.org/doc/html/draft-ietf-6man-rfc2460bis-13</a>.</p>
        <p class="ref">Desanti, Claudio, Robert Nixon, and Craig Carlson. <em>Transmission of IPv6, IPv4, and Address Resolution Protocol (ARP) Packets over Fibre Channel</em>. Request for Comments 4338. RFC Editor, 2006. doi:10.17487/RFC4338.</p>
        <p class="ref">“DoD Standard Internet Protocol.” IETF, January 1980. <a href="https://tools.ietf.org/html/rfc760">https://tools.ietf.org/html/rfc760</a>.</p>
        <p class="ref">Fairhurst, Gorry, Marie-Jose Montpetit, Bernhard Collini-Nocker, Hilmar Linder, and Horst D. Clausen. <em>A Framework for Transmission of IP Datagrams over MPEG-2 Networks</em>. Request for Comments 4259. RFC Editor, 2005. doi:10.17487/RFC4259.</p>
        <p class="ref">Floyd, Sally, Jamshid Mahdavi, Matt Mathis, and Dr. Allyn Romanow. <em>TCP Selective Acknowledgment Options</em>. Request for Comments 2018. RFC Editor, 1996. doi:10.17487/RFC2018.</p>
        <p class="ref">Gont, Fernando, and Steven Bellovin. <em>Defending against Sequence Number Attacks</em>. Request for Comments 6528. RFC Editor, 2012. doi:10.17487/RFC6528.</p>
        <p class="ref"><a id="page_145"></a>Gupta, Mukesh, and Alex Conta. <em>Internet Control Message Protocol (ICMPv6) for the Internet Protocol Version 6 (IPv6) Specification</em>. Request for Comments 4443. RFC Editor, 2006. doi:10.17487/RFC4443.</p>
        <p class="ref">Ha, Sangtae, Injong Rhee, and Lisong Xu. “CUBIC: A New TCP-Friendly High-Speed TCP Variant.” <em>ACM SIGOPS Operating System Review</em> 42, no. 5 (July 2008): 64–74.</p>
        <p class="ref">Huston, Geoff. “Dealing with IPv6 Fragmentation in the DNS.” <em>APNIC Blog</em>, August 22, 2017. <a href="https://blog.apnic.net/2017/08/22/dealing-ipv6-fragmentation-dns/">https://blog.apnic.net/2017/08/22/dealing-ipv6-fragmentation-dns/</a>.</p>
        <p class="ref"><em>Internet Control Message Protocol</em>. Request for Comments 792. RFC Editor, 1981. doi:10.17487/RFC0792.</p>
        <p class="ref">“Internet Protocol.” IETF, September 1981. <a href="https://tools.ietf.org/html/rfc791">https://tools.ietf.org/html/rfc791</a>.</p>
        <p class="ref"><em>IPv4 Exhaustion</em>, June 9, 2010. <a href="https://commons.wikimedia.org/wiki/File:Ipv4-exhaust.svg">https://commons.wikimedia.org/wiki/File:Ipv4-exhaust.svg</a>.</p>
        <p class="ref">Jacobson, V. “Congestion Avoidance and Control.” In <em>Symposium Proceedings on Communications Architectures and Protocols</em>, 314–29. SIGCOMM ’88. New York, NY, USA: ACM, 1988. doi:10.1145/52324.52356.</p>
        <p class="ref">Jamal, Habibullah, and Kiran Sultan. “Performance Analysis of TCP Congestion Control Algorithms.” <em>International Journal of Computers and Communications</em> 2, no. 1 (2008): 30–38.</p>
        <p class="ref">Johansson, Peter G. <em>IPv4 over IEEE 1394</em>. Request for Comments 2734. RFC Editor, 1999. doi:10.17487/RFC2734.</p>
        <p class="ref">Katz, Dave. <em>Transmission of IP and ARP over FDDI Networks</em>. Request for Comments 1390. RFC Editor, 1993. doi:10.17487/RFC1390.</p>
        <p class="ref">Lawrence, Joe L., and David M. Piscitello. <em>The Transmission of IP Datagrams over the SMDS Service</em>. Request for Comments 1209. RFC Editor, 1991. doi:10.17487/RFC1209.</p>
        <p class="ref">Luciani, Dr. James V., Dr. Bala Rajagopalan, and Daniel O. Awduche. <em>IP over Optical Networks: A Framework</em>. Request for Comments 3717. RFC Editor, 2004. doi:10.17487/RFC3717.</p>
        <p class="ref">Mathis, Matt, Nandita Dukkipati, and Yuchung Cheng. <em>Proportional Rate Reduction for TCP</em>. Request for Comments 6937. RFC Editor, 2013. doi:10.17487/RFC6937.</p>
        <p class="ref">Panabaker, Ruston, Simon Wegerif, and Dan Zigmond. <em>The Transmission of IP Over the Vertical Blanking Interval of a Television Signal</em>. Request for Comments 2728. RFC Editor, 1999. doi:10.17487/RFC2728.</p>
        <p class="ref"><a id="page_146"></a>Partridge, Dr. Craig, Mark Allman, and Sally Floyd. <em>Increasing TCP’s Initial Window</em>. Request for Comments 3390. RFC Editor, 2002. doi:10.17487/RFC3390.</p>
        <p class="ref">Postel, J. “Comments on Internet Protocol and TCP,” August 15, 1977. <a href="https://www.rfc-editor.org/ien/ien2.txt">https://www.rfc-editor.org/ien/ien2.txt</a>.</p>
        <p class="ref">———. “Draft Internetwork Protocol Specification, Version 2,” February 1978. <a href="https://www.rfc-editor.org/ien/ien28.pdf">https://www.rfc-editor.org/ien/ien28.pdf</a>.</p>
        <p class="ref">———. “Internetwork Protocol Specification, Version 4,” June 1978. <a href="https://www.rfc-editor.org/ien/ien41.pdf">https://www.rfc-editor.org/ien/ien41.pdf</a>.</p>
        <p class="ref">———. “Internetwork Protocol Specification, Version 4,” September 1978. <a href="https://www.rfc-editor.org/ien/ien41.pdf">https://www.rfc-editor.org/ien/ien41.pdf</a>.</p>
        <p class="ref">“QUIC, a Multiplexed Stream Transport over UDP—The Chromium Projects.” Accessed July 5, 2017. <a href="https://www.chromium.org/quic">https://www.chromium.org/quic</a>.</p>
        <p class="ref">Riegel, Max, Sangjin Jeong, and HongSeok Jeon. <em>Transmission of IP over Ethernet over IEEE 802.16 Networks</em>. Request for Comments 5692. RFC Editor, 2009. doi:10.17487/RFC5692.</p>
        <p class="ref">Stevens, W. Richard. <em>TCP Slow Start, Congestion Avoidance, Fast Retransmit, and Fast Recovery Algorithms</em>. Request for Comments 2001. RFC Editor, 1997. doi:10.17487/RFC2001.</p>
        <p class="ref">Varada, Srihari V. <em>IP Version 6 over PPP</em>. Request for Comments 5072. RFC Editor, 2007. doi:10.17487/RFC5072.</p>
        <p class="ref">Waitzman, David. <em>Standard for the Transmission of IP Datagrams on Avian Carriers</em>. Request for Comments 1149. RFC Editor, 1990. doi:10.17487/RFC1149.</p>
        <div class="heading">
        <h3 class="h3" id="ch05lev13">Review Questions</h3>
        <p class="indenthangingN">1. The choice of using a /64 for the host address space is often considered controversial. What do you think are the positive and negative aspects of this specific choice?</p>
        </div>
        <p class="indenthangingN">2. The Internet has been “running out of IPv4 address space” for many years. One of the reactions to this lack of address space has been the widespread deployment of Network Address Translators (NATs). The following questions relate to NATs.</p>
        <p class="indenthangingNA">a. What is the difference between a NAT and a Port Address Translator (PAT)?</p>
        <p class="indenthangingNA">b. Why do PATs create a problem for FTP (for instance)? How is this normally solved?</p>
        <p class="indenthangingNA"><a id="page_147"></a>c. Throughout the development of IPv6, there was a general movement against the deployment of NATs and PATs; can you think of or find the reasons engineers objected to the use of NAT and PAT on the global Internet?</p>
        <p class="indenthangingN">3. The fragmentation of packets by routers and other network devices was removed from the IPv6 specification, although it was allowed in the IPv4 specifications. What are the tradeoffs in removing this capability? What complexity does fragmentation add to network devices, and what complexity does removing it from the network devices add to end hosts?</p>
        <p class="indenthangingN">4. How can an implementation of TCP differentiate between well-known and ephemeral ports? Does it need to?</p>
        <p class="indenthangingN">5. From a security perspective, what might be the advantages and disadvantages of allowing network devices and hosts to respond to ICMP, versus not allowing them to?</p>
        <p class="indenthangingN">6. Explain the aggregation of IPv6 addresses in terms of nibbles (4 bits) rather than in bits, as is done in the chapter.</p>
        <p class="indenthangingN">7. Why is the prefix length called the <em>prefix length</em>? What is the history behind this term?</p>
        <p class="indenthangingN">8. Compare the prefix length to the older method for determining the point where the network address stops and the host bits, or the “bits the network device does not care about,” begin, the subnet mask. Which do you think is easier to use? <a id="page_148"></a></p>
        <p class="footnotet"><a id="ch05fn-1"></a><a href="ch05.xhtml#ch05fn1">1</a>. Postel, “Comments on Internet Protocol and TCP,” 1.</p>
        <p class="footnote"><a id="ch05fn-2"></a><a href="ch05.xhtml#ch05fn2">2</a>. Postel, “Draft Internetwork Protocol Specification, Version 2.”</p>
        <p class="footnote"><a id="ch05fn-3"></a><a href="ch05.xhtml#ch05fn3">3</a>. Postel, “Internetwork Protocol Specification, Version 4,” June 1978.</p>
        <p class="footnote"><a id="ch05fn-4"></a><a href="ch05.xhtml#ch05fn4">4</a>. Postel, “Internetwork Protocol Specification, Version 4,” September 1978.</p>
        <p class="footnote"><a id="ch05fn-5"></a><a href="ch05.xhtml#ch05fn5">5</a>. “DoD Standard Internet Protocol.”</p>
        <p class="footnote"><a id="ch05fn-6"></a><a href="ch05.xhtml#ch05fn6">6</a>. “Internet Protocol.”</p>
        <p class="footnote"><a id="ch05fn-7"></a><a href="ch05.xhtml#ch05fn7">7</a>. Mro, <em>IPv4 Exhaustion</em>.</p>
        <p class="footnote"><a id="ch05fn-8"></a><a href="ch05.xhtml#ch05fn8">8</a>. Fairhurst et al., <em>A Framework for Transmission of IP Datagrams over MPEG-2 Networks</em>.</p>
        <p class="footnote"><a id="ch05fn-9"></a><a href="ch05.xhtml#ch05fn9">9</a>. Cole, Shur, and Villamizar, <em>IP over ATM: A Framework Document</em>.</p>
        <p class="footnote1"><a id="ch05fn-10"></a><a href="ch05.xhtml#ch05fn10">10</a>. Luciani, Rajagopalan, and Awduche, <em>IP over Optical Networks: A Framework</em>.</p>
        <p class="footnote1"><a id="ch05fn-11"></a><a href="ch05.xhtml#ch05fn11">11</a>. Varada, <em>IP Version 6 over PPP</em>.</p>
        <p class="footnote1"><a id="ch05fn-12"></a><a href="ch05.xhtml#ch05fn12">12</a>. Panabaker, Wegerif, and Zigmond, <em>The Transmission of IP Over the Vertical Blanking Interval of a Television Signal</em>.</p>
        <p class="footnote1"><a id="ch05fn-13"></a><a href="ch05.xhtml#ch05fn13">13</a>. Katz, <em>Transmission of IP and ARP over FDDI Networks</em>.</p>
        <p class="footnote1"><a id="ch05fn-14"></a><a href="ch05.xhtml#ch05fn14">14</a>. Waitzman, <em>Standard for the Transmission of IP Datagrams on Avian Carriers</em>.</p>
        <p class="footnote1"><a id="ch05fn-15"></a><a href="ch05.xhtml#ch05fn15">15</a>. Floyd et al., <em>TCP Selective Acknowledgment Options</em>.</p>
        <p class="footnote1"><a id="ch05fn-16"></a><a href="ch05.xhtml#ch05fn16">16</a>. Blanton, Paxson, and Allman, <em>TCP Congestion Control</em>.</p>
        <p class="footnote1"><a id="ch05fn-17"></a><a href="ch05.xhtml#ch05fn17">17</a>. Gont and Bellovin, <em>Defending against Sequence Number Attacks</em>.</p>
        <p class="footnote1"><a id="ch05fn-18"></a><a href="ch05.xhtml#ch05fn18">18</a>. Huston, “Dealing with IPv6 Fragmentation in the DNS.”</p>
        </div></div><link rel="stylesheet" href="/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="/api/v2/epubs/urn:orm:book:9780134762814/files/9780134762852.css" crossorigin="anonymous"></div></div></section>
</div>

https://learning.oreilly.com