<style>
    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 300;
        src: url(https://static.contineljs.com/fonts/Roboto-Light.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Light.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 400;
        src: url(https://static.contineljs.com/fonts/Roboto-Regular.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Regular.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 500;
        src: url(https://static.contineljs.com/fonts/Roboto-Medium.woff2?v=2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Medium.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 700;
        src: url(https://static.contineljs.com/fonts/Roboto-Bold.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Bold.woff) format("woff");
    }

    * {
        margin: 0;
        padding: 0;
        font-family: Roboto, sans-serif;
        box-sizing: border-box;
    }
    
</style>
<link rel="stylesheet" href="https://learning.oreilly.com/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492092506/files/epub.css" crossorigin="anonymous">
<div style="width: 100%; display: flex; justify-content: center; background-color: black; color: wheat;">
    <section data-testid="contentViewer" class="contentViewer--KzjY1"><div class="annotatable--okKet"><div id="book-content"><div class="readerContainer--bZ89H white--bfCci" style="font-size: 1em; max-width: 70ch;"><div id="sbo-rt-content"><h2 class="h2" id="ch01"><a id="page_5"></a><strong>Chapter 1<br>Fundamental Concepts</strong></h2>
        <div class="sidebar">
        <p class="sb-noindent"><strong>Learning Objectives</strong></p>
        <p class="sb-noindent">After reading this chapter, you should be able to:</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Understand the relationship between business drivers and network engineering</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Understand the difference between circuit and packet switching</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Understand the advantages and disadvantages of circuit and packet switching</p>
        <p class="sb-indenthangingB"><img class="middle" src="/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/bull.jpg" alt="Image" width="12" height="12"> Understand the basic concept of network complexity and complexity tradeoffs</p>
        </div>
        <p class="noindent">Networks were always designed to do one thing: carry information from one attached system to another. The discussion (or perhaps argument) over the best way to do this seemingly simple task has been long-lived, sometimes accompanied by more heat than light, and often intertwined with people and opinions of a rather absolute kind. This history can be roughly broken into multiple, and often overlapping, stages, each of which asked a different question:</p>
        <p class="bullt">• Should networks be circuit switched or packet switched?</p>
        <p class="bull">• Should packet switched networks use fixed- or variable-sized frames?</p>
        <p class="bull">• What is the best way to calculate a set of shortest paths through a network?</p>
        <p class="bull">• How should packet switched networks interact with Quality of Service (QoS)?</p>
        <p class="bullb">• Should the control plane be centralized or decentralized?</p>
        <p class="indent"><a id="page_6"></a>Some of these questions have been long since answered, most often by blending the more extreme elements of each position into a sometimes messy, but generally always useful, solution. Some of these questions are, on the other hand, still active, particularly the last one. Perhaps, in twenty years’ time, readers will be able to look on this last question as being answered, as well.</p>
        <p class="indent">This chapter will describe the basic terms and concepts used in this book from within the framework of these historical movements or stages within the world of network engineering. By the end of this chapter, you will be ready to tackle the first two parts of this book—the forwarding plane and the control plane. The third part, an overview of network design, builds on the first two parts. The final part of this book looks at a few specific technologies and movements likely to shape the future—not only of network engineering, but even of the production and processing of information overall.</p>
        <div class="heading">
        <h3 class="h3" id="ch01lev1">Art or Engineering?</h3>
        <p class="noindent">One question that must be asked, up front, is whether network engineering is an art, or truly engineering. Many engineering fields begin as more of an art. For instance, in the early 1970s, working on and around electronics—tubes, “coils,” and transformers—was largely considered an art. By the mid-1980s, electronics had become ubiquitous, and this began a commoditization process harsher than any standardization. Electronics then was considered more engineering than art. By the 2010s, electronics became “just the stuff that makes up computers.” There is still some art in the designing and troubleshooting of electronics, but, by and large, their creation became more focused on engineering principles. The problems have moved from “how do you do that,” to “what is the cheapest way to do that,” or “what is the smallest way to do that,” or some other problem that would have been considered second order in the earlier days. Perhaps one way to phrase the movement in electronics is in ratios. Perhaps (and these are very rough estimates), electronics started at around 80% art and 20% engineering, and has now moved to 80% engineering and 20% art.</p>
        </div>
        <p class="indent">What about network engineering? Will it pass through the same phases, eventually moving into the 80% engineering, 20% art range? This seems doubtful for several reasons. Network engineering works in a largely virtual space; although there are wires and devices, the protocols, data, and functionality are all laid on top of the physical infrastructure, rather than <em>being</em> the physical infrastructure. Unlike electronics, where you can point to a physical object and say, “this is the product,” a network is not a physical thing. To put this another way, the network is a conceptual “thing” built using a wide array of individual components connected together through <a id="page_7"></a>protocols and data models. This means design choices are almost infinitely variable and malleable. Each problem can be approached, assessed, and designed much more specifically than in electronics. So long as there are new problems to solve, there will be new solutions developed, deployed, and—eventually (finally) removed from networks. Perhaps a useful comparison is between applications and the various kinds of computing devices; no matter how standardized computing devices become, there is still an almost infinite selection of software applications to run on top.</p>
        <p class="indent"><a href="ch01.xhtml#ch01fig01">Figure 1-1</a> will be useful in illustrating this “fit” between the network and the business from one perspective.</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/01fig01.jpg" aria-describedby="Al01fig01" alt="Figure shows the first perspective of the Business to Technology fit." width="537" height="461"><aside class="hidden" id="Al01fig01">
        <p>Overpaying for infrastructure is mentioned at the top with four arrows pointing downward to a dotted line arrangement that looks like a step. Lost business opportunity is at the bottom with three arrows pointing upward to the dotted line. A wavy line is seen along the dotted line.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch01fig01"></a><strong>Figure 1-1</strong> <em>Business to Technology Fit, First Perspective</em></p>
        </div>
        <p class="indent">In <a href="ch01.xhtml#ch01fig01">Figure 1-1</a>, the solid gray curved line is <em>business growth</em>. The dashed black line running vertical and horizontal is <em>network capacity</em>. There are many times when the network is overprovisioned, costing the business money to maintain unused capacity; these are shown in the gray line-shaded regions. There are other times when the network is under strain. In these darker gray solid-shaded regions, the business could grow faster, but the network is holding it back. One of the many objectives of network architecture and design (this is more of an architecture issue than strictly a design issue; see <em>The Art of Network Architecture)</em> is to bring these lines closer together. Accomplishing this part of the work requires creativity and future thinking problem-solving skills. The engineer must ask questions like “How can the <a id="page_8"></a>network be built so it scales larger and smaller to move with the business’s requirements?” This is more than just scale and size; however, it is possible the nature of the business may even change over time, driving changes in applications, operational procedures, and operational pace. The network must have an architecture capable of changing as needed without introducing <em>ossification</em>, or the hardening of systems and processes that will eventually cause the network to fail in a catastrophic way. This part of the working on networks is often considered more <em>art</em> than <em>engineering</em>, and it is not likely to change until the entire business world changes in some way.</p>
        <p class="indent"><a href="ch01.xhtml#ch01fig02">Figure 1-2</a> illustrates another way in which businesses drive network engineering as an art.</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/01fig02.jpg" aria-describedby="Al01fig02" alt="Figure represents features versus usage in networking products." width="679" height="331"><aside class="hidden" id="Al01fig02">
        <p>A graph is represented with Feature Count and Time as its vertical and horizontal axes. Four upward sloping lines are marked in the graph and the area under each of the line represents: Features for network A, Features for network B, Features for network C, and Features for network D.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch01fig02"></a><strong>Figure 1-2</strong> <em>Features versus Usage in Networking Products</em></p>
        </div>
        <p class="indent">In <a href="ch01.xhtml#ch01fig02">Figure 1-2</a>, time runs from the left to the right, and feature count from the bottom to the top. What the chart expresses is the additional features added to a product over time. Network operator A will start out needing a somewhat small feature set, but the feature set required will increase over time; the same will hold true of the other three networks. The feature sets required to run any of these networks will always overlap to some degree, <em>and they will also always be different to some degree</em>. If a vendor wants to be able to sell a single product (or product line) and cater to all four networks, it will need to implement every unique feature required by each network. The entire set of features is depicted by the peak of the chart on the right side. For each of the networks, some percentage of the features available in any product will be unnecessary—also known as <em>code bloat</em>.</p>
        <p class="indent"><a id="page_9"></a>Even though these features are not being used, each one will still represent security vulnerabilities, code that must be tested, code that interacts with features that <em>are</em> being used, etc. In other words, <em>each one of these unused features is actually a liability for the network operator</em>. The ideal solution might be to custom build equipment for each network, containing just the features required—but this is often not a choice available to either the vendor or the network operator. Instead, network engineers must somehow balance between required features and available features—and this process is definitely more a form of <em>art</em> than <em>engineering</em>.</p>
        <p class="indent">So long as there are mismatches between the way networks can be built and the way businesses use networks, there will always be some interplay between <em>art</em> and <em>engineering</em> in networking. The percentage of each one will vary based on the network, tools, and the time within the network engineering field, of course, but the <em>art</em> component will probably always be more strongly represented in the networking field than it is in fields like electronics engineering.</p>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">Some people might object to the use of the word <em>art</em> in this section. It is easy enough to replace <em>art</em> with <em>craft</em>, however, if this makes the concepts in this section easier to understand.</p>
        </div>
        <div class="heading">
        <h3 class="h3" id="ch01lev2">Circuit Switching</h3>
        <p class="noindent">The first large discussion in the computer networking world was whether networks should be circuit switched or packet switched. The basic difference between these two is the concept of a circuit—do the transmitter and receiver “see” the network as a single wire, or connection, preconfigured (or set up) with a specific set of proper-ties before they begin communicating? Or do they “see” the network as a shared resource, where information is simply generated and transmitted “at will”? The former is considered circuit switched, while the latter is considered packet switched. Circuit switching tends to provide more traffic flow and delivery guarantees, while packet switching tends to deliver data at a much lower cost—the first of many tradeoffs you will encounter in network engineering. <a href="ch01.xhtml#ch01fig03">Figure 1-3</a> will be used to illustrate circuit switching, using Time Division Multiplexing (TDM) as an example.</p>
        </div>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/01fig03.jpg" aria-describedby="Al01fig03" alt="Figure shows time division multiplexing based circuit switching." width="701" height="257"><aside class="hidden" id="Al01fig03">
        <p>Routers A, B, C, D, E, and F are present in the figure. Total bandwidth of A is divided into eight blocks and has A1 and A2 enclosed in the first and fourth boxes respectively. Total bandwidth of B is divided into eight blocks and has B1 and B2 enclosed in the second and fourth boxes respectively. A and B are connected to C at the center with a bandwidth merging both A and B, consisting A1, A2, B1, and B2 at its first, fourth, second, and seventh packets respectively. Two lines from D meet E at the top with a bandwidth consisting A1 and B2 at the first and fourth block respectively. F is at the bottom with its bandwidth consisting B1 and A2 at the first and third block respectively. D is also connected to F.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch01fig03"></a><strong>Figure 1-3</strong> <em>Time Division Multiplexing Based Circuit Switching</em></p>
        </div>
        <p class="indent">In <a href="ch01.xhtml#ch01fig03">Figure 1-3</a>, the total bandwidth of the links between any two devices is split up into eight equal parts; A is sending data to E using time slot A1 and F using time slot A2; B is sending data to E using time slot B1 and F using time slot B2. Each piece of information is a fixed length, so each one can be put into a single time slot in the <a id="page_10"></a>ongoing data stream (hence, each block of data represents a fixed amount of time, or slot, on the wire). Assume there is a controller someplace assigning a slot on each of the segments the traffic will traverse:</p>
        <p class="bullt">• <strong>For [A,E] traffic:</strong></p>
        <p class="bull1"><span class="pd_ash">•</span> <strong>At C:</strong> slot 1 from A is switched to slot 1 toward D</p>
        <p class="bull1"><span class="pd_ash">•</span> <strong>At D:</strong> slot 1 from C is switched to slot 1 toward E</p>
        <p class="bull">• <strong>For [A,F] traffic:</strong></p>
        <p class="bull1"><span class="pd_ash">•</span> <strong>At C:</strong> slot 4 from A is switched to slot 4 toward D</p>
        <p class="bull1"><span class="pd_ash">•</span> <strong>At D:</strong> slot 4 from C is switched to slot 3 toward F</p>
        <p class="bull">• <strong>For [B,E] traffic:</strong></p>
        <p class="bull1"><span class="pd_ash">•</span> <strong>At C:</strong> slot 4 from B is switched to slot 7 toward D</p>
        <p class="bull1"><span class="pd_ash">•</span> <strong>At D:</strong> slot 7 from C is switched to slot 4 toward E</p>
        <p class="bull">• <strong>For [B,F] traffic:</strong></p>
        <p class="bull1"><span class="pd_ash">•</span> <strong>At C:</strong> slot 2 from B is switched to slot 2 toward D</p>
        <p class="bull1"><span class="pd_ash">•</span> <strong>At D:</strong> slot 2 from C is switched to slot 1 toward F</p>
        <p class="indentt">None of the packet processing devices in the network need to know which bit of data is going where; so long as C takes whatever is in slot 1 in A’s data stream in each time frame and copies it to slot 1 in its outgoing stream toward D, and D copies it from slot 1 inbound from C to slot 1 outbound to E, traffic transmitted by A <a id="page_11"></a>will be delivered at E. There is an interesting point to note about this kind of traffic processing—to forward the traffic, none of the devices in the network actually need to know what the source or destination is. The blocks of data being transmitted through the network do not need to contain source or destination addresses; where they are headed, and where they are coming from, decisions are all based on the controllers’ knowledge of open slots in each link. The set of slots assigned to any particular device-to-device communications is called a circuit, because it is bandwidth and network resources committed to the communications between the one pair of devices.</p>
        <p class="indent">The primary advantages of circuit switched networks include:</p>
        <p class="bullt">• The devices do not need to read a header, or do any complex processing, to switch packets. This was extremely important in the early days of networking, when hardware had much lower transistor and gate counts, line speeds were lower, and the time to process a packet in the device was a large part of the overall packet delay through the network.</p>
        <p class="bullb">• The controller knows the available bandwidth and traffic being pushed toward the edge devices everywhere in the network. This makes it somewhat simple, given there is actually enough bandwidth available, to engineer traffic to create the most optimal paths through the network possible.</p>
        <p class="indent">There are also disadvantages, including:</p>
        <p class="bullt">• The complexity of the controller ramps up significantly as the network and services it offers grow in scale. The load on the controller can become overwhelming, in fact, causing network outages.</p>
        <p class="bull">• The bandwidth on each link is not used optimally. In <a href="ch01.xhtml#ch01fig03">Figure 1-3</a>, the blocks of time (or <em>cells</em>) containing an <em>*</em> are essentially wasted bandwidth. The slots are assigned to a particular circuit ahead of time: slots used for the [A,E] traffic cannot be “borrowed” for the [A,F] traffic even when A has nothing to transmit toward E.</p>
        <p class="bullb">• The time required to react to changes in topology can be quite long in network terms; the local device must discover the change, report it to the controller, and the controller must reconfigure every network device along the path of each affected traffic flow.</p>
        <p class="indent">TDM systems contributed a number of ideas to the development of the networks used today. In particular, TDM systems molded much of the early discussion <a id="page_12"></a>on breaking data into packets for transmission through the network, and laid the groundwork for much later work in QoS and flow control. One rather significant idea these early TDM systems bequeathed to the larger networking world is <em>network planes</em>.</p>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">Quality of Service is briefly considered in a later section in this chapter, and then in more depth in <a href="ch08.xhtml#ch08">Chapter 8</a>, “<a href="ch08.xhtml#ch08">Quality of Service</a>,” later in this book.</p>
        </div>
        <p class="indent">Specifically, TDM systems are divided into three planes:</p>
        <p class="bullt">• The <strong>control plane</strong> is the set of protocols and processes that build the information necessary for the network devices to forward traffic through the network. In circuit switched networks, the control plane is completely a separate plane; there is normally a separate network between the controller and the individual devices (though not always, particularly in newer circuit switched systems).</p>
        <p class="bull">• The <strong>data plane</strong> (also known as the <em>forwarding</em> plane) is the path of information through the network. This includes decoding the signal received in a wire into frames, processing them, and pushing them back onto the wire, encoded according to the physical transport system.</p>
        <p class="bullb">• The <strong>management plane</strong> is focused on managing the network devices, including monitoring the available memory, monitoring queue depth, and monitoring when the device drops the information being transmitted through the network, etc. It is often difficult to distinguish between the management and the control planes in a network. For instance, if the device is manually configured to forward traffic in a particular way, is this a management plane function (because the device is being configured) or a control plane function (because this is information about how to forward information)?</p>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">This question does not have a definitive answer. Throughout this book, however, anything that impacts the way traffic is forwarded through the network is considered part of the control plane, while anything that impacts the physical or logical state of the device, such as interface state, is considered part of the management plane. Do not expect these definitions to hold true in the real world.</p>
        </div>
        <div class="note">
        <p class="title"><a id="page_13"></a><strong>Note</strong></p>
        <p class="notepara">Frame Relay, SONET, ISDN, and X.25 are examples of circuit switched technology, some of which are still deployed at the time of writing. See the “Further Reading” section for suggested sources for learning about these technologies.</p>
        </div>
        <div class="heading">
        <h3 class="h3" id="ch01lev3">Packet Switching</h3>
        <p class="noindent">In the early- to mid-1960s, packet switching was “in the air.” A lot of people were rethinking the way networks had been built until then, and were considering alternatives to the circuit switched paradigm. Paul Baran, working for the RAND Corporation, proposed a packet switching network as a solution for survivability; around the same time, Donald Davies, in the UK, proposed the same type of system. These ideas made their way to the Lawrence Livermore Laboratory, leading to the first packet switched network (called <em>Octopus)</em> being put into operation in 1968. The ARPANET, an experimental packet switched network, began operation not long after, in 1970.</p>
        </div>
        <div class="heading">
        <h4 class="h4" id="ch01lev4"><strong>Packet Switched Operation</strong></h4>
        </div>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">The actual process of switching a packet is discussed in greater detail in <a href="ch07.xhtml#ch07">Chapter 7</a>, “<a href="ch07.xhtml#ch07">Packet Switching</a>.”</p>
        </div>
        <p class="indent">The essential difference between circuit switching and packet switching is the role individual network devices play in the forwarding of traffic, as <a href="ch01.xhtml#ch01fig04">Figure 1-4</a> illustrates.</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/01fig04.jpg" aria-describedby="Al01fig04" alt="Figure represents a packet switched network." width="700" height="345"><aside class="hidden" id="Al01fig04">
        <p>Routers A, B, C, D, E, and F are present in the figure. Total bandwidth of A is divided into four packets and has H, A1, H, and A2 enclosed. Total bandwidth of B is divided into four packets and has H, B1, H, and B2 enclosed. A and B meet C and D at the center with a bandwidth merging both A and B, consisting H, A1, H, A2, H, B1, H, and B2. Two lines from D meet E at the top with a bandwidth consisting H, A1, H, and B2 and meet F at the bottom with its bandwidth consisting H, B1, H, and A2.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch01fig04"></a><strong>Figure 1-4</strong> <em>Packet Switched Network</em></p>
        </div>
        <p class="indent">In <a href="ch01.xhtml#ch01fig04">Figure 1-4</a>, A produces two blocks of data. Each of these includes a header describing, at a minimum, the destination (represented by the H in each block of data). This complete bundle of information—the original block of data and the header—is called a packet. The header can also describe what is inside the packet, and include any special handling instructions forwarding devices should take when processing the packet—these are sometimes called <em>metadata</em>, or “data about the data in the packet.”</p>
        <p class="indent">There are two packets produced by A: A1, destined to E; and A2, destined to F. B sends two packets as well: B1, destined to F, and B2, destined to E. When C receives <a id="page_14"></a>these packets, it reads a small part of the packet header, often called a field, to determine the destination. C then consults a local table to determine which outbound interface the packet should be transmitted on. D does likewise, forwarding the packet out the correct interface toward the destination.</p>
        <p class="indent">This way of forwarding traffic is called hop-by-hop forwarding, because each device in the network makes a completely independent decision about where to forward each individual packet. The local table each device consults is called a forwarding table; this normally is not one table, but many tables, potentially including a Routing Information Base (RIB) and a Forwarding Information Base (FIB).</p>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">These tables, how they are built, and how they are used, are explained more fully in <a href="ch07.xhtml#ch07">Chapter 7</a>, “<a href="ch07.xhtml#ch07">Packet Switching</a>.”</p>
        </div>
        <p class="indent">In the original circuit switched systems, the control plane is completely separate from packet forwarding through the network. With the move from circuit to packet switched, there was a corresponding move from centralized controller decisions to a distributed protocol running over the network itself. For the latter, each node is capable of making its own forwarding decisions locally. Each device in the network runs the distributed protocol to gain the information needed to build these local tables. This model is called a distributed control plane; thus the idea of a control plane was simply transferred from one model to the other, although they do not actually mean the same thing.</p>
        <div class="note">
        <p class="title"><a id="page_15"></a><strong>Note</strong></p>
        <p class="notepara">Packet switching networks can use a centralized control plane, and circuit switching networks can use distributed control planes. At the time packet switched networks were first designed and deployed, however, they typically used distributed control planes. Software-Defined Networks (SDNs) brought the concept of centralized control planes back into the world of packet switched networks.</p>
        </div>
        <p class="indent">The first advantage the packet switched network has over a circuit switched network is the hop-by-hop forwarding paradigm. As each device can make a completely independent forwarding decision, packets can be dynamically forwarded around changes in the network topology, eliminating the need to communicate to the controller and await a decision. So long as there are at least two paths between the source and the destination (the network is two connected), packets handed to the network by the source will eventually be handed to the destination by the network.</p>
        <p class="indent">The second advantage the packet switched network has over a circuit switched network is the way the packet switched network uses bandwidth. In the circuit switched network, if a particular circuit (really a time slot in the TDM example given) is not used, then the slot is simply wasted. In hop-by-hop forwarding, each device can best use the bandwidth available on each outbound link to carry the necessary traffic load. While this is <em>locally</em> more complex, it is <em>globally</em> simpler, and it makes better use of network resources.</p>
        <p class="indent">The primary disadvantage of packet switched networks is the additional complexity required, particularly in the forwarding process. Each device must be able to read the packet header, look up the destination in a table, and then forward the information based on the table lookup results. In early hardware, these were difficult, time-consuming tasks; circuit switching was generally faster than packet switching. As hardware has improved over time, the speed of switching a variable length packet is generally close enough to the speed of switching a fixed length packet that there is little difference between packet and circuit switching.</p>
        <div class="heading">
        <h4 class="h4" id="ch01lev5"><strong>Flow Control in Packet Switched Networks</strong></h4>
        <p class="noindent">In a circuit switched network, the controller allocates a specific amount of band-width to each circuit by assigning time slots from the source to the destination. What happens if the transmitter wants to send more traffic than the allocated time slots will support? The answer is simple—<em>it cannot</em>. In a sense, then, the ability to control the flow of packets through the network is built in to a circuit switched network; <a id="page_16"></a>there is no way to send more traffic than the network can forward, because “space” the transmitter has at its disposal for information sending is pre-allocated.</p>
        </div>
        <p class="indent">What about packet switched networks? If all the links in the network shown in <a href="ch01.xhtml#ch01fig04">Figure 1-4</a> have the same link speed, what happens if both A and B want to use the entire link capacity toward C? How will C decide how to send it all to D on a link that is half as large as the traffic it needs to handle? Here is where traffic flow control techniques can be used. Typically, they are implemented as a separate protocol/rule set “riding on top of” the underlying network, helping to “organize” packet transmission by building a virtual circuit between the two communicating devices.</p>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">Flow and error control are discussed in detail in <a href="ch02.xhtml#ch02">Chapter 2</a>, “<a href="ch02.xhtml#ch02">Data Transport Problems and Solutions</a>.”</p>
        </div>
        <p class="indent">The Transmission Control Protocol (TCP) provides flow control for Internet Protocol (IP) based packet switched networks. This protocol was first specified in 1973 by Vint Cerf and Bob Kahn.</p>
        <div class="sidebar1">
        <p class="title1"><strong>The Protocol Wars</strong></p>
        <p class="noindent">In the development of packet switched networks, a number of different protocols (or protocol stacks) were developed. Over time, all of them have been abandoned in favor of the IP suite of protocols. For instance, Banyan Vines had its own protocol suite based on IP called Vines Internet Protocol (VIP), and Novell Netware had its own protocol suite based on a protocol called IPX. Other standards bodies created standard protocol suites as well, such as the International Telecommunications Union’s (ITU) suite of protocols built around Connectionless Mode Network Service (CLNS).</p>
        <p class="indent">Why did all of these protocol suites fall by the wayside? Some of them were proprietary, and many governments and large organizations rejected proprietary solutions to packet switched networking for a wide range of reasons. The proprietary solutions were often not as well thought out, either, as they were generally developed and maintained by a small group of people. Standards-based protocols can be more complex, but they also tend to be developed and maintained by a larger group of experienced engineers. The protocol suite based on CLNS was a serious contender for some time, but it just never really caught on in the global Internet, which was becoming an important economic force at the time. <a id="page_17"></a>There were some specific technical reasons for this—for instance, CLNS does not number <em>wires</em>, but hosts. The aggregation of reachability information (concepts covered in more detail later in this book) is therefore limited in many ways.</p>
        <p class="indent">An interesting reference for the discussion between the CLNS and IP protocol suites is <em>The Elements of Networking Style</em>.<sup><a id="ch01fn1"></a><a href="ch01.xhtml#ch01fn-1">1</a></sup></p>
        </div>
        <div class="heading">
        <h3 class="h3" id="ch01lev6">Fixed Versus Variable Length Frames</h3>
        <p class="noindent">In the late 1980s, a new topic of discussion washed over the network engineering world—Asynchronous Transfer Mode (ATM). The need for ever higher speed circuits, combined with slow progress in switching packets individually based on their destination addresses, led to a push for a new form of transport that would, eventually, reconfigure the entire set (or stack, because each protocol forms a layer on top of the protocol below, like a “stacked cake”) of protocols used in modern networks. ATM combined the fixed length cell (or packet) size of circuit switching with a header from packet switching (although greatly simplified) to produce an “in between” technology solution. There were two key points to ATM: label switching and fixed call sizes; <a href="ch01.xhtml#ch01fig05">Figure 1-5</a> illustrates the first.</p>
        </div>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/01fig05.jpg" aria-describedby="Al01fig05" alt="Figure represents the process of label switching." width="701" height="258"><aside class="hidden" id="Al01fig05">
        <p>Routers A, B, C, D, E, and F are present in the figure. A computer, G has three blocks with two packets, H and A1 enclosed in the second and third block. A line leads to A with a total bandwidth of three packets and has L, H, and A1 enclosed. B is below with no packets assigned to it. A and B meet C at the center with a bandwidth matching As bandwidth, consisting L, H, and A1. A line reads from C to D which is identical as C. Two lines move from D to meet E at the top which is empty and F at the bottom with its bandwidth consisting L, H, and A1. A line reads from the right of F to meet a computer, H that has three blocks with two packets, H, and A1 enclosed in the second and third block.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch01fig05"></a><strong>Figure 1-5</strong> <em>Label Switching</em></p>
        </div>
        <p class="indent">In <a href="ch01.xhtml#ch01fig05">Figure 1-5</a>, G sends a packet destined to H. On receiving this packet, A examines a local table, and finds the next hop toward H is C. A’s local table also specifies a <a id="page_18"></a>label, shown as L, rather than “just” information about where to forward the packet. A inserts this label into a dedicated field at the head of the packet and forwards it to C. When C receives the packet, it does not need to read the destination address in the header; rather, it just reads the label, which is a short, fixed length field. The label is looked up in a local table, which tells C to forward traffic to D for destination H. The label is very small, and is therefore easy to process for the forwarding devices, making switching much faster.</p>
        <p class="indent">The label can also “contain” handling information for the packet, in a sense. For instance, if there are actually two streams of traffic between G and H, each one can be assigned a different label (or set of labels) through the network. Packets carrying one label can be given priority over packets carrying another label, so the network devices do not need to look at any fields in the header to determine how to process a particular packet.</p>
        <p class="indent">This can be seen as a compromise between packet and circuit switching. While each packet is still forwarded hop by hop, a virtual circuit can also be defined by the label path through the network. The second point was that ATM was also based on a fixed sized cell: each packet was limited to 53 octets of information. Fixed size cells may seem to be a minor issue, but fixed size packets can make a huge performance difference. <a href="ch01.xhtml#ch01fig06">Figure 1-6</a> illustrates some factors involved in fixed cell sizes.</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/01fig06.jpg" aria-describedby="Al01fig06" alt="Figure represents fixed cell sizes." width="700" height="364"><aside class="hidden" id="Al01fig06">
        <p>A row labeled Packet 1 at the top has a box labeled A1 to the left. An arrow leads from it to another box to the right labeled A1. An arrow leads upward from A1 to meet Memory at the top. Copy is adjacent to it and has an arrow leading downward to A1. An arrow leads to the right to meet A1 and another arrow leads from the box to the right to meet A1. Another row labeled Packet 2 has a box labeled A1 to the left that has an arrow leading to the right, meeting A1. An arrow reads upward from A1 to meet Fragment. An arrow leads to from Fragment from a block with two packets, A1 and A2 enclosed. An arrow leads upward to meet Memory. Copy is adjacent to it with an arrow pointing to it from a block with two packets, A1 and A2 enclosed. A line leads to the right, meeting a block with two packets, A1 and A2 enclosed. An arrow leads to the right to meet another block with two packets, A1 and A2. A computer, A is below and has a line pointing to the right, meeting a box labeled LC1 which is enclosed in dotted lines. A rectangle labeled Fabric is at the center, meeting a box labeled LC2 to the right. The whole dotted portion is labeled B. A line leads from LC2 to the right, meeting C. A line leads from C to the right, meeting a computer labeled D.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch01fig06"></a><strong>Figure 1-6</strong> <em>Fixed Cell Sizes</em></p>
        </div>
        <p class="indent">In <a href="ch01.xhtml#ch01fig06">Figure 1-6</a>, packet 1 (A1) is copied from the network into memory on a line card or interface, <em>LC1;</em> then it travels across the internal fabric inside B (between memory locations) to <em>LC2</em>, being finally placed back onto the network at B’s outbound interface. It might seem trivial from such a diagram, but perhaps the most <a id="page_19"></a>important factor in the speed at which a device can switch/process packets is the time it takes to copy the packet across any internal paths between memory locations. The process of copying information from one place in memory to another is one of the slowest operations a device can undertake, particularly on older processors. Making every packet the same (a fixed cell size) allowed code optimizations around the copy process, dramatically increasing switching speed.</p>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">The process of switching a packet across an internal fabric is considered in <a href="ch07.xhtml#ch07">Chapter 7</a>, “<a href="ch07.xhtml#ch07">Packet Switching</a>.”</p>
        </div>
        <p class="indent">Packet 2’s path through B is even worse from a performance perspective; it is copied off the network into local memory first. When the destination port is determined by looking in the local forwarding table, the code processing the packet realizes the packet must be fragmented to fit into the largest packet size allowed on the outbound [B,C] link. The inbound line card, <em>LC1</em>, fragments the packet into <em>A1</em> and <em>A2</em>, creating a second header and adjusting any values in the header as needed. The packet is divided into two packets, A1 and A2. These two packets are copied in two operations across the fabric to the outbound line card, <em>LC2</em>. By using fixed size cells, ATM avoids the performance cost of fragmenting packets (at the time ATM was being proposed) incurred by almost every other packet switching system.</p>
        <p class="indent">ATM did not, in fact, start at the network core and work its way to the network edge. Why not? The first answer lies in the rather strange choice of cell size. Why 53 octets? The answer is simple—and perhaps a little astounding. ATM was supposed to replace not only packet switched networks, but also the then-current generation of voice networks based on circuit switched technologies. In unifying these two technologies, providers could offer both sorts of services on a single set of circuits and devices.</p>
        <p class="indent">What amount of information, or packet size, is ideal for carrying voice traffic? Around 48 octets. What amount of information, or packet size, is the minimum that makes any sort of sense for data transmission? Around 64 octets. Fifty-three octets was chosen as a compromise between these two sizes; it would not be perfect for voice transmission, as 5 octets of every cell carrying voice would be wasted. It would not be perfect for data traffic, because the most common packet size, 64 octets, would need to be split into two cells to be carried across an ATM network. A common line of thinking, at the time these deliberations were being held, was the data transport protocols would be able to adjust to the slightly smaller cell size, hence making 53 octets an optimal size to support a wide variety of traffic. The data transport protocols, however, did not adjust. To transport a 64-octet block of <a id="page_20"></a>data, one cell would contain 53 octets, and the second would contain 9 octets, with 42 octets of empty space. Providers discovered 50% or more of the bandwidth available on ATM links was consumed by empty cells—effectively wasted bandwidth. Hence, data providers stopped deploying ATM, voice providers never really started deploying it, and ATM died.</p>
        <p class="indent">What is interesting is how the legacy of projects like ATM live on in other protocols and ideas. The label switching concept was picked up by Yakov Rekhter and other engineers, and developed into <em>label switching</em>. This keeps many of the fundamental advantages of ATM’s quick lookup in the forwarding path, and bundling the metadata about packet handling into the label itself. Label switching eventually became Multiprotocol Label Switching (MPLS), which not only provides faster lookup, but also stacks of labels and virtualization. The basic idea was thus taken and expanded, impacting modern network protocols and designs in significant ways.</p>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">MPLS is discussed in <a href="ch09.xhtml#ch09">Chapter 9</a>, “<a href="ch09.xhtml#ch09">Network Virtualization</a>.”</p>
        </div>
        <p class="indent">The second legacy of ATM is the fixed cell size. For many years, the dominant network transport suite, based on TCP and IP, has allowed network devices to fragment packets while forwarding them. This is a well-known way to degrade the performance of a network, however. A <em>do not fragment</em> bit was added to the IP header, telling network devices to drop packets rather than fragmenting them, and serious efforts were put into discovering the largest packet that can be transmitted through the network between any pair of devices. A newer generation of IP, called IPv6, removed fragmentation by network devices from the protocol specification.</p>
        <div class="heading">
        <h3 class="h3" id="ch01lev7">Calculating Loop-Free Paths</h3>
        <p class="noindent">Overlapping many of these previous discussions within the network engineering world was another issue that often made it more difficult to decide whether packet or circuit switching was the better solution. How should loop-free paths be computed in a packet switched network?</p>
        </div>
        <p class="indent">As packet switched networks have, throughout the history of network engineering, been associated with distributed control planes, and circuit switched networks have been associated with centralized control planes, the issue of computing loop-free paths efficiently had a major impact on deciding whether packet switched networks were viable or not.</p>
        <a id="page_21"></a>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">Loop-free paths are discussed in <a href="part2.xhtml#part2">Part II</a>, “<a href="part2.xhtml#part2">The Control Plane</a>.”</p>
        </div>
        <p class="indent">In the early days of network engineering, the available processing power, memory, and bandwidth were often in short supply. <a href="ch01.xhtml#ch01tab01">Table 1-1</a> provides a little historical context.</p>
        <div class="tab-heading">
        <p class="tab-caption"><a id="ch01tab01"></a><strong>Table 1-1</strong> <em>History of Computing Power, Memory, and Bandwidth</em></p>
        <table class="tablewidth">
        <tbody>
        <tr>
        <td class="bg1"><p class="thead"><strong>Year</strong></p></td>
        <td class="bg1"><p class="thead"><strong>MIPS</strong></p></td>
        <td class="bg1"><p class="thead"><strong>Memory (Cost/MB)</strong></p></td>
        <td class="bg1"><p class="thead"><strong>Bandwidth (LAN)</strong></p></td>
        </tr>
        <tr>
        <td class="tbody_first"><p class="noindent">1984</p></td>
        <td class="tbody_first"><p class="noindent">3.2 (Motorola 68010)</p></td>
        <td class="tbody_first"><p class="noindent">1331</p></td>
        <td class="tbody_first"><p class="noindent">2Mb/s</p></td>
        </tr>
        <tr>
        <td class="tbody_first"><p class="noindent">1987</p></td>
        <td class="tbody_first"><p class="noindent">6.6 (Motorola 68020)</p></td>
        <td class="tbody_first"><p class="noindent">154</p></td>
        <td class="tbody_first"><p class="noindent">10Mb/s</p></td>
        </tr>
        <tr>
        <td class="tbody_first"><p class="noindent">1990</p></td>
        <td class="tbody_first"><p class="noindent">44 (Motorola 68040)</p></td>
        <td class="tbody_first"><p class="noindent">98</p></td>
        <td class="tbody_first"><p class="noindent">16Mb/s</p></td>
        </tr>
        <tr>
        <td class="tbody_first"><p class="noindent">1996</p></td>
        <td class="tbody_first"><p class="noindent">541 (Intel Pentium Pro)</p></td>
        <td class="tbody_first"><p class="noindent">8</p></td>
        <td class="tbody_first"><p class="noindent">100Mb/s</p></td>
        </tr>
        <tr>
        <td class="tbody_first"><p class="noindent">1999</p></td>
        <td class="tbody_first"><p class="noindent">2,054 (Intel Pentium III)</p></td>
        <td class="tbody_first"><p class="noindent">1</p></td>
        <td class="tbody_first"><p class="noindent">100Mbp/s</p></td>
        </tr>
        <tr>
        <td class="tbody_first"><p class="noindent">2006</p></td>
        <td class="tbody_first"><p class="noindent">49,161 (Intel Core 2, 4 cores)</p></td>
        <td class="tbody_first"><p class="noindent">0.1</p></td>
        <td class="tbody_first"><p class="noindent">4Gb/s</p></td>
        </tr>
        <tr>
        <td class="tbody_first"><p class="noindent">2014</p></td>
        <td class="tbody_first"><p class="noindent">238,310 (Intel i7, 4 cores)</p></td>
        <td class="tbody_first"><p class="noindent">0.001</p></td>
        <td class="tbody_first"><p class="noindent">100Gb/s</p></td>
        </tr>
        </tbody>
        </table>
        </div>
        <p class="indent">In 1984, when many of these discussions were occurring, any difference in the amount of processor and memory between two ways of calculating loop-free paths through a network would have a material impact on the cost of building a network. When bandwidth is at a premium, reducing the number of bits a control plane required to transfer the information required to calculate a set of loop-free paths through a network makes a real difference in the amount of user traffic the network can handle. Reducing the number of bits required for the control to operate also makes a large difference in the stability of the network at lower bandwidths.</p>
        <p class="indent">For instance, using a Type Length Vector (TLV) format to describe control plane information carried across the network adds a few octets of information to the overall packet length—but in the context of a 2Mbps link, aggravated by a chatty control plane, the costs could far outweigh the longer-term advantage of protocol extensibility.</p>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">TLVs are discussed in <a href="ch02.xhtml#ch02">Chapter 2</a>, “<a href="ch02.xhtml#ch02">Data Transport Problems and Solutions</a>.”</p>
        </div>
        <p class="indent"><a id="page_22"></a>The protocol wars were rather heated at some points; entire research projects were undertaken, and papers written, about why and how one protocol was better than another. As an example of the kind of back and forth these arguments generated, a shirt seen at the Internet Engineering Task Force (IETF) during which the Open Shortest Path First (OSPF) Protocol was being developed said: <em>IS-IS = 0</em>. The “IS-IS” here refers to <em>Intermediate System-to-Intermediate System</em>, a control plane (routing protocol) originally developed by the International Organization for Standardization (ISO).</p>
        <p class="indent">There was a wide variety of mechanisms proposed to solve the problems of calculating loop-free paths through a network; ultimately three general classes of solutions have been widely deployed and used:</p>
        <p class="bullt">• <strong>Distance Vector</strong> protocols, which calculate loop-free paths hop by hop based on the path cost</p>
        <p class="bull">• <strong>Link State</strong> protocols, which calculate loop-free paths across a database synchronized across the network devices</p>
        <p class="bullb">• <strong>Path Vector</strong> protocols, which calculate loop-free paths hop by hop based on a record of previous hops</p>
        <p class="indent">The discussion over which protocol is best for each specific network, and for what particular reasons, still persists; it is probably a never-ending conversation, as there is (probably) no final answer to the question. Instead, as with fitting a network to a business, there will probably always be some degree of art (or craft) involved in making a particular control plane work on a particular network. Much of the urgency in the question, however, has been drawn out by the increasing speed of networks—in processing power, memory, and bandwidth.</p>
        <div class="heading">
        <h3 class="h3" id="ch01lev8">Quality of Service</h3>
        <p class="noindent">As real-time traffic started to be carried over packet switched networks, QoS became a major problem. Voice and video both rely on the network being able to carry traffic between hosts quickly (having low delay), and with small amounts of variability in interpacket spacing (jitter). Discussions around QoS actually began in the early days of packet switched networking, but reached a high point around the time ATM was being considered. In fact, one of the main advantages of ATM was the ability to closely control the way in which packets were handled as they were carried over a packet switched network. With the failure of ATM in the <a id="page_23"></a>market, two distinct lines of thought emerged about applications that require strong controls on <em>jitter</em> and <em>delay</em>:</p>
        </div>
        <p class="bullt">• These applications would never work on packet switched networks; these kinds of applications would always need to be run on a separate network.</p>
        <p class="bullb">• It is just a matter of finding the right set of QoS controls to allow such applications to run on packet switched networks.</p>
        <div class="note">
        <p class="title"><strong>Note</strong></p>
        <p class="notepara">Quality of Service is discussed in detail in <a href="ch08.xhtml#ch08">Chapter 8</a>, “<a href="ch08.xhtml#ch08">Quality of Service</a>.”</p>
        </div>
        <p class="indent">The primary application most providers and engineers were concerned about was voice, and the fundamental question came down to this: is it possible to provide decent voice over a network also carrying large file transfers and other “non-real-time” traffic? Complex schemes were invented to allow packets to be classified and marked (called QoS marking) so network devices would know how to handle them properly. Mapping systems were developed to carry these QoS markings from one type of network to another, and a lot of time and effort were put into researching queueing mechanisms—the order in which packets are sent out on an interface. <a href="ch01.xhtml#ch01fig07">Figure 1-7</a> shows a sample chart of one QoS system and the mapping between applications and QoS markings will suffice to illustrate the complexity of these systems.</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/01fig07.jpg" aria-describedby="Al01fig07" alt="Pie chart represents QoS Planning and Mapping." width="690" height="486"><aside class="hidden" id="Al01fig07">
        <p>Figure shows a pie chart enclosed in another pie chart. The inner pie chart has Best Effort 25% enclosed. The outer pie chart shows Best Effort 25%. To the right, the inner pie chart has Real Time 33% enclosed. The outer pie chart has it divided into two sections labeled, Voice 18% and Interactive Video 15% to make for 33% real time. A portion labeled Critical Data 37% is enclosed in the inner pie chart with six sections at the outer pie chart labeled, Streaming Video 10%, Network Management 5%, Transactional Data 5%, Mission Critical Data 7%, Call Signaling 5%, and Internetwork Control 5%. Bulk 5% is to the right in the inner pie chart with two sections, Scavenger 1% and Bulk 4% at the outer pie chart.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch01fig07"></a><strong>Figure 1-7</strong> <em>QoS Planning and Mapping</em></p>
        </div>
        <p class="indent">The increasing link speeds, shown previously in <a href="ch01.xhtml#ch01tab01">Table 1-1</a>, had two effects on the discussion around QoS:</p>
        <p class="bullt">• Faster links will (obviously) carry more data. As any individual voice and video stream becomes a shrinking part of the overall bandwidth usage, the need to strongly balance the use of bandwidth between different applications became less important.</p>
        <p class="bullb">• The amount of time required to move a packet from memory onto the wire through a physical chip is reduced with each increase in bandwidth.</p>
        <p class="indent">As available bandwidth increased, the need for complex queueing strategies to counter jitter became less important. This increase in speed has been augmented by newer queueing systems that are much more effective at managing different kinds of traffic, reducing the necessity of marking and handling traffic in a fine-grained fashion.</p>
        <p class="indent"><a id="page_24"></a>These increases in bandwidth were often enabled by changing from copper to glass fiber. Fiber not only offers larger bandwidths but also more reliable transmission of data. The way physical links are built also evolved, making them more resistant to breakage and other material problems. A second factor increasing bandwidth availability was the growth of the Internet. As networks became more common and more connected, a single link failure had a lesser impact on the amount of available bandwidth and on the traffic flows across the network.</p>
        <p class="indent">As processors became faster, it became possible to develop systems where dropped and delayed packets would have less effect on the quality of a real-time stream. Increasing processor speeds also made it possible to use very effective compression algorithms, reducing the size of each stream. On the network side, faster processors meant the control plane could compute a set of loop-free paths through the network faster, reducing both direct and indirect impacts of link and device failures.</p>
        <p class="indent">Ultimately, although QoS is still important, it can be much simplified. Four to six queues are often enough to support even the most difficult applications. If more are needed, some systems can now either engineer traffic flows through a network or <a id="page_25"></a>actively manage queues, to balance between the complexity of queue management and application support.</p>
        <div class="heading">
        <h3 class="h3" id="ch01lev9">The Revenge of Centralized Control Planes</h3>
        <p class="noindent">In the 1990s, in order to resolve many of the perceived problems with packet switched networks, such as complex control planes and QoS management, researchers began working on a concept called <em>Active Networking</em>. The general idea was that the control plane for a packet switched network could, and should, be separated from the forwarding devices in order to allow the network to interact with the applications running on top of it.</p>
        </div>
        <p class="indent">The basic concept of separating the control and data planes more distinctly in packet switching networks was again considered in the formation of the Forwarding and Control Element Separation (ForCES) working group in the IETF. This working group was primarily concerned with creating an interface applications can use to install forwarding information onto network devices. The working group was eventually shut down in 2015 and its standards were never widely implemented.</p>
        <p class="indent">In 2006, researchers began looking for a way to experiment with control planes in packet switched networks without the need to code modifications on the devices themselves—a particular problem, as most of these devices were sold by vendors as unmodifiable appliances (or black boxes). The eventual result was <em>OpenFlow</em>, a standard interface that allows applications to install entries directly in the forwarding table (rather than the routing table; this is explained more fully in several places in <a href="part1.xhtml#part1">Part I</a> of this book, “<a href="part1.xhtml#part1">The Data Plane</a>”). The research project was picked up as a feature by several vendors, and a wide array of controllers have been created by vendors and open source projects. Many engineers believed OpenFlow would revolutionize network engineering by centralizing the control plane.</p>
        <p class="indent">The reality is likely to be far different—what is likely to happen is what has always happened in the world of data networking: the better parts of a centralized control plane will be consumed into existing systems, and the fully centralized model will fall to the wayside, leaving in its path changed ideas about how the control plane interacts with applications and the network at large.</p>
        <div class="heading">
        <h3 class="h3" id="ch01lev10">Complexity</h3>
        <p class="noindent">The technologies described thus far—circuit and packet switching, control planes, and QoS—are very complex. In fact, there appears to be no end to the increasing <a id="page_26"></a>complexity in networks, particularly as applications and businesses become more demanding. This section will consider two specific questions in relation to complexity and networks:</p>
        </div>
        <p class="bullt">• What is network complexity?</p>
        <p class="bullb">• Can network complexity be “solved”?</p>
        <p class="indent">The final parts of this section will consider a way of looking at complexity as a set of tradeoffs.</p>
        <div class="heading">
        <h4 class="h4" id="ch01lev11"><strong>Why So Complex?</strong></h4>
        <p class="noindent">While the most obvious place to begin might be with a definition of complexity, it is actually more useful to consider why complexity is required in a more general sense. To put it more succinctly, is it possible to “solve” complexity? Why not just design simpler networks and protocols? Why does every attempt to make anything simpler in the networking world end up apparently making things more complex in the long run?</p>
        </div>
        <p class="indent">For instance, by tunneling on top of (or through) IP, the control plane’s complexity is reduced, and the network is made simpler overall. Why then do tunneled overlays end up containing so much complexity?</p>
        <p class="indent">There are two answers to this question. <em>First</em>, human nature being what it is, engineers will always invent ten different ways to solve the same problem. This is especially true in the virtual world, where new solutions are (relatively) easy to deploy, it is (relatively) easy to find a problem with the last set of proposed solutions, and it is (relatively) easy to move some bits around to create a new solution that is “better than the old one.” This is particularly true from a vendor perspective, when building something new often means being able to sell an entirely new line of products and technologies—even if those technologies look very much like the old ones. The virtual space, in other words, is partially so messy because it is so easy to build something new there.</p>
        <p class="indent">The <em>second</em> answer, however, lies in a more fundamental problem: complexity is necessary to deal with the uncertainty involved in difficult to solve problems. <a href="ch01.xhtml#ch01fig08">Figure 1-8</a> illustrates.</p>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/01fig08.jpg" aria-describedby="Al01fig08" alt="Figure shows a graphical representation of complexity, effectiveness, and robustness." width="655" height="258"><aside class="hidden" id="Al01fig08">
        <p>A graph has Increasing mentioned in the vertical axis. A line labeled Complexity is inclined at around 45 degree angle between the horizontal and vertical axis. A curved, dotted line, labeled Solution Effectiveness leads upward and flows horizontally. A curved, dotted line, labeled Robustness reads upward to a point and goes down, reaching the bottom.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch01fig08"></a><strong>Figure 1-8</strong> <em>Complexity, Effectiveness, and Robustness</em></p>
        </div>
        <p class="indentb">Adding complexity seems to allow a network to handle future requirements and unexpected events more easily, as well as provide more services over a smaller set of base functions. If this is the case, why not simply build a single protocol running on a single network able to handle all the requirements potentially thrown at it and can handle any sequence of events you can imagine? A single network running a single <a id="page_27"></a>protocol would certainly reduce the number of moving parts network engineers need to deal with, making all our lives simpler, right? In fact, there are a number of different ways to manage complexity, for instance:</p>
        <p class="indenthangingN">1. Abstract the complexity away, to build a black box around each part of the system, so each piece and the interactions between these pieces are more immediately understandable.</p>
        <p class="indenthangingN">2. Toss the complexity over the cubicle wall—to move the problem out of the networking realm into the realm of applications, or coding, or a protocol. As RFC1925 says, “It is easier to move a problem around (e.g., by moving the problem to a different part of the overall network architecture) than it is to solve it.”</p>
        <p class="indenthangingN">3. Add another layer on top, to treat all the complexity as a black box by putting another protocol or tunnel on top of what’s already there. Returning to RFC1925, “It is always possible to add another level of indirection.”</p>
        <p class="indenthangingN">4. Become overwhelmed with the complexity, label what exists as “legacy,” and chase some new shiny thing perceived to be able to solve all the problems in a much less complex way.</p>
        <p class="indenthangingN">5. Ignoring the problem and hoping it will go away. Arguing for an exception “just this once,” so a particular business goal can be met, or some problem fixed, within a very tight schedule, with the promise that the complexity issue will be dealt with “later,” is a good example.</p>
        <p class="indentt"><a id="page_28"></a>Each of these solutions, however, has a set of tradeoffs to consider and manage. Further, at some point, any complex system becomes brittle—<em>robust yet fragile</em>. A system is robust yet fragile when it is able to react resiliently to an expected set of circumstances, but an unexpected set of circumstances will cause it to fail. To give an example from the real world—knife blades are required to have a somewhat unique combination of characteristics. They must be hard enough to hold an edge and cut, and yet flexible enough to bend slightly in use, returning to their original shape without any evidence of damage, and they must not shatter when dropped. It has taken years of research and experience to find the right metal to make a knife blade from, and there are still long and deeply technical discussions about which material is right for specific properties, under what conditions, etc.</p>
        <p class="blockquote">“Trying to make a network proof against predictable problems tends to make it fragile in dealing with unpredictable problems (through an ossification effect as you mentioned). Giving the same network the strongest possible ability to defend itself against unpredictable problems, it necessarily follows, means that it MUST NOT be too terribly robust against predictable problems. Not being too robust against predictable problems is necessary to avoid the ossification issue, but not necessarily sufficient to provide for a robust ability to handle unpredictable network problems.” —Tony Przygienda</p>
        <p class="blockquote">Complexity is necessary, then: it cannot be “solved.”</p>
        <div class="heading">
        <h4 class="h4" id="ch01lev12"><strong>Defining Complexity</strong></h4>
        <p class="noindent">Given complexity is necessary, engineers are going to need to learn to manage it in some way, by finding or building a model or framework. The best place to begin in building such a model is with the most fundamental question: What does complexity mean in terms of networks? Can you put a network on a scale and have the needle point to “complex”? Is there a mathematical model into which you can plug the configurations and topology of a set of network devices to produce a “complexity index”? How do the concepts of scale, resilience, brittleness, and elegance relate to complexity? The best place to begin in building a model is with an example.</p>
        </div>
        <div class="heading">
        <h5 class="h5" id="ch01level1"><em><strong>Control Plane State versus Stretch</strong></em></h5>
        <p class="noindent">What is network stretch? In the simplest terms possible, it is the difference between the shortest path in a network and the path that traffic between two points actually takes. <a href="ch01.xhtml#ch01fig09">Figure 1-9</a> illustrates this concept.</p>
        </div>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/01fig09.jpg" aria-describedby="Al01fig09" alt="A network of routers is shown." width="692" height="323"><aside class="hidden" id="Al01fig09">
        <p>Figure represents five routers, A, B, C, D, and E connected to illustrate state and stretch.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch01fig09"></a><strong>Figure 1-9</strong> <em>A Small Network to Illustrate State and Stretch</em></p>
        </div>
        <p class="indent">Assuming the cost of each link in this network is 1, the shortest physical path between Routers A and C will also be the shortest logical path: [A,B,C]. What <a id="page_29"></a>happens, however, if the metric on the [A,B] link is changed to 3? The shortest physical path is still [A,B,C], but the shortest logical path is now [A,D,E,C]. The differential between the shortest physical path and the shortest logical path is the distance a packet being forwarded between Routers A and C must travel—in this case, the stretch can be calculated as (4 [A,D,E,C])−(3 [A,B,C]), for a stretch of 1.</p>
        <div class="heading">
        <h5 class="h5" id="ch01level2"><em><strong>How Is Stretch Measured?</strong></em></h5>
        <p class="noindent">The way stretch is measured depends on what is most important in any given situation, but the most common way is by comparing hop counts through the network, as is used in the examples here. In some cases, it might be more important to consider the metric along two paths, the delay along two paths, or some other metric, but the important point is to measure it consistently across every possible path to allow for accurate comparison between paths.</p>
        </div>
        <p class="indent">It is sometimes difficult to differentiate between the physical topology and the logical topology. In this case, was the [A,B] link metric increased because the link is actually a slower link? If so, whether this is an example of stretch, or an example of simply bringing the logical topology in line with the physical topology is debatable.</p>
        <p class="indent">In line with this observation, it is much easier to define policy in terms of stretch than almost any other way. Policy is any configuration that increases the stretch of a network. Using <em>Policy-Based Routing</em>, or <em>Traffic Engineering</em>, to push traffic off the shortest physical path and onto a longer logical path to reduce congestion on specific links, for instance, is a policy—it increases stretch.</p>
        <p class="indent">Increasing stretch is not always a bad thing. Understanding the concept of stretch simply helps us understand various other concepts and put a framework around <a id="page_30"></a>complexity and optimization tradeoffs. The shortest path, physically speaking, is not always the best path.</p>
        <p class="indent">Stretch, in this illustration, is very simple—it impacts every destination, and every packet flowing through the network. In the real world, things are more complex. Stretch is actually per source/destination pair, making it very difficult to measure on a network-wide basis.</p>
        <div class="heading">
        <h5 class="h5" id="ch01level3"><em><strong>Defining Complexity: A Model</strong></em></h5>
        <p class="noindent">Three components—state, optimization, and surface—are common in virtually every network or protocol design decision. These can be seen as a set of tradeoffs, as illustrated in <a href="ch01.xhtml#ch01fig10">Figure 1-10</a> and described in the list that follows.</p>
        </div>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/01fig10.jpg" aria-describedby="Al01fig10" alt="Figure represents the plane of the possible." width="564" height="730"><aside class="hidden" id="Al01fig10">
        <p>A vertical, dotted line labeled Surface is at the top has a dotted line labeled (de)Optimization perpendicular to it. Another dotted line labeled State is perpendicular to (de)Optimization. An bowed inward arc is seen over the dotted lines. The space between the dotted lines and the arc is marked and labeled Realm of the impossible. The plane above the arc is labeled Plane of the possible.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch01fig10"></a><strong>Figure 1-10</strong> <em>The Plane of the Possible</em></p>
        </div>
        <p class="bullt">• Increasing optimization always moves toward more state or more interaction surfaces.</p>
        <p class="bull">• Decreasing state always moves toward less optimization or more interaction surfaces.</p>
        <p class="bullb">• Decreasing interaction surfaces always moves toward less optimization or more state.</p>
        <p class="indent">These are no ironclad rules, of course; they are contingent on the specific network, protocols, and requirements, but they are generally true often enough to make this a useful model for understanding tradeoffs in complexity.</p>
        <div class="heading">
        <h5 class="h5" id="ch01level4"><em><strong>Interaction Surfaces</strong></em></h5>
        <p class="noindent">While state and optimization are fairly intuitive, it is worthwhile to spend just a moment more on interaction surfaces. The concept of interaction surfaces is difficult to grasp primarily because it covers such a wide array of ideas. Perhaps an example would be helpful; assume a function that</p>
        </div>
        <p class="bullt">• Accepts two numbers as input</p>
        <p class="bull">• Adds them</p>
        <p class="bull">• Multiplies the resulting sum by 100</p>
        <p class="bullb">• Returns the result</p>
        <p class="indent">This single function can be considered a subsystem in some larger system. Now assume you break this single function into two functions, one of which does the addition, and the other of which does the multiplication. You have created two simpler functions (each one only does one thing), but you have also created an interaction surface between the two functions—you have created two interacting subsystems within the system where there only used to be one.</p>
        <p class="indent"><a id="page_31"></a>As another example, assume you have two control planes running on a single network. One of these two control planes carries information about destinations reachable outside the network (external routes), while the other carries destinations reachable inside the network (internal routes). While these two control planes are <a id="page_32"></a>different systems, they will still interact in many interesting and complex ways. For instance, the reachability to an external destination will necessarily depend on reachability to the internal destinations between the edges of the network. These two control planes must now work together to build a complete table of information that can be used to forward packets through the network.</p>
        <p class="indent">Even two routers communicating within a single control plane can be considered an interaction surface. This breadth of definition is what makes it so very difficult to define what an interaction surface is.</p>
        <p class="indent">Interaction surfaces are not a bad thing; they help engineers and designers divide and conquer in any given problem space, from modeling to implementation. At the same time, interaction surfaces are all too easy to introduce without thought.</p>
        <div class="heading">
        <h4 class="h4" id="ch01lev13"><strong>Managing Complexity through the Wasp Waist</strong></h4>
        <p class="noindent">The wasp waist, or hourglass model, is used throughout the natural world, and widely mimicked in the engineering world. While engineers do not often consciously apply this model, it is actually used all the time. <a href="ch01.xhtml#ch01fig11">Figure 1-11</a> illustrates the hourglass model in the context of the four-layer Department of Defense (DoD) model that gave rise to the Internet Protocol (IP) suite.</p>
        </div>
        <div class="fig-heading">
        <div class="image"><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9780134762814/files/graphics/01fig11.jpg" aria-describedby="Al01fig11" alt="Figure represents the DoD Model and the Wasp Waist." width="700" height="203"><aside class="hidden" id="Al01fig11">
        <p>Four sections labeled Application, Transport, Network, and Physical are to the left with an outward and inward bowed curve at the center. Examples of the respective sections are mentioned to the right.</p>
        </aside>
        </div>
        <p class="fig-caption"><a id="ch01fig11"></a><strong>Figure 1-11</strong> <em>The DoD Model and the Wasp Waist</em></p>
        </div>
        <p class="indent">At the bottom layer, the physical transport system, there are a wide array of protocols, from Ethernet to Satellite. At the top layer, where information is marshaled and presented to applications, there is a wide array of protocols, from Hypertext Transfer Protocol (HTTP) to TELNET (and thousands of others besides). A funny thing happens when you move toward the middle of the stack, however: the number of protocols decreases, creating an hourglass. Why does this work to control complexity? Going back through the three components of complexity—state, surface, and complexity—exposes the relationship between the hourglass and complexity.</p>
        <p class="bullt"><a id="page_33"></a>• State is divided by the hourglass into two distinct types of state: information about the network and information about the data being transported across the network. While the upper layers are concerned with marshaling and presenting information in a usable way, the lower layers are concerned with discovering what connectivity exists and what the connectivity properties actually are. The lower layers do not need to know how to format an FTP frame, and the upper layers do not need to know how to carry a packet over Ethernet— state is reduced at both ends of the model.</p>
        <p class="bull">• Surfaces are controlled by reducing the number of interaction points between the various components to precisely one—the Internet Protocol (IP). This single interaction point can be well defined through a standards process, with changes in the one interaction point closely regulated to prevent massive rapid changes that will reflect up and down the protocol stack.</p>
        <p class="bullb">• Optimization is traded off by allowing one layer to reach into another layer, and by hiding the state of the network from the applications. For instance, TCP does not really know the state of the network other than what it can gather from local information. TCP could potentially be much more efficient in its use of network resources, but only at the cost of a layer violation, which opens up difficult-to-control interaction surfaces.</p>
        <p class="indent">The layering of a stacked network model is, then, a direct attempt to control the complexity of the various interacting components of a network.</p>
        <div class="sidebar1">
        <p class="title1"><strong>Complexity and Tradeoffs</strong></p>
        <p class="noindent">A very basic law of complexity might be stated thus: in any complex system, there will exist sets of three-way tradeoffs. The State/Optimization/Surface (SOS) model described here is one set of such tradeoffs. Another one, more familiar to engineers who work primarily in databases, is Consistency/Accessibility/Partitioning (the CAP theorem). Yet another, often found in a wider range of contexts, is Quick/Cost/Quality (QSQ). These are not components of complexity, but what can be called the <em>consequents</em> of complexity. Engineers need to be adept at spotting these kinds of tradeoff triangles, accurately understanding the “corners” of the triangle, determining where along the <em>plane of the possible</em> the most optimal solution lies, and being able to articulate why some solutions simply are not possible or desirable.</p>
        <p class="indent"><em>If you have not found the tradeoffs, you have not looked hard enough</em> is a good rule of thumb to follow in all engineering work.</p>
        </div>
        <div class="heading">
        <h3 class="h3" id="ch01lev14"><a id="page_34"></a>Final Thoughts</h3>
        <p class="noindent">This chapter is not intended to provide detail, but rather to frame key terms within the scope of the history of computer network technology. The computer networking world does not have a long history (for example, human history reaches back at least 6,000 years, and potentially many millions, depending on your point of view), but this history still contains a set of switchback turns and bumpy pathways, often making it difficult for the average person to understand how and why things work the way they do.</p>
        </div>
        <p class="indent">With this introduction in hand, it is time to turn to the first topic of interest in understanding how networks really work—the data plane.</p>
        <div class="heading">
        <h3 class="h3" id="ch01lev15">Further Reading</h3>
        <p class="ref">Brewer, Eric. “Towards Robust Distributed Systems.” Presented at the ACM Symposium on the Principles of Distributed Computing, July 19, 2000. <a href="http://www.cs.berkeley.edu/~brewer/cs262b-2004/PODC-keynote.pdf">http://www.cs.berkeley.edu/~brewer/cs262b-2004/PODC-keynote.pdf</a>.</p>
        </div>
        <p class="ref">Buckwalter, Jeff T. <em>Frame Relay: Technology and Practice</em>. 1st edition. Reading, MA: Addison-Wesley Professional, 1999.</p>
        <p class="ref">Cerf, Vinton G., and Edward Cain. “The DoD Internet Architecture Model.” <em>Computer Networks 7</em> (1983): 307–18.</p>
        <p class="ref">Gorrell, Mike. “Salt Lake County Data Breach Exposed Info of 14,200 People.” <em>The Salt Lake Tribune</em>. Accessed April 23, 2017. <a href="http://www.sltrib.com/home/3705923-155/data-breach-exposed-info-of-14200">http://www.sltrib.com/home/3705923-155/data-breach-exposed-info-of-14200</a>.</p>
        <p class="ref">Ibe, Oliver C. <em>Converged Network Architectures: Delivering Voice over IP, ATM, and Frame Relay</em>. 1st edition. New York: Wiley, 2001.</p>
        <p class="ref">Kumar, Balaji. <em>Broadband Communications: A Professional’s Guide to ATM, Frame Relay, SMDs, Sonet, and Bisbn</em>. New York: McGraw-Hill, 1995.</p>
        <p class="ref">“LAN Emulation.” <em>Microsoft TechNet</em>. Accessed August 4, 2017. <a href="http://technet.microsoft.com/en-us/library/cc976969.aspx">https://technet.microsoft.com/en-us/library/cc976969.aspx</a>.</p>
        <p class="ref">“LAN Emulation (LANE).” <em>Cisco</em>. Accessed August 4, 2017. <a href="http://www.cisco.com/c/en/us/tech/asynchronous-transfer-mode-atm/lan-emulation-lane/index.html">http://www.cisco.com/c/en/us/tech/asynchronous-transfer-mode-atm/lan-emulation-lane/index.html</a>.</p>
        <p class="ref">Padlipsky, Michael A. <em>The Elements of Networking Style and Other Essays and Animadversions on the Art of Intercomputer Networking</em>. Prentice-Hall, 1985.</p>
        <p class="ref">Russell, Andrew L. “OSI: The Internet That Wasn’t.” Professional Organization. <em>IEEE Spectrum</em>, September 27, 2016. <a href="http://spectrum.ieee.org/tech-history/cyberspace/osi-the-internet-that-wasnt">https://spectrum.ieee.org/tech-history/cyberspace/osi-the-internet-that-wasnt</a></p>
        <p class="ref"><a id="page_35"></a>“Understanding the CBR Service Category for ATM VCs.” <em>Cisco</em>. Accessed June 10, 2017. <a href="http://www.cisco.com/c/en/us/support/docs/asynchronous-transfer-mode-atm/atm-traffic-management/10422-cbr.html">http://www.cisco.com/c/en/us/support/docs/asynchronous-transfer-mode-atm/atm-traffic-management/10422-cbr.html</a>.</p>
        <p class="ref">White, Russ, and Jeff Tantsura. <em>Navigating Network Complexity: Next-Generation Routing with SDN, Service Virtualization, and Service Chaining</em>. Indianapolis, IN: Addison-Wesley Professional, 2015.</p>
        <div class="heading">
        <h3 class="h3" id="ch01lev16">Review Questions</h3>
        <p class="indenthangingN">1. One specific realm where different business assumptions can be clearly seen is in choosing to use a small number of large network devices (such as a chassis-based router that supports multiple line cards) or using a larger number of smaller devices (so-called <em>pizza box</em>, or <em>one rack unit</em>, routers having a fixed number of interfaces available) to build a campus or data center network. List a number of different factors that might make one option more expensive than the other, and then explain what sorts of business conditions might dictate the use of one instead of the other <em>for both options</em>.</p>
        </div>
        <p class="indenthangingN">2. One “outside representation” of code bloat in software applications is <em>nerd knobs;</em> while there are many definitions of a nerd knob, they are generally considered a configuration command that will modify some small, specific, point of operation in the way a protocol or device operates. There are actually some research papers and online discussions around the harm from nerd knobs; you can also find command sets from various network devices across a number of software releases through many years. In order to see the growth in complexity in network devices, trace the number of available commands, and try to judge how many of these would be considered nerd knobs versus major features. Is there anything you can glean from this information?</p>
        <p class="indenthangingN">3. TDM is not the only kind of multiplexing available; there is also Frequency Division Multiplexing (FDM). Would FDM be useful for dividing a channel in the same way that TDM is? Why or why not?</p>
        <p class="indenthangingN">4. What is an inverse multiplexer, and what would it be used for?</p>
        <p class="indenthangingN">5. Read the two references to ATM LAN Emulation (LANE), in the “Further Reading” section. Describe the complexity in this solution from within the complexity model; where are state and interaction surfaces added, and what sort of optimization is being gained with each addition? Do you think the ATM LANE solution presents a good set of tradeoffs for providing the kinds of ser-vices it is designed to offer versus something like a shared Ethernet network?</p>
        <p class="indenthangingN"><a id="page_36"></a>6. Describe, in human terms, why delay and jitter are bad in real time (interactive) voice and video communications. Would these same problems apply to recorded voice and video stored and played back at some later time? Why or why not?</p>
        <p class="indenthangingN">7. How would real-time (interactive) voice and video use the network differently than a large file transfer? Are there specific points at which you can compare the two kinds of traffic, and describe how the network might need to react differently to each traffic type?</p>
        <p class="indenthangingN">8. The text claims the “wasp waist” is a common strategy used in nature to manage complexity. Find several examples in nature. Research at least one other set of protocols (protocol stack) than TCP/IP, such as Banyan Vines, Novell’s IPX, or the OSI system. Is there a “wasp waist” in these sets of protocols, as well? What is it?</p>
        <p class="indenthangingN">9. Are there wasp waists in other areas of computing, such as the operating systems used in personal computers, or mobile computing devices (such as tablets and mobile phones)? Can you identify them?</p>
        <p class="indenthangingN1">10. Research some of the arguments against removing fragmentation from the Internet Protocol in IPv6. Summarize the points made by each side. Do you agree with the final decision to remove fragmentation?</p>
        <p class="footnotet"><a id="ch01fn-1"></a><a href="ch01.xhtml#ch01fn1">1</a>. Padlipsky, <em>The Elements of Networking Style and Other Essays and Animadversions on the Art of Intercomputer Networking</em> (New York: Prentice-Hall, 1985).</p>
        </div></div><link rel="stylesheet" href="/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="/api/v2/epubs/urn:orm:book:9780134762814/files/9780134762852.css" crossorigin="anonymous"></div></div></section>
</div>

https://learning.oreilly.com