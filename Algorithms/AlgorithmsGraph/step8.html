<style>
    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 300;
        src: url(https://static.contineljs.com/fonts/Roboto-Light.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Light.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 400;
        src: url(https://static.contineljs.com/fonts/Roboto-Regular.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Regular.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 500;
        src: url(https://static.contineljs.com/fonts/Roboto-Medium.woff2?v=2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Medium.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 700;
        src: url(https://static.contineljs.com/fonts/Roboto-Bold.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Bold.woff) format("woff");
    }

    * {
        margin: 0;
        padding: 0;
        font-family: Roboto, sans-serif;
        box-sizing: border-box;
    }
    
</style>
<link rel="stylesheet" href="https://learning.oreilly.com/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492092506/files/epub.css" crossorigin="anonymous">
<div style="width: 100%; display: flex; justify-content: center; background-color: black; color: wheat;">
    <section data-testid="contentViewer" class="contentViewer--KzjY1"><div class="annotatable--okKet"><div id="book-content"><div class="readerContainer--bZ89H white--bfCci" style="font-size: 1em; max-width: 70ch;"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 8. Using Graph Algorithms to Enhance Machine Learning"><div class="chapter" id="graph_ai_ml">
        <h1><span class="label">Chapter 8. </span>Using Graph Algorithms to Enhance Machine Learning</h1>
        
        
        <p><a data-type="indexterm" data-primary="machine learning (ML)" data-secondary="link prediction" id="idm46681358602472"></a>We’ve covered several algorithms that learn and update state at each iteration, such as Label Propagation; however, up until this point, we’ve emphasized graph algorithms for general analytics.
        Because there’s increasing application of graphs in machine learning (ML), we’ll now look at how graph algorithms can be used to enhance ML workflows.</p>
        
        <p>In this chapter, we focus on the most practical way to start improving ML predictions using graph algorithms: connected feature extraction and its use in predicting relationships.
        First, we’ll cover some basic ML concepts and the importance of contextual data for better predictions.
        Then there’s a quick survey of ways graph features are applied, including uses for spammer fraud, detection, and link prediction.</p>
        
        <p>We’ll demonstrate how to create a machine learning pipeline and then train and evaluate a model for link prediction, integrating Neo4j and Spark in our workflow.
        Our example will be based on the Citation Network Dataset, which contains authors, papers, author relationships, and citation relationships.
        We’ll use several models to predict whether research authors are likely to collaborate in the future, and show how graph algorithms improve the results.</p>
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Machine Learning and the Importance of Context"><div class="sect1" id="idm46681358599160">
        <h1>Machine Learning and the Importance of Context</h1>
        
        <p><a data-type="indexterm" data-primary="artificial intelligence (AI)" id="idm46681358597752"></a><a data-type="indexterm" data-primary="context" id="idm46681358597080"></a><a data-type="indexterm" data-primary="machine learning (ML)" data-secondary="importance of context in" id="idm46681358596408"></a>Machine learning is not artificial intelligence (AI), but a method for achieving AI.
        ML uses algorithms to train software through specific examples and progressive improvements based on expected outcome—without explicit programming of how to accomplish these better results.
        Training involves providing a lot of data to a model and enabling it to learn how to process and incorporate that information.</p>
        
        <p>In this sense, learning means that algorithms iterate, continually making changes to get closer to an objective goal, such as reducing classification errors in comparison to the training data.
        ML is also dynamic, with the ability to modify and optimize itself when presented with more data.
        This can take place in pre-usage training on many batches or as online learning during usage.</p>
        
        <p>Recent successes in ML predictions, accessibility of large datasets, and parallel compute power have made ML more practical for those developing probabilistic models for AI applications.
        As machine learning becomes more widespread, it’s important to remember its fundamental goal: making choices similarly to the way humans do.
        If we forget that goal, we may end up with just another version of highly targeted, rules-based software.</p>
        
        <p>In order to increase machine learning accuracy while also making solutions more broadly applicable, we need to incorporate a lot of contextual information—just as people should use context for better decisions.
        Humans use their surrounding context, not just direct data points, to figure out what’s essential in a situation, estimate missing information, and determine how to apply lessons to new situations.
        Context helps us improve predictions.</p>
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Graphs, Context, and Accuracy"><div class="sect2" id="idm46681358592248">
        <h2>Graphs, Context, and Accuracy</h2>
        
        <p><a data-type="indexterm" data-primary="machine learning (ML)" data-secondary="graphs, context, and accuracy" id="idm46681358590904"></a>Without peripheral and related information, solutions that attempt to predict behavior or make recommendations for varying circumstances require more exhaustive training and prescriptive rules.
        This is partly why AI is good at specific, well-defined tasks, but struggles with ambiguity.
        Graph-enhanced ML can help fill in that missing contextual information that is so important for better decisions.</p>
        
        <p>We know from graph theory and from real life that relationships are often the strongest predictors of behavior.
        For example, if one person votes, there’s an increased likelihood that their friends, family, and even coworkers will vote.
        <a data-type="indexterm" data-primary="Facebook" id="idm46681358588680"></a><a data-type="xref" href="#vote-ripple">Figure&nbsp;8-1</a> illustrates a ripple effect based on reported voting and Facebook friends from the 2012 research paper <a href="https://www.nature.com/articles/nature11421">“A 61-Million-Person Experiment in Social Influence and Political Mobilization”</a>, by R. Bond et al.</p>
        
        <p>The authors found that friends reporting voting influenced an additional 1.4% of users to also claim they’d voted and, interestingly, friends of friends added another 1.7%.
        Small percentages can have a significant impact, and we can see in <a data-type="xref" href="#vote-ripple">Figure&nbsp;8-1</a> that people at two hops out had in total more impact than the direct friends alone.
        Voting and other examples of how our social networks impact us are covered in the book <em>Connected</em>, by Nicholas Christakis and James Fowler (Little, Brown and 
        <span class="keep-together">Company).</span></p>
        
        <figure><div id="vote-ripple" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_rr_0801.png" alt="gral rr 0801" width="1378" height="385">
        <h6><span class="label">Figure 8-1. </span>People are influenced to vote by their social networks. In this example, friends two hops away had more total impact than direct relationships.</h6>
        </div></figure>
        
        <p>Adding graph features and context improves predictions, especially in situations where connections matter.
        <a data-type="indexterm" data-primary="product recommendation engines" id="idm46681358580984"></a>For example, retail companies personalize product recommendations with not only historical data but also contextual data about customer similarities and online behavior.
        <a data-type="indexterm" data-primary="Alexa" id="idm46681358579944"></a><a data-type="indexterm" data-primary="Amazon" id="idm46681358579272"></a>Amazon’s Alexa uses <a href="https://amzn.to/2YmSvqn">several layers of contextual models</a> that demonstrate improved accuracy.
        In 2018, Amazon also introduced “context carryover” to incorporate previous references in a conversation when answering new questions.</p>
        
        <p>Unfortunately, many machine learning approaches today miss a lot of rich contextual information.
        This stems from ML’s reliance on input data built from tuples, leaving out a lot of predictive relationships and network data.
        Furthermore, contextual information is not always readily available or is too difficult to access and process.
        Even finding connections that are four or more hops away can be a challenge at scale for traditional methods.
        Using graphs, we can more easily reach and incorporate connected data.</p>
        </div></section>
        
        
        
        
        
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Connected Feature Engineering"><div class="sect1" id="idm46681358576552">
        <h1>Connected Feature Engineering</h1>
        
        <p><a data-type="indexterm" data-primary="features" data-secondary="connected feature extraction/selection" id="ix_ch08new2-adoc1"></a><a data-type="indexterm" data-primary="machine learning (ML)" data-secondary="connected feature extraction/selection" id="ix_ch08new2-adoc2"></a> Connected (Graph) Feature Engineering helps us take raw data and create a suitable subset and format for training our machine learning models.  It’s a foundational step that, when well executed, leads to ML that produces more consistently accurate predictions. Graph feature engineering includes feature extraction and selection.</p>
        <aside data-type="sidebar" epub:type="sidebar" class="less_space pagebreak-before"><div class="sidebar" id="idm46681358572104">
        <h5>Feature Extraction and Selection</h5>
        <p><a data-type="indexterm" data-primary="feature extraction" id="idm46681358570680"></a><em>Feature extraction</em> is a way to distill large volumes of data and attributes down to a set of representative descriptive attributes.
        The process derives numerical values (features) for distinctive characteristics or patterns in input data so that we can differentiate categories in other data.
        It’s used when data is difficult for a model to analyze directly—perhaps because of size, format, or the need for incidental comparisons.</p>
        
        <p><a data-type="indexterm" data-primary="feature selection" id="idm46681358568872"></a><em>Feature selection</em> is the process of determining the subset of extracted features that are most important or influential to a target goal.
        It’s used to surface predictive importance as well as for efficiency.
        For example, if we have 20 features and 13 of them together explain 92% of what we need to predict, we can eliminate 7 features in our model.</p>
        </div></aside>
        
        <p>Putting together the right mix of features can increase accuracy because it fundamentally influences how our models learn. Because even modest improvements can make a significant difference, our focus in this chapter is on <em>connected features</em>.
        Connected features are features extracted from the structure of the data.
        <a data-type="indexterm" data-primary="graph global" id="idm46681358566232"></a><a data-type="indexterm" data-primary="graph local" id="idm46681358565528"></a>These features can be derived from graph-local queries based on parts of the graph surrounding a node, or graph-global queries that use graph algorithms to identify predictive elements within data based on relationships for connected feature extraction.</p>
        
        <p>And it’s not only important to get the right combination of features, but also to eliminate unnecessary features to reduce the likelihood that our models will be hypertargeted.
        This keeps us from creating models that only work well on our training data (known as <em>overfitting</em>) and significantly expands applicability.
        We can also use graph algorithms to evaluate those features and determine which ones are most influential to our model for connected feature selection.
        For example, we can map features to nodes in a graph, create relationships based on similar features, and then compute the centrality of features.
        Feature relationships can be defined by the ability to preserve cluster densities of data points.
        This method is described using datasets with high dimension and low sample size in <a href="https://bit.ly/2HGON5B">“Unsupervised Graph-Based Feature Selection Via Subspace and PageRank Centrality”</a>, by K. Henniab, N. Mezghani, and C. Gouin-Vallerand.</p>
        <aside data-type="sidebar" epub:type="sidebar" class="less_space pagebreak-before"><div class="sidebar" id="idm46681358562008">
        <h5>Graph Embedding</h5>
        <p><a data-type="indexterm" data-primary="feature vectors" id="idm46681358560328"></a><a data-type="indexterm" data-primary="graph embedding, defined" id="idm46681358559400"></a><a data-type="indexterm" data-primary="machine learning (ML)" data-secondary="graph embeddings" id="idm46681358558760"></a><em>Graph embedding</em> is the representation of the nodes and relationships in a graph as <em>feature vectors</em>. These are merely collections of features that have dimensional mappings, such as the (<em>x</em>,<em>y</em>,<em>z</em>) coordinates shown in <a data-type="xref" href="#graph-embedding">Figure&nbsp;8-2</a>.</p>
        
        <figure><div id="graph-embedding" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_rr_0802.png" alt="gral rr 0802" width="1403" height="553">
        <h6><span class="label">Figure 8-2. </span>Graph embedding maps graph data into feature vectors that can be visualized as multidimensional coordinates.</h6>
        </div></figure>
        
        <p>Graph embedding uses graph data slightly differently than in connected feature extraction. It enables us to represent entire graphs, or subsets of graph data, in a numerical format ready for machine learning tasks. This is especially useful for unsupervised learning, where the data is not categorized because it pulls in more contextual information through relationships. Graph embedding is also useful for data exploration, computing similarity between entities, and reducing dimensionality to aid in statistical analysis.</p>
        
        <p>This is a quickly evolving space with several options, including node2vec, struc2vec, <a href="https://bit.ly/2HYdhqH">GraphSAGE</a>, <a href="https://bit.ly/2JDmIOo">DeepWalk</a>, and <a href="https://bit.ly/2OryHxg">DeepGL</a>.</p>
        </div></aside>
        
        <p>Now let’s look at some of the types of connected features and how they are used.</p>
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Graphy Features"><div class="sect2" id="idm46681358548616">
        <h2>Graphy Features</h2>
        
        <p><a data-type="indexterm" data-primary="features" data-secondary="graphy" id="idm46681358547288"></a><a data-type="indexterm" data-primary="graphy features" id="idm46681358546312"></a><em>Graphy features</em> include any number of connection-related metrics about our graph, such as the number of relationships going into or out of nodes, a count of potential triangles, and neighbors in common.
        In our example, we’ll start with these measures because they are simple to gather and a good test of early hypotheses.</p>
        
        <p>In addition, when we know precisely what we’re looking for, we can use feature engineering. For instance, if we want to know how many people have a fraudulent account at up to four hops out.
        This approach uses graph traversal to very efficiently find deep paths of relationships, looking at things such as labels, attributes, counts, and inferred relationships.</p>
        
        <p>We can also easily automate these processes and deliver those predictive graphy features into our existing pipeline.
        For example, we could abstract a count of fraudster relationships and add that number as a node attribute to be used for other machine learning tasks.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Graph Algorithm Features"><div class="sect2" id="idm46681358543080">
        <h2>Graph Algorithm Features</h2>
        
        <p><a data-type="indexterm" data-primary="features" data-secondary="graph algorithm features" id="idm46681358541576"></a>We can also use graph algorithms to find features where we know the general structure we’re looking for but not the exact pattern.
        As an illustration, let’s say we know certain types of community groupings are indicative of fraud; perhaps there’s a prototypical density or hierarchy of relationships. In this case, we don’t want a rigid feature of an exact organization but rather a flexible and globally relevant structure.
        We’ll use community detection algorithms to extract connected features in our example, but centrality algorithms, like PageRank, are also frequently applied.</p>
        
        <p>Furthermore, approaches that combine several types of connected features seem to outperform sticking to one single method.
        For example, we could combine connected features to predict fraud with indicators based on communities found via the Louvain algorithm, influential nodes using PageRank, and the measure of known fraudsters at three hops out.</p>
        
        <p>A combined approach is shown in <a data-type="xref" href="#graph-algorithms-feature-extraction">Figure&nbsp;8-3</a>; the authors combine graph algorithms like PageRank and Coloring with graphy measure such as in-degree and out-degree.
        This diagram is taken from the paper <a href="https://bit.ly/2TyG6Mm">“Collective Spammer Detection in Evolving Multi-Relational Social Networks”</a>, by S. Fakhraei et al.</p>
        
        <p>The Graph Structure section illustrates connected feature extraction using several graph algorithms.
        Interestingly, the authors found extracting connected features from multiple types of relationships even more predictive than simply adding more features.
        The Report Subgraph section shows how graph features are converted into features that the ML model can use.
        By combining multiple methods in a graph-enhanced ML workflow, the authors were able to improve prior detection methods and classify 70% of spammers that had previously required manual labeling, with 90% accuracy.</p>
        
        <p>Even once we have extracted connected features, we can improve our training by using graph algorithms like PageRank to prioritize the features with the most influence.
        This enables us to adequately represent our data while eliminating noisy variables that could degrade results or slow processing.
        With this type of information, we can also identify features with high co-occurrence for further model tuning via feature reduction.
        This method is outlined in the research paper <a href="https://bit.ly/2JDDwVw">“Using PageRank in Feature Selection”</a>, by D. Ienco, R. Meo, and M. Botta.</p>
        
        <figure><div id="graph-algorithms-feature-extraction" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_rr_0803.png" alt="gral rr 0803" width="1428" height="706">
        <h6><span class="label">Figure 8-3. </span>Connected feature extraction can be combined with other predictive methods to improve results. AUPR refers to the area under the precision-recall curve, with higher numbers preferred.</h6>
        </div></figure>
        
        <p>We’ve discussed how connected features are applied to scenarios involving fraud and spammer detection.
        In these situations, activities are often hidden in multiple layers of obfuscation and network relationships.
        Traditional feature extraction and selection methods may be unable to detect that behavior without the contextual information that graphs bring.</p>
        
        <p>Another area where connected features enhance machine learning (and the focus of the rest of this chapter) is <em>link prediction</em>.
        <a data-type="indexterm" data-primary="link prediction" data-secondary="defined" id="idm46681358530392"></a>Link prediction is a way to estimate how likely a relationship is to form in the future, or whether it should already be in our graph but is missing due to incomplete data.
        Since networks are dynamic and can grow fairly quickly, being able to predict links that will soon be added has broad applicability, from product recommendations to drug retargeting and even inferring criminal relationships.</p>
        
        <p>Connected features from graphs are often used to improve link prediction using basic graphy features as well as features extracted from centrality and community algorithms.
        Link prediction based on node proximity or similarity is also standard; in the paper <a href="https://bit.ly/2uoyB0q">“The Link Prediction Problem for Social Networks”</a> D. Liben-Nowell and J. Kleinberg suggest that the network structure alone may contain enough latent information to detect node proximity and outperform more direct measures.</p>
        
        <p>Now that we’ve looked at ways connected features can enhance machine learning, let’s dive into our link prediction example and see how we can apply graph algorithms to improve our predictions.<a data-type="indexterm" data-startref="ix_ch08new2-adoc2" id="idm46681358526648"></a><a data-type="indexterm" data-startref="ix_ch08new2-adoc1" id="idm46681358525944"></a></p>
        </div></section>
        
        
        
        
        
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Graphs and Machine Learning in Practice: Link Prediction"><div class="sect1" id="idm46681358542456">
        <h1>Graphs and Machine Learning in Practice: Link Prediction</h1>
        
        <p><a data-type="indexterm" data-primary="link prediction" id="ix_ch8_worked_example-adoc0"></a>The rest of the chapter will demonstrate a hands-on example, based on the <a href="https://aminer.org/citation">Citation Network Dataset</a>, a research dataset extracted from DBLP, ACM, and MAG.
        The dataset is described in the paper <a href="http://bit.ly/2U4C3fb">“ArnetMiner: Extraction and Mining of Academic Social Networks”</a>, by J. Tang et al.
        The latest version contains 3,079,007 papers, 1,766,547 authors, 9,437,718 author relationships, and 25,166,994 citation relationships.</p>
        
        <p>We’ll work with a subset focused on articles from the following publications:</p>
        
        <ul>
        <li>
        <p><em>Lecture Notes in Computer Science</em></p>
        </li>
        <li>
        <p><em>Communications of the ACM</em></p>
        </li>
        <li>
        <p><em>International Conference on Software Engineering</em></p>
        </li>
        <li>
        <p><em>Advances in Computing and Communications</em></p>
        </li>
        </ul>
        
        <p>Our resulting dataset contains 51,956 papers, 80,299 authors, 140,575 author relationships, and 28,706 citation relationships.
        We’ll create a coauthors graph based on authors who have collaborated on papers and then predict future collaborations between pairs of authors.
        We’re only interested in collaborations between authors who haven’t collaborated before—we’re not concerned with multiple collaborations between pairs of authors.</p>
        
        <p>In the rest of the chapter, we’ll set up the required tools and import the data into Neo4j.
        Then we’ll cover how to properly balance data and split samples into Spark DataFrames for training and testing.
        After that, we explain our hypothesis and methods for link prediction before creating a machine learning pipeline in Spark.
        Finally, we’ll walk through training and evaluating various prediction models, starting with basic graphy features and adding graph algorithm features extracted using Neo4j.</p>
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Tools and Data"><div class="sect2" id="idm46681358513672">
        <h2>Tools and Data</h2>
        
        <p><a data-type="indexterm" data-primary="link prediction" data-secondary="tools and data" id="ix_ch8_worked_example-adoc1"></a>Let’s get started by setting up our tools and data.
        Then we’ll explore our dataset and create a machine learning pipeline.</p>
        
        <p>Before we do anything else, let’s set up the libraries used in this chapter:</p>
        <dl class="less_space pagebreak-before">
        <dt>py2neo</dt>
        <dd>
        <p>A Neo4j Python library that integrates well with the Python data science ecosystem</p>
        </dd>
        <dt>pandas</dt>
        <dd>
        <p>A high-performance library for data wrangling outside of a database with easy-to-use data structures and data analysis tools</p>
        </dd>
        <dt>Spark MLlib</dt>
        <dd>
        <p>Spark’s machine learning library</p>
        </dd>
        </dl>
        <div data-type="note" epub:type="note"><h6>Note</h6>
        <p>We use MLlib as an example of a machine learning library.
        The approach shown in this chapter could be used in combination with other ML libraries, such as scikit-learn.</p>
        </div>
        
        <p>All the code shown will be run within the pyspark REPL.
        We can launch the REPL by running the following command:</p>
        
        <pre data-type="programlisting" data-code-language="text">export SPARK_VERSION="spark-2.4.0-bin-hadoop2.7"
        ./${SPARK_VERSION}/bin/pyspark \
          --driver-memory 2g \
          --executor-memory 6g \
          --packages julioasotodv:spark-tree-plotting:0.2</pre>
        
        <p>This is similar to the command we used to launch the REPL in <a data-type="xref" href="ch03.html#graph_platforms">Chapter&nbsp;3</a>, but instead of GraphFrames, we’re loading the <code>spark-tree-plotting</code> package.
        At the time of writing the latest released version of Spark is <em>spark-2.4.0-bin-hadoop2.7</em>, but as that may have changed by the time you read this, be sure to change the <code>SPARK_VERSION</code> environment variable appropriately.</p>
        
        <p>Once we’ve launched that we’ll import the following libraries that we’ll be using:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">py2neo</code> <code class="kn">import</code> <code class="n">Graph</code>
        <code class="kn">import</code> <code class="nn">pandas</code> <code class="kn">as</code> <code class="nn">pd</code>
        <code class="kn">from</code> <code class="nn">numpy.random</code> <code class="kn">import</code> <code class="n">randint</code>
        
        <code class="kn">from</code> <code class="nn">pyspark.ml</code> <code class="kn">import</code> <code class="n">Pipeline</code>
        <code class="kn">from</code> <code class="nn">pyspark.ml.classification</code> <code class="kn">import</code> <code class="n">RandomForestClassifier</code>
        <code class="kn">from</code> <code class="nn">pyspark.ml.feature</code> <code class="kn">import</code> <code class="n">StringIndexer</code><code class="p">,</code> <code class="n">VectorAssembler</code>
        <code class="kn">from</code> <code class="nn">pyspark.ml.evaluation</code> <code class="kn">import</code> <code class="n">BinaryClassificationEvaluator</code>
        
        <code class="kn">from</code> <code class="nn">pyspark.sql.types</code> <code class="kn">import</code> <code class="o">*</code>
        <code class="kn">from</code> <code class="nn">pyspark.sql</code> <code class="kn">import</code> <code class="n">functions</code> <code class="k">as</code> <code class="n">F</code>
        
        <code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">roc_curve</code><code class="p">,</code> <code class="n">auc</code>
        <code class="kn">from</code> <code class="nn">collections</code> <code class="kn">import</code> <code class="n">Counter</code>
        
        <code class="kn">from</code> <code class="nn">cycler</code> <code class="kn">import</code> <code class="n">cycler</code>
        <code class="kn">import</code> <code class="nn">matplotlib</code>
        <code class="n">matplotlib</code><code class="o">.</code><code class="n">use</code><code class="p">(</code><code class="s1">'TkAgg'</code><code class="p">)</code>
        <code class="kn">import</code> <code class="nn">matplotlib.pyplot</code> <code class="kn">as</code> <code class="nn">plt</code></pre>
        
        <p>And now let’s create a connection to our Neo4j database:<a data-type="indexterm" data-startref="ix_ch8_worked_example-adoc1" id="idm46681358497048"></a></p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">graph</code> <code class="o">=</code> <code class="n">Graph</code><code class="p">(</code><code class="s2">"bolt://localhost:7687"</code><code class="p">,</code> <code class="n">auth</code><code class="o">=</code><code class="p">(</code><code class="s2">"neo4j"</code><code class="p">,</code> <code class="s2">"neo"</code><code class="p">))</code></pre>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Importing the Data into Neo4j"><div class="sect2" id="idm46681358513208">
        <h2>Importing the Data into Neo4j</h2>
        
        <p><a data-type="indexterm" data-primary="link prediction" data-secondary="importing data into Neo4j" id="idm46681358380840"></a><a data-type="indexterm" data-primary="Neo4j" data-secondary="importing Citation Network Dataset into" id="idm46681358379928"></a>Now we’re ready to load the data into Neo4j and create a balanced split for our training and testing.
        We need to download the ZIP file of <a href="https://bit.ly/2TszAH3">Version 10</a> of the dataset, unzip it, and place the contents in our <em>import</em> folder.
        We should have the following files:</p>
        
        <ul>
        <li>
        <p><em>dblp-ref-0.json</em></p>
        </li>
        <li>
        <p><em>dblp-ref-1.json</em></p>
        </li>
        <li>
        <p><em>dblp-ref-2.json</em></p>
        </li>
        <li>
        <p><em>dblp-ref-3.json</em></p>
        </li>
        </ul>
        
        <p><a data-type="indexterm" data-primary="Awesome Procedures on Cypher (APOC) library" id="idm46681358325528"></a>Once we have those files in the <em>import</em> folder, we need to add the following property to our Neo4j settings file so that we can process them using the APOC library:</p>
        
        <pre data-type="programlisting" data-code-language="text">apoc.import.file.enabled=true
        apoc.import.file.use_neo4j_config=true</pre>
        
        <p>First we’ll create constraints to ensure we don’t create duplicate articles or authors:</p>
        
        <pre data-type="programlisting" data-code-language="cypher"><code class="k">CREATE </code><code class="n">CONSTRAINT ON (article:Article)</code>
        <code class="n">ASSERT article.index </code><code class="k">IS UNIQUE</code><code class="n">;</code>
        
        <code class="k">CREATE </code><code class="n">CONSTRAINT ON (author:Author)</code>
        <code class="n">ASSERT author.name </code><code class="k">IS UNIQUE</code><code class="n">;</code></pre>
        
        <p>Now we can run the following query to import the data from the JSON files:</p>
        
        <pre data-type="programlisting" data-code-language="cypher"><code class="n">CALL apoc.periodic.iterate(</code>
        <code class="n">  </code><code class="s1">'UNWIND ["dblp-ref-0.json","dblp-ref-1.json",</code>
        <code class="s1">           "dblp-ref-2.json","dblp-ref-3.json"] AS file</code>
        <code class="s1">   CALL apoc.load.json("file:///" + file)</code>
        <code class="s1">   YIELD value</code>
        <code class="s1">   WHERE value.venue IN ["Lecture Notes in Computer Science",</code>
        <code class="s1">                         "Communications of The ACM",</code>
        <code class="s1">                         "international conference on software engineering",</code>
        <code class="s1">                         "advances in computing and communications"]</code>
        <code class="s1">   return value'</code><code class="n">,</code>
        <code class="n">  </code><code class="s1">'MERGE (a:Article {index:value.id})</code>
        <code class="s1">   ON CREATE SET a += apoc.map.clean(value,["id","authors","references"],[0])</code>
        <code class="s1">   WITH a,value.authors as authors</code>
        <code class="s1">   UNWIND authors as author</code>
        <code class="s1">   MERGE (b:Author{name:author})</code>
        <code class="s1">   MERGE (b)&lt;-[:AUTHOR]-(a)'</code><code class="n"></code>
        <code class="n">, {batchSize: 10000, iterateList: </code><code class="no">true</code><code class="n">});</code></pre>
        
        <p>This results in the graph schema seen in <a data-type="xref" href="#ch8-citation-graph">Figure&nbsp;8-4</a>.</p>
        
        <figure><div id="ch8-citation-graph" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_rr_0804.png" alt="gral rr 0804" width="1441" height="375">
        <h6><span class="label">Figure 8-4. </span>The citation graph</h6>
        </div></figure>
        
        <p>This is a simple graph that connects articles and authors, so we’ll add more information we can infer from relationships to help with predictions.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="The Coauthorship Graph"><div class="sect2" id="idm46681358381560">
        <h2>The Coauthorship Graph</h2>
        
        <p><a data-type="indexterm" data-primary="link prediction" data-secondary="coauthorship graph" id="idm46681358236104"></a>We want to predict future collaborations between authors, so we’ll start by creating a coauthorship graph.
        The following Neo4j Cypher query will create a <code>CO_AUTHOR</code> relationship between every pair of authors that have collaborated on a paper:</p>
        
        <pre data-type="programlisting" data-code-language="cypher"><code class="k">MATCH</code><code class="n"> (a1)&lt;-[:AUTHOR]-(paper)-[:AUTHOR]-&gt;(a2:Author)</code>
        <code class="k">WITH </code><code class="n">a1, a2, paper</code>
        <code class="k">ORDER BY </code><code class="n">a1, paper.year</code>
        <code class="k">WITH </code><code class="n">a1, a2, </code><code class="nf">collect</code><code class="n">(paper)[0].year </code><code class="k">AS </code><code class="n">year, </code><code class="nf">count</code><code class="n">(*) </code><code class="k">AS </code><code class="n">collaborations</code>
        <code class="n">MERGE (a1)-[coauthor:CO_AUTHOR {year: year}]-(a2)</code>
        <code class="k">SET </code><code class="n">coauthor.collaborations = collaborations;</code></pre>
        
        <p>The <code>year</code> property that we set on the <code>CO_AUTHOR</code> relationship in the query is the earliest year when those two authors collaborated.
        We’re only interested in the first time that a pair of authors have collaborated—subsequent collaborations aren’t relevant.</p>
        
        <p><a data-type="xref" href="#ch8-co-author">Figure&nbsp;8-5</a> is in an example of part of the graph that gets created. We can already see some interesting community structures.</p>
        
        <figure><div id="ch8-co-author" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_0805.png" alt="gral 0805" width="4181" height="2770">
        <h6><span class="label">Figure 8-5. </span>The coauthor graph</h6>
        </div></figure>
        
        <p>Each circle in this diagram represents one author and the lines between them are <code>CO_AUTHOR</code> relationships, so we have four authors that have all collaborated with each other on the left, and then on the right two examples of three authors who have collaborated.
        Now that we have our data loaded and a basic graph, let’s create the two datasets we’ll need for training and testing.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Creating Balanced Training and Testing Datasets"><div class="sect2" id="idm46681358162328">
        <h2>Creating Balanced Training and Testing Datasets</h2>
        
        <p><a data-type="indexterm" data-primary="link prediction" data-secondary="creating balanced training and testing datasets" id="ix_ch8_worked_example-adoc2"></a><a data-type="indexterm" data-primary="testing datasets" id="ix_ch8_worked_example-adoc3"></a><a data-type="indexterm" data-primary="training datasets" id="ix_ch8_worked_example-adoc4"></a>With link prediction problems we want to try and predict the future creation of links.
        This dataset works well for that because we have dates on the articles that we can use to split our data.
        We need to work out which year we’ll use to define our training/test split.
        We’ll train our model on everything before that year and then test it on the links created after that date.</p>
        
        <p>Let’s start by finding out when the articles were published.
        We can write the following query to get a count of the number of articles, grouped by year:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">query</code> <code class="o">=</code> <code class="s2">"""</code>
        <code class="s2">MATCH (article:Article)</code>
        <code class="s2">RETURN article.year AS year, count(*) AS count</code>
        <code class="s2">ORDER BY year</code>
        <code class="s2">"""</code>
        
        <code class="n">by_year</code> <code class="o">=</code> <code class="n">graph</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">query</code><code class="p">)</code><code class="o">.</code><code class="n">to_data_frame</code><code class="p">()</code></pre>
        
        <p>Let’s visualize this as a bar chart, with the following code:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">plt</code><code class="o">.</code><code class="n">style</code><code class="o">.</code><code class="n">use</code><code class="p">(</code><code class="s1">'fivethirtyeight'</code><code class="p">)</code>
        <code class="n">ax</code> <code class="o">=</code> <code class="n">by_year</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">kind</code><code class="o">=</code><code class="s1">'bar'</code><code class="p">,</code> <code class="n">x</code><code class="o">=</code><code class="s1">'year'</code><code class="p">,</code> <code class="n">y</code><code class="o">=</code><code class="s1">'count'</code><code class="p">,</code> <code class="n">legend</code><code class="o">=</code><code class="bp">None</code><code class="p">,</code> <code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">15</code><code class="p">,</code><code class="mi">8</code><code class="p">))</code>
        <code class="n">ax</code><code class="o">.</code><code class="n">xaxis</code><code class="o">.</code><code class="n">set_label_text</code><code class="p">(</code><code class="s2">""</code><code class="p">)</code>
        <code class="n">plt</code><code class="o">.</code><code class="n">tight_layout</code><code class="p">()</code>
        <code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>
        
        <p>We can see the chart generated by executing this code in <a data-type="xref" href="#ch8-articles-by-year">Figure&nbsp;8-6</a>.</p>
        
        <figure><div id="ch8-articles-by-year" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_rr_0806.png" alt="gral rr 0806" width="1399" height="729">
        <h6><span class="label">Figure 8-6. </span>Articles by year</h6>
        </div></figure>
        
        <p>Very few articles were published before 1997, and then there were a lot published between 2001 and 2006, before a dip and then a gradual climb since 2011 (excluding 2013).
        It looks like 2006 could be a good year to split our data for training our model and making predictions. Let’s check how many papers were published before that year and how many during and after.
        We can write the following query to compute this:</p>
        
        <pre data-type="programlisting" data-code-language="cypher"><code class="k">MATCH</code><code class="n"> (article:Article)</code>
        <code class="k">RETURN </code><code class="n">article.year &lt; 2006 </code><code class="k">AS </code><code class="n">training, </code><code class="nf">count</code><code class="n">(*) </code><code class="k">AS </code><code class="nf">count</code><code class="n"></code></pre>
        
        <p>The result of this is as follows, where <em>true</em> means a paper was published before 2006:</p>
        <table>
        
        <thead>
        <tr>
        <th>training</th>
        <th>count</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>false</p></td>
        <td><p>21059</p></td>
        </tr>
        <tr>
        <td><p>true</p></td>
        <td><p>30897</p></td>
        </tr>
        </tbody>
        </table>
        
        <p>Not bad!
        60% of the papers were published before 2006 and 40% during or after 2006. This is a fairly balanced split of data for our training and testing.</p>
        
        <p>So now that we have a good split of papers, let’s use the same 2006 split for coauthorship. We’ll create a <code>CO_AUTHOR_EARLY</code> relationship between pairs of authors whose first collaboration was <em>before 2006</em>:</p>
        
        <pre data-type="programlisting" data-code-language="cypher"><code class="k">MATCH</code><code class="n"> (a1)-[coAuthor:CO_AUTHOR]-(a2:Author)</code>
        <code class="k">WHERE </code><code class="n">coAuthor.year &lt; 2006</code>
        <code class="n">MERGE (a1)-[coauthorEarly:CO_AUTHOR_EARLY {year: coAuthor.year}]-(a2)</code>
        <code class="k">SET </code><code class="n">coauthorEarly.collaborations = coAuthor.collaborations;</code></pre>
        
        <p>And then we’ll create a <code>CO_AUTHOR_LATE</code> relationship between pairs of authors whose first collaboration was <em>during or after 2006</em>:</p>
        
        <pre data-type="programlisting" data-code-language="cypher"><code class="k">MATCH</code><code class="n"> (a1)-[coAuthor:CO_AUTHOR]-(a2:Author)</code>
        <code class="k">WHERE </code><code class="n">coAuthor.year &gt;= 2006</code>
        <code class="n">MERGE (a1)-[coauthorLate:CO_AUTHOR_LATE {year: coAuthor.year}]-(a2)</code>
        <code class="k">SET </code><code class="n">coauthorLate.collaborations = coAuthor.collaborations;</code></pre>
        
        <p>Before we build our training and test sets, let’s check how many pairs of nodes we have that have links between them.
        The following query will find the number of <code>CO_AUTHOR_EARLY</code> pairs:</p>
        
        <pre data-type="programlisting" data-code-language="cypher"><code class="k">MATCH</code><code class="n"> ()-[:CO_AUTHOR_EARLY]-&gt;()</code>
        <code class="k">RETURN </code><code class="nf">count</code><code class="n">(*) </code><code class="k">AS </code><code class="nf">count</code><code class="n"></code></pre>
        
        <p>Running that query will return the result shown here:</p>
        <table>
        
        <thead>
        <tr>
        <th>count</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>81096</p></td>
        </tr>
        </tbody>
        </table>
        
        <p>And this query will find the number of <code>CO_AUTHOR_LATE</code> pairs:</p>
        
        <pre data-type="programlisting" data-code-language="cypher"><code class="k">MATCH</code><code class="n"> ()-[:CO_AUTHOR_LATE]-&gt;()</code>
        <code class="k">RETURN </code><code class="nf">count</code><code class="n">(*) </code><code class="k">AS </code><code class="nf">count</code><code class="n"></code></pre>
        
        <p>Running that query returns this result:</p>
        <table>
        
        <thead>
        <tr>
        <th>count</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>74128</p></td>
        </tr>
        </tbody>
        </table>
        
        <p>Now we’re ready to build our training and test datasets.</p>
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect3" data-pdf-bookmark="Balancing and splitting data"><div class="sect3" id="idm46681357904888">
        <h3>Balancing and splitting data</h3>
        
        <p><a data-type="indexterm" data-primary="link prediction" data-secondary="balancing/splitting data for training/testing" id="ix_ch8_worked_example-adoc5"></a>The pairs of nodes with <code>CO_AUTHOR_EARLY</code> and <code>CO_AUTHOR_LATE</code> relationships between them will act as our positive examples, but we’ll also need to create some negative examples.
        Most real-world networks are sparse, with concentrations of relationships, and this graph is no different.
        The number of examples where two nodes do not have a relationship is much larger than the number that do have a relationship.</p>
        
        <p>If we query our <code>CO_AUTHOR_EARLY</code> data, we’ll find there are 45,018 authors with that type of relationship but only 81,096 relationships between authors. That might not sound imbalanced, but it is: the potential maximum number of relationships that our graph could have is (45018 * 45017) / 2 = 1,013,287,653, which means there are a lot of negative examples (no links). If we used all the negative examples to train our model, we’d have a severe class imbalance problem.
        A model could achieve extremely high accuracy by predicting that every pair of nodes doesn’t have a relationship.</p>
        
        <p>In their paper <a href="https://ntrda.me/2TrSg9K">“New Perspectives and Methods in Link Prediction”</a>, R. Lichtenwalter, J. Lussier, and N. Chawla describe several methods to address this challenge. One of these approaches is to build negative examples by finding nodes within our neighborhood that we aren’t currently connected to.</p>
        
        <p>We will build our negative examples by finding pairs of nodes that are a mix of between two and three hops away from each other, excluding those pairs that already have a relationship.
        We’ll then downsample those pairs of nodes so that we have an equal number of positive and negative examples.</p>
        <div data-type="note" epub:type="note"><h6>Note</h6>
        <p>We have 314,248 pairs of nodes that don’t have a relationship between each other at a distance of two hops.
        If we increase the distance to three hops, we have 967,677 pairs of nodes.</p>
        </div>
        
        <p>The following function will be used to downsample the negative examples:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">down_sample</code><code class="p">(</code><code class="n">df</code><code class="p">):</code>
            <code class="n">copy</code> <code class="o">=</code> <code class="n">df</code><code class="o">.</code><code class="n">copy</code><code class="p">()</code>
            <code class="n">zero</code> <code class="o">=</code> <code class="n">Counter</code><code class="p">(</code><code class="n">copy</code><code class="o">.</code><code class="n">label</code><code class="o">.</code><code class="n">values</code><code class="p">)[</code><code class="mi">0</code><code class="p">]</code>
            <code class="n">un</code> <code class="o">=</code> <code class="n">Counter</code><code class="p">(</code><code class="n">copy</code><code class="o">.</code><code class="n">label</code><code class="o">.</code><code class="n">values</code><code class="p">)[</code><code class="mi">1</code><code class="p">]</code>
            <code class="n">n</code> <code class="o">=</code> <code class="n">zero</code> <code class="o">-</code> <code class="n">un</code>
            <code class="n">copy</code> <code class="o">=</code> <code class="n">copy</code><code class="o">.</code><code class="n">drop</code><code class="p">(</code><code class="n">copy</code><code class="p">[</code><code class="n">copy</code><code class="o">.</code><code class="n">label</code> <code class="o">==</code> <code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="n">n</code><code class="o">=</code><code class="n">n</code><code class="p">,</code> <code class="n">random_state</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code><code class="o">.</code><code class="n">index</code><code class="p">)</code>
            <code class="k">return</code> <code class="n">copy</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="n">frac</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code></pre>
        
        <p>This function works out the difference between the number of positive and negative examples, and then samples the negative examples so that there are equal numbers.
        We can then run the following code to build a training set with balanced positive and negative examples:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">train_existing_links</code> <code class="o">=</code> <code class="n">graph</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="s2">"""</code>
        <code class="s2">MATCH (author:Author)-[:CO_AUTHOR_EARLY]-&gt;(other:Author)</code>
        <code class="s2">RETURN id(author) AS node1, id(other) AS node2, 1 AS label</code>
        <code class="s2">"""</code><code class="p">)</code><code class="o">.</code><code class="n">to_data_frame</code><code class="p">()</code>
        
        <code class="n">train_missing_links</code> <code class="o">=</code> <code class="n">graph</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="s2">"""</code>
        <code class="s2">MATCH (author:Author)</code>
        <code class="s2">WHERE (author)-[:CO_AUTHOR_EARLY]-()</code>
        <code class="s2">MATCH (author)-[:CO_AUTHOR_EARLY*2..3]-(other)</code>
        <code class="s2">WHERE not((author)-[:CO_AUTHOR_EARLY]-(other))</code>
        <code class="s2">RETURN id(author) AS node1, id(other) AS node2, 0 AS label</code>
        <code class="s2">"""</code><code class="p">)</code><code class="o">.</code><code class="n">to_data_frame</code><code class="p">()</code>
        
        <code class="n">train_missing_links</code> <code class="o">=</code> <code class="n">train_missing_links</code><code class="o">.</code><code class="n">drop_duplicates</code><code class="p">()</code>
        <code class="n">training_df</code> <code class="o">=</code> <code class="n">train_missing_links</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">train_existing_links</code><code class="p">,</code> <code class="n">ignore_index</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
        <code class="n">training_df</code><code class="p">[</code><code class="s1">'label'</code><code class="p">]</code> <code class="o">=</code> <code class="n">training_df</code><code class="p">[</code><code class="s1">'label'</code><code class="p">]</code><code class="o">.</code><code class="n">astype</code><code class="p">(</code><code class="s1">'category'</code><code class="p">)</code>
        <code class="n">training_df</code> <code class="o">=</code> <code class="n">down_sample</code><code class="p">(</code><code class="n">training_df</code><code class="p">)</code>
        <code class="n">training_data</code> <code class="o">=</code> <code class="n">spark</code><code class="o">.</code><code class="n">createDataFrame</code><code class="p">(</code><code class="n">training_df</code><code class="p">)</code></pre>
        
        <p>We’ve now coerced the <code>label</code> column to be a category, where <code>1</code> indicates that there is a link between a pair of nodes, and <code>0</code> indicates that there is not a link.
        We can look at the data in our DataFrame by running the following code:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">training_data</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="n">n</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code></pre>
        <table>
        
        <thead>
        <tr>
        <th>node1</th>
        <th>node2</th>
        <th>label</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>10019</p></td>
        <td><p>28091</p></td>
        <td><p>1</p></td>
        </tr>
        <tr>
        <td><p>10170</p></td>
        <td><p>51476</p></td>
        <td><p>1</p></td>
        </tr>
        <tr>
        <td><p>10259</p></td>
        <td><p>17140</p></td>
        <td><p>0</p></td>
        </tr>
        <tr>
        <td><p>10259</p></td>
        <td><p>26047</p></td>
        <td><p>1</p></td>
        </tr>
        <tr>
        <td><p>10293</p></td>
        <td><p>71349</p></td>
        <td><p>1</p></td>
        </tr>
        </tbody>
        </table>
        
        <p>The results show us a list of node pairs and whether they have a coauthor relationship; for example, nodes <code>10019</code> and <code>28091</code> have a <code>1</code> label, indicating a collaboration.</p>
        
        <p>Now let’s execute the following code to check the summary of contents for the DataFrame:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">training_data</code><code class="o">.</code><code class="n">groupby</code><code class="p">(</code><code class="s2">"label"</code><code class="p">)</code><code class="o">.</code><code class="n">count</code><code class="p">()</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>
        
        <p>Here’s the result:</p>
        <table>
        
        <thead>
        <tr>
        <th>label</th>
        <th>count</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>0</p></td>
        <td><p>81096</p></td>
        </tr>
        <tr>
        <td><p>1</p></td>
        <td><p>81096</p></td>
        </tr>
        </tbody>
        </table>
        
        <p>We’ve created our training set with the same number of positive and negative samples. Now we need to do the same for the test set.
        The following code will build a test set with balanced positive and negative examples:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">test_existing_links</code> <code class="o">=</code> <code class="n">graph</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="s2">"""</code>
        <code class="s2">MATCH (author:Author)-[:CO_AUTHOR_LATE]-&gt;(other:Author)</code>
        <code class="s2">RETURN id(author) AS node1, id(other) AS node2, 1 AS label</code>
        <code class="s2">"""</code><code class="p">)</code><code class="o">.</code><code class="n">to_data_frame</code><code class="p">()</code>
        
        <code class="n">test_missing_links</code> <code class="o">=</code> <code class="n">graph</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="s2">"""</code>
        <code class="s2">MATCH (author:Author)</code>
        <code class="s2">WHERE (author)-[:CO_AUTHOR_LATE]-()</code>
        <code class="s2">MATCH (author)-[:CO_AUTHOR*2..3]-(other)</code>
        <code class="s2">WHERE not((author)-[:CO_AUTHOR]-(other))</code>
        <code class="s2">RETURN id(author) AS node1, id(other) AS node2, 0 AS label</code>
        <code class="s2">"""</code><code class="p">)</code><code class="o">.</code><code class="n">to_data_frame</code><code class="p">()</code>
        
        <code class="n">test_missing_links</code> <code class="o">=</code> <code class="n">test_missing_links</code><code class="o">.</code><code class="n">drop_duplicates</code><code class="p">()</code>
        <code class="n">test_df</code> <code class="o">=</code> <code class="n">test_missing_links</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">test_existing_links</code><code class="p">,</code> <code class="n">ignore_index</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
        <code class="n">test_df</code><code class="p">[</code><code class="s1">'label'</code><code class="p">]</code> <code class="o">=</code> <code class="n">test_df</code><code class="p">[</code><code class="s1">'label'</code><code class="p">]</code><code class="o">.</code><code class="n">astype</code><code class="p">(</code><code class="s1">'category'</code><code class="p">)</code>
        <code class="n">test_df</code> <code class="o">=</code> <code class="n">down_sample</code><code class="p">(</code><code class="n">test_df</code><code class="p">)</code>
        <code class="n">test_data</code> <code class="o">=</code> <code class="n">spark</code><code class="o">.</code><code class="n">createDataFrame</code><code class="p">(</code><code class="n">test_df</code><code class="p">)</code></pre>
        
        <p>We can execute the following code to check the contents of the DataFrame:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">test_data</code><code class="o">.</code><code class="n">groupby</code><code class="p">(</code><code class="s2">"label"</code><code class="p">)</code><code class="o">.</code><code class="n">count</code><code class="p">()</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>
        
        <p>Which gives the following result:</p>
        <table>
        
        <thead>
        <tr>
        <th>label</th>
        <th>count</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>0</p></td>
        <td><p>74128</p></td>
        </tr>
        <tr>
        <td><p>1</p></td>
        <td><p>74128</p></td>
        </tr>
        </tbody>
        </table>
        
        <p>Now that we have balanced training and test datasets, let’s look at our methods for predicting links<a data-type="indexterm" data-startref="ix_ch8_worked_example-adoc5" id="idm46681357442520"></a>.<a data-type="indexterm" data-startref="ix_ch8_worked_example-adoc4" id="idm46681357441720"></a><a data-type="indexterm" data-startref="ix_ch8_worked_example-adoc3" id="idm46681357441048"></a><a data-type="indexterm" data-startref="ix_ch8_worked_example-adoc2" id="idm46681357440408"></a></p>
        </div></section>
        
        
        
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="How We Predict Missing Links"><div class="sect2" id="idm46681357903816">
        <h2>How We Predict Missing Links</h2>
        
        <p><a data-type="indexterm" data-primary="link prediction" data-secondary="predicting missing links" id="idm46681357439384"></a>We need to start with some basic assumptions about what elements in our data might predict whether two authors will become coauthors at a later date. Our hypothesis would vary by domain and problem, but in this case, we believe the most predictive features will be related to communities. We’ll begin with the assumption that the following elements increase the probability that authors become coauthors:</p>
        
        <ul>
        <li>
        <p>More coauthors in common</p>
        </li>
        <li>
        <p>Potential triadic relationships between authors</p>
        </li>
        <li>
        <p>Authors with more relationships</p>
        </li>
        <li>
        <p>Authors in the same community</p>
        </li>
        <li>
        <p>Authors in the same, tighter community</p>
        </li>
        </ul>
        
        <p>We’ll build graph features based on our assumptions and use those to train a binary classifier. <a data-type="indexterm" data-primary="binary classification" id="idm46681357431432"></a><em>Binary classification</em> is a type of ML with the task of predicting which of two predefined groups an element belongs to based on a rule. We’re using the classifier for the task of predicting whether a pair of authors will have a link or not, based on a classification rule.
        For our examples, a value of <code>1</code> means there is a link (coauthorship), and a value of <code>0</code> means there isn’t a link (no coauthorship).</p>
        
        <p><a data-type="indexterm" data-primary="random forest" id="idm46681357428792"></a>We’ll implement our binary classifier as a random forest in Spark. A <em>random forest</em> is an ensemble learning method for classification, regression, and other tasks, as illustrated in <a data-type="xref" href="#ch8-random-forest">Figure&nbsp;8-7</a>.</p>
        
        <figure><div id="ch8-random-forest" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_rr_0807.png" alt="gral rr 0807" width="1421" height="734">
        <h6><span class="label">Figure 8-7. </span>A random forest builds a collection of decision trees and then aggregates results for a majority vote (for classification) or an average value (for regression).</h6>
        </div></figure>
        
        <p>Our random forest classifier will take the results from the multiple decision trees we train and then use voting to predict a classification—in our example, whether there is a link (coauthorship) or not.</p>
        
        <p>Now let’s create our workflow.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Creating a Machine Learning Pipeline"><div class="sect2" id="idm46681357401160">
        <h2>Creating a Machine Learning Pipeline</h2>
        
        <p><a data-type="indexterm" data-primary="link prediction" data-secondary="creating machine learning pipeline" id="idm46681357399752"></a>We’ll create our machine learning pipeline based on a random forest classifier in Spark.
        This method is well suited as our dataset will be comprised of a mix of strong and weak features.
        While the weak features will sometimes be helpful, the random forest method will ensure we don’t create a model that only fits our training data.</p>
        
        <p>To create our ML pipeline, we’ll pass in a list of features as the <code>fields</code> variable—these are the features that our classifier will use.
        The classifier expects to receive those features as a single column called <code>features</code>, so we use the <code>VectorAssembler</code> to transform the data into the required format.</p>
        
        <p>The following code creates a machine learning pipeline and sets up our parameters using MLlib:</p>
        
        <pre data-type="programlisting" data-code-language="python" class="pagebreak-before"><code class="k">def</code> <code class="nf">create_pipeline</code><code class="p">(</code><code class="n">fields</code><code class="p">):</code>
            <code class="n">assembler</code> <code class="o">=</code> <code class="n">VectorAssembler</code><code class="p">(</code><code class="n">inputCols</code><code class="o">=</code><code class="n">fields</code><code class="p">,</code> <code class="n">outputCol</code><code class="o">=</code><code class="s2">"features"</code><code class="p">)</code>
            <code class="n">rf</code> <code class="o">=</code> <code class="n">RandomForestClassifier</code><code class="p">(</code><code class="n">labelCol</code><code class="o">=</code><code class="s2">"label"</code><code class="p">,</code> <code class="n">featuresCol</code><code class="o">=</code><code class="s2">"features"</code><code class="p">,</code>
                                        <code class="n">numTrees</code><code class="o">=</code><code class="mi">30</code><code class="p">,</code> <code class="n">maxDepth</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code>
            <code class="k">return</code> <code class="n">Pipeline</code><code class="p">(</code><code class="n">stages</code><code class="o">=</code><code class="p">[</code><code class="n">assembler</code><code class="p">,</code> <code class="n">rf</code><code class="p">])</code></pre>
        
        <p>The <code>RandomForestClassifier</code> uses these parameters:</p>
        <dl>
        <dt><code>labelCol</code></dt>
        <dd>
        <p>The name of the field containing the variable we want to predict; i.e., whether a pair of nodes have a link</p>
        </dd>
        <dt><code>featuresCol</code></dt>
        <dd>
        <p>The name of the field containing the variables that will be used to predict whether a pair of nodes have a link</p>
        </dd>
        <dt><code>numTrees</code></dt>
        <dd>
        <p>The number of decision trees that form the random forest</p>
        </dd>
        <dt><code>maxDepth</code></dt>
        <dd>
        <p>The maximum depth of the decision trees</p>
        </dd>
        </dl>
        
        <p>We chose the number of decision trees and their depth based on experimentation. We can think about hyperparameters like the settings of an algorithm that can be adjusted to optimize performance. The best hyperparameters are often difficult to determine ahead of time, and tuning a model usually requires some trial and error.</p>
        
        <p>We’ve covered the basics and set up our pipeline, so let’s dive into creating our model and evaluating how well it performs.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Predicting Links: Basic Graph Features"><div class="sect2" id="idm46681357298808">
        <h2>Predicting Links: Basic Graph Features</h2>
        
        <p><a data-type="indexterm" data-primary="link prediction" data-secondary="basic graph features for" id="ix_ch8_worked_example-adoc6"></a>We’ll start by creating a simple model that tries to predict whether two authors will have a future collaboration based on features extracted from common authors, preferential attachment, and the total union of neighbors:</p>
        <dl>
        <dt>Common authors</dt>
        <dd>
        <p>Finds the number of potential triangles between two authors. This captures the idea that two authors who have coauthors in common may be introduced and collaborate in the future.</p>
        </dd>
        <dt>Preferential attachment</dt>
        <dd>
        <p>Produces a score for each pair of authors by multiplying the number of coauthors each has. The intuition is that authors are more likely to collaborate with someone who already coauthors a lot of papers.</p>
        </dd>
        <dt>Total union of neighbors</dt>
        <dd>
        <p>Finds the total number of coauthors that each author has, minus the duplicates.</p>
        </dd>
        </dl>
        
        <p>In Neo4j, we can compute these values using Cypher queries.
        The following function will compute these measures for the training set:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">apply_graphy_training_features</code><code class="p">(</code><code class="n">data</code><code class="p">):</code>
            <code class="n">query</code> <code class="o">=</code> <code class="s2">"""</code>
        <code class="s2">    UNWIND $pairs AS pair</code>
        <code class="s2">    MATCH (p1) WHERE id(p1) = pair.node1</code>
        <code class="s2">    MATCH (p2) WHERE id(p2) = pair.node2</code>
        <code class="s2">    RETURN pair.node1 AS node1,</code>
        <code class="s2">           pair.node2 AS node2,</code>
        <code class="s2">           gds.alpha.linkprediction.commonNeighbors(p1, p2, {</code>
        <code class="s2">             relationshipQuery: "CO_AUTHOR_EARLY"}) AS commonAuthors,</code>
        <code class="s2">           gds.alpha.linkprediction.preferentialAttachment(p1, p2, {</code>
        <code class="s2">             relationshipQuery: "CO_AUTHOR_EARLY"}) AS prefAttachment,</code>
        <code class="s2">           gds.alpha.linkprediction.totalNeighbors(p1, p2, {</code>
        <code class="s2">             relationshipQuery: "CO_AUTHOR_EARLY"}) AS totalNeighbours</code>
        <code class="s2">    """</code>
            <code class="n">pairs</code> <code class="o">=</code> <code class="p">[{</code>
                <code class="s2">"node1"</code><code class="p">:</code> <code class="n">row</code><code class="p">[</code><code class="s2">"node1"</code><code class="p">],</code>
                <code class="s2">"node2"</code><code class="p">:</code> <code class="n">row</code><code class="p">[</code><code class="s2">"node2"</code><code class="p">]</code>
            <code class="p">}</code> <code class="k">for</code> <code class="n">row</code> <code class="ow">in</code> <code class="n">data</code><code class="o">.</code><code class="n">collect</code><code class="p">()]</code>
            <code class="n">features</code> <code class="o">=</code> <code class="n">spark</code><code class="o">.</code><code class="n">createDataFrame</code><code class="p">(</code>
                <code class="n">graph</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">query</code><code class="p">,</code> <code class="p">{</code>
                    <code class="s2">"pairs"</code><code class="p">:</code> <code class="n">pairs</code>
                <code class="p">})</code><code class="o">.</code><code class="n">to_data_frame</code><code class="p">())</code>
            <code class="k">return</code> <code class="n">data</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="n">features</code><code class="p">,</code> <code class="p">[</code><code class="s2">"node1"</code><code class="p">,</code> <code class="s2">"node2"</code><code class="p">])</code></pre>
        
        <p>And the following function will compute them for the test set:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">apply_graphy_test_features</code><code class="p">(</code><code class="n">data</code><code class="p">):</code>
            <code class="n">query</code> <code class="o">=</code> <code class="s2">"""</code>
        <code class="s2">    UNWIND $pairs AS pair</code>
        <code class="s2">    MATCH (p1) WHERE id(p1) = pair.node1</code>
        <code class="s2">    MATCH (p2) WHERE id(p2) = pair.node2</code>
        <code class="s2">    RETURN pair.node1 AS node1,</code>
        <code class="s2">           pair.node2 AS node2,</code>
        <code class="s2">           gds.alpha.linkprediction.commonNeighbors(p1, p2, {</code>
        <code class="s2">             relationshipQuery: "CO_AUTHOR"}) AS commonAuthors,</code>
        <code class="s2">           gds.alpha.linkprediction.preferentialAttachment(p1, p2, {</code>
        <code class="s2">             relationshipQuery: "CO_AUTHOR"}) AS prefAttachment,</code>
        <code class="s2">           gds.alpha.linkprediction.totalNeighbors(p1, p2, {</code>
        <code class="s2">             relationshipQuery: "CO_AUTHOR"}) AS totalNeighbours</code>
        <code class="s2">    """</code>
            <code class="n">pairs</code> <code class="o">=</code> <code class="p">[{</code>
                <code class="s2">"node1"</code><code class="p">:</code> <code class="n">row</code><code class="p">[</code><code class="s2">"node1"</code><code class="p">],</code>
                <code class="s2">"node2"</code><code class="p">:</code> <code class="n">row</code><code class="p">[</code><code class="s2">"node2"</code><code class="p">]</code>
            <code class="p">}</code> <code class="k">for</code> <code class="n">row</code> <code class="ow">in</code> <code class="n">data</code><code class="o">.</code><code class="n">collect</code><code class="p">()]</code>
            <code class="n">features</code> <code class="o">=</code> <code class="n">spark</code><code class="o">.</code><code class="n">createDataFrame</code><code class="p">(</code>
                <code class="n">graph</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">query</code><code class="p">,</code> <code class="p">{</code>
                    <code class="s2">"pairs"</code><code class="p">:</code> <code class="n">pairs</code>
                <code class="p">})</code><code class="o">.</code><code class="n">to_data_frame</code><code class="p">())</code>
            <code class="k">return</code> <code class="n">data</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="n">features</code><code class="p">,</code> <code class="p">[</code><code class="s2">"node1"</code><code class="p">,</code> <code class="s2">"node2"</code><code class="p">])</code></pre>
        
        <p>Both of these functions take in a DataFrame that contains pairs of nodes in the columns <code>node1</code> and <code>node2</code>.
        We then build an array of maps containing these pairs and compute each of the measures for each pair of nodes.</p>
        <div data-type="note" epub:type="note"><h6>Note</h6>
        <p>The <code>UNWIND</code> clause is particularly useful in this chapter for taking a large collection of node pairs and returning all their features in one query.</p>
        </div>
        
        <p>We can apply these functions in Spark to our training and test DataFrames with the following code:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">training_data</code> <code class="o">=</code> <code class="n">apply_graphy_training_features</code><code class="p">(</code><code class="n">training_data</code><code class="p">)</code>
        <code class="n">test_data</code> <code class="o">=</code> <code class="n">apply_graphy_test_features</code><code class="p">(</code><code class="n">test_data</code><code class="p">)</code></pre>
        
        <p>Let’s explore the data in our training set.
        The following code will plot a histogram of the frequency of <code>commonAuthors</code>:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">plt</code><code class="o">.</code><code class="n">style</code><code class="o">.</code><code class="n">use</code><code class="p">(</code><code class="s1">'fivethirtyeight'</code><code class="p">)</code>
        <code class="n">fig</code><code class="p">,</code> <code class="n">axs</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">,</code> <code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">18</code><code class="p">,</code> <code class="mi">7</code><code class="p">),</code> <code class="n">sharey</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
        <code class="n">charts</code> <code class="o">=</code> <code class="p">[(</code><code class="mi">1</code><code class="p">,</code> <code class="s2">"have collaborated"</code><code class="p">),</code> <code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="s2">"haven't collaborated"</code><code class="p">)]</code>
        
        <code class="k">for</code> <code class="n">index</code><code class="p">,</code> <code class="n">chart</code> <code class="ow">in</code> <code class="nb">enumerate</code><code class="p">(</code><code class="n">charts</code><code class="p">):</code>
            <code class="n">label</code><code class="p">,</code> <code class="n">title</code> <code class="o">=</code> <code class="n">chart</code>
            <code class="n">filtered</code> <code class="o">=</code> <code class="n">training_data</code><code class="o">.</code><code class="n">filter</code><code class="p">(</code><code class="n">training_data</code><code class="p">[</code><code class="s2">"label"</code><code class="p">]</code> <code class="o">==</code> <code class="n">label</code><code class="p">)</code>
            <code class="n">common_authors</code> <code class="o">=</code> <code class="n">filtered</code><code class="o">.</code><code class="n">toPandas</code><code class="p">()[</code><code class="s2">"commonAuthors"</code><code class="p">]</code>
            <code class="n">histogram</code> <code class="o">=</code> <code class="n">common_authors</code><code class="o">.</code><code class="n">value_counts</code><code class="p">()</code><code class="o">.</code><code class="n">sort_index</code><code class="p">()</code>
            <code class="n">histogram</code> <code class="o">/=</code> <code class="nb">float</code><code class="p">(</code><code class="n">histogram</code><code class="o">.</code><code class="n">sum</code><code class="p">())</code>
            <code class="n">histogram</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">kind</code><code class="o">=</code><code class="s2">"bar"</code><code class="p">,</code> <code class="n">x</code><code class="o">=</code><code class="s1">'Common Authors'</code><code class="p">,</code> <code class="n">color</code><code class="o">=</code><code class="s2">"darkblue"</code><code class="p">,</code>
                           <code class="n">ax</code><code class="o">=</code><code class="n">axs</code><code class="p">[</code><code class="n">index</code><code class="p">],</code> <code class="n">title</code><code class="o">=</code><code class="n">f</code><code class="s2">"Authors who {title} (label={label})"</code><code class="p">)</code>
            <code class="n">axs</code><code class="p">[</code><code class="n">index</code><code class="p">]</code><code class="o">.</code><code class="n">xaxis</code><code class="o">.</code><code class="n">set_label_text</code><code class="p">(</code><code class="s2">"Common Authors"</code><code class="p">)</code>
        
        <code class="n">plt</code><code class="o">.</code><code class="n">tight_layout</code><code class="p">()</code>
        <code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>
        
        <p>We can see the chart generated in <a data-type="xref" href="#ch8-explore-authors">Figure&nbsp;8-8</a>.</p>
        
        <figure><div id="ch8-explore-authors" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_rr_0808.png" alt="gral rr 0808" width="1407" height="526">
        <h6><span class="label">Figure 8-8. </span>Frequency of commonAuthors</h6>
        </div></figure>
        
        <p>On the left we see the frequency of <code>commonAuthors</code> when authors have collaborated, and on the right we see the frequency of <code>commonAuthors</code> when they haven’t.
        For those who haven’t collaborated (right side) the maximum number of common authors is 9, but 95% of the values are 1 or 0. It’s not surprising that of the people who have not collaborated on a paper, most also do not have many other coauthors in common.
        For those who have collaborated (left side), 70% have less than five coauthors in common, with a spike between one and two other coauthors.</p>
        
        <p>Now we want to train a model to predict missing links. The following function does this:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">train_model</code><code class="p">(</code><code class="n">fields</code><code class="p">,</code> <code class="n">training_data</code><code class="p">):</code>
            <code class="n">pipeline</code> <code class="o">=</code> <code class="n">create_pipeline</code><code class="p">(</code><code class="n">fields</code><code class="p">)</code>
            <code class="n">model</code> <code class="o">=</code> <code class="n">pipeline</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">training_data</code><code class="p">)</code>
            <code class="k">return</code> <code class="n">model</code></pre>
        
        <p>We’ll start by creating a basic model that only uses <code>commonAuthors</code>.
        We can create that model by running this code:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">basic_model</code> <code class="o">=</code> <code class="n">train_model</code><code class="p">([</code><code class="s2">"commonAuthors"</code><code class="p">],</code> <code class="n">training_data</code><code class="p">)</code></pre>
        
        <p>With our model trained, let’s check how it performs against some dummy data. The following code evaluates the code against different values for <code>commonAuthors</code>:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">eval_df</code> <code class="o">=</code> <code class="n">spark</code><code class="o">.</code><code class="n">createDataFrame</code><code class="p">(</code>
            <code class="p">[(</code><code class="mi">0</code><code class="p">,),</code> <code class="p">(</code><code class="mi">1</code><code class="p">,),</code> <code class="p">(</code><code class="mi">2</code><code class="p">,),</code> <code class="p">(</code><code class="mi">10</code><code class="p">,),</code> <code class="p">(</code><code class="mi">100</code><code class="p">,)],</code>
            <code class="p">[</code><code class="s1">'commonAuthors'</code><code class="p">])</code>
        
        <code class="p">(</code><code class="n">basic_model</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">eval_df</code><code class="p">)</code>
         <code class="o">.</code><code class="n">select</code><code class="p">(</code><code class="s2">"commonAuthors"</code><code class="p">,</code> <code class="s2">"probability"</code><code class="p">,</code> <code class="s2">"prediction"</code><code class="p">)</code>
         <code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="n">truncate</code><code class="o">=</code><code class="bp">False</code><code class="p">))</code></pre>
        
        <p class="pagebreak-before">Running that code will give the following result:</p>
        <table>
        
        <thead>
        <tr>
        <th>commonAuthors</th>
        <th>probability</th>
        <th>prediction</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>0</p></td>
        <td><p>[0.7540494940434322,0.24595050595656787]</p></td>
        <td><p>0.0</p></td>
        </tr>
        <tr>
        <td><p>1</p></td>
        <td><p>[0.7540494940434322,0.24595050595656787]</p></td>
        <td><p>0.0</p></td>
        </tr>
        <tr>
        <td><p>2</p></td>
        <td><p>[0.0536835525078107,0.9463164474921892]</p></td>
        <td><p>1.0</p></td>
        </tr>
        <tr>
        <td><p>10</p></td>
        <td><p>[0.0536835525078107,0.9463164474921892]</p></td>
        <td><p>1.0</p></td>
        </tr>
        </tbody>
        </table>
        
        <p>If we have a <code>commonAuthors</code> value of less than 2 there’s a 75% probability that there won’t be a relationship between the authors, so our model predicts 0.
        If we have a <code>commonAuthors</code> value of 2 or more there’s a 94% probability that there will be a relationship between the authors, so our model predicts 1.</p>
        
        <p>Let’s now evaluate our model against the test set.
        Although there are several ways to evaluate how well a model performs, most are derived from a few baseline predictive metrics, as outlined in <a data-type="xref" href="#predictive-metrics">Table&nbsp;8-1</a>.</p>
        <table class="custom_table" id="predictive-metrics">
        <caption><span class="label">Table 8-1. </span>Predictive metrics</caption>
        <thead>
        <tr>
        <th>Measure</th>
        <th>Formula</th>
        <th>Description</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>Accuracy</p></td>
        <td><p><mjx-container class="MathJax CtxtMenu_Attached_0" jax="SVG" display="true" tabindex="0" ctxtmenu_counter="26" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="33.282ex" height="4.652ex" role="img" focusable="false" viewBox="0 -1359 14710.4 2056" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -1.577ex;"><defs><path id="MJX-27-TEX-I-1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path><path id="MJX-27-TEX-I-1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-27-TEX-I-1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-27-TEX-I-1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path id="MJX-27-TEX-I-1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path><path id="MJX-27-TEX-I-1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path id="MJX-27-TEX-I-1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path id="MJX-27-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-27-TEX-I-1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path id="MJX-27-TEX-I-1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path><path id="MJX-27-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-27-TEX-I-1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path><path id="MJX-27-TEX-I-1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path><path id="MJX-27-TEX-I-1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path><path id="MJX-27-TEX-I-1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path id="MJX-27-TEX-I-1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path><path id="MJX-27-TEX-I-1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path><path id="MJX-27-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><use data-c="1D447" xlink:href="#MJX-27-TEX-I-1D447"></use></g><g data-mml-node="mi" transform="translate(704,0)"><use data-c="1D45F" xlink:href="#MJX-27-TEX-I-1D45F"></use></g><g data-mml-node="mi" transform="translate(1155,0)"><use data-c="1D462" xlink:href="#MJX-27-TEX-I-1D462"></use></g><g data-mml-node="mi" transform="translate(1727,0)"><use data-c="1D452" xlink:href="#MJX-27-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(2193,0)"><use data-c="1D443" xlink:href="#MJX-27-TEX-I-1D443"></use></g><g data-mml-node="mi" transform="translate(2944,0)"><use data-c="1D45C" xlink:href="#MJX-27-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(3429,0)"><use data-c="1D460" xlink:href="#MJX-27-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(3898,0)"><use data-c="1D456" xlink:href="#MJX-27-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(4243,0)"><use data-c="1D461" xlink:href="#MJX-27-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(4604,0)"><use data-c="1D456" xlink:href="#MJX-27-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(4949,0)"><use data-c="1D463" xlink:href="#MJX-27-TEX-I-1D463"></use></g><g data-mml-node="mi" transform="translate(5434,0)"><use data-c="1D452" xlink:href="#MJX-27-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(5900,0)"><use data-c="1D460" xlink:href="#MJX-27-TEX-I-1D460"></use></g><g data-mml-node="mo" transform="translate(6591.2,0)"><use data-c="2B" xlink:href="#MJX-27-TEX-N-2B"></use></g><g data-mml-node="mi" transform="translate(7591.4,0)"><use data-c="1D447" xlink:href="#MJX-27-TEX-I-1D447"></use></g><g data-mml-node="mi" transform="translate(8295.4,0)"><use data-c="1D45F" xlink:href="#MJX-27-TEX-I-1D45F"></use></g><g data-mml-node="mi" transform="translate(8746.4,0)"><use data-c="1D462" xlink:href="#MJX-27-TEX-I-1D462"></use></g><g data-mml-node="mi" transform="translate(9318.4,0)"><use data-c="1D452" xlink:href="#MJX-27-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(9784.4,0)"><use data-c="1D441" xlink:href="#MJX-27-TEX-I-1D441"></use></g><g data-mml-node="mi" transform="translate(10672.4,0)"><use data-c="1D452" xlink:href="#MJX-27-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(11138.4,0)"><use data-c="1D454" xlink:href="#MJX-27-TEX-I-1D454"></use></g><g data-mml-node="mi" transform="translate(11615.4,0)"><use data-c="1D44E" xlink:href="#MJX-27-TEX-I-1D44E"></use></g><g data-mml-node="mi" transform="translate(12144.4,0)"><use data-c="1D461" xlink:href="#MJX-27-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(12505.4,0)"><use data-c="1D456" xlink:href="#MJX-27-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(12850.4,0)"><use data-c="1D463" xlink:href="#MJX-27-TEX-I-1D463"></use></g><g data-mml-node="mi" transform="translate(13335.4,0)"><use data-c="1D452" xlink:href="#MJX-27-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(13801.4,0)"><use data-c="1D460" xlink:href="#MJX-27-TEX-I-1D460"></use></g></g><g data-mml-node="mrow" transform="translate(3553.7,-686)"><g data-mml-node="mi"><use data-c="1D447" xlink:href="#MJX-27-TEX-I-1D447"></use></g><g data-mml-node="mi" transform="translate(704,0)"><use data-c="1D45C" xlink:href="#MJX-27-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(1189,0)"><use data-c="1D461" xlink:href="#MJX-27-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(1550,0)"><use data-c="1D44E" xlink:href="#MJX-27-TEX-I-1D44E"></use></g><g data-mml-node="mi" transform="translate(2079,0)"><use data-c="1D459" xlink:href="#MJX-27-TEX-I-1D459"></use></g><g data-mml-node="mi" transform="translate(2377,0)"><use data-c="1D443" xlink:href="#MJX-27-TEX-I-1D443"></use></g><g data-mml-node="mi" transform="translate(3128,0)"><use data-c="1D45F" xlink:href="#MJX-27-TEX-I-1D45F"></use></g><g data-mml-node="mi" transform="translate(3579,0)"><use data-c="1D452" xlink:href="#MJX-27-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(4045,0)"><use data-c="1D451" xlink:href="#MJX-27-TEX-I-1D451"></use></g><g data-mml-node="mi" transform="translate(4565,0)"><use data-c="1D456" xlink:href="#MJX-27-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(4910,0)"><use data-c="1D450" xlink:href="#MJX-27-TEX-I-1D450"></use></g><g data-mml-node="mi" transform="translate(5343,0)"><use data-c="1D461" xlink:href="#MJX-27-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(5704,0)"><use data-c="1D456" xlink:href="#MJX-27-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(6049,0)"><use data-c="1D45C" xlink:href="#MJX-27-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(6534,0)"><use data-c="1D45B" xlink:href="#MJX-27-TEX-I-1D45B"></use></g><g data-mml-node="mi" transform="translate(7134,0)"><use data-c="1D460" xlink:href="#MJX-27-TEX-I-1D460"></use></g></g><rect width="14470.4" height="60" x="120" y="220"></rect></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block" alttext="StartFraction upper T r u e upper P o s i t i v e s plus upper T r u e upper N e g a t i v e s Over upper T o t a l upper P r e d i c t i o n s EndFraction"><mfrac><mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>+</mo><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>N</mi><mi>e</mi><mi>g</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow><mrow><mi>T</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi><mi>P</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>s</mi></mrow></mfrac></math></mjx-assistive-mml></mjx-container></p></td>
        <td><p>The fraction of predictions our model gets right, or the total number of correct predictions divided by the total number of predictions.
        Note that accuracy alone can be misleading, especially when our data is unbalanced.
        For example, if we have a dataset containing 95 cats and 5 dogs and our model predicts that every image is a cat we’ll have a 95% accuracy score despite correctly identifying none of the dogs.</p></td>
        </tr>
        <tr>
        <td><p>Precision</p></td>
        <td><p><mjx-container class="MathJax CtxtMenu_Attached_0" jax="SVG" display="true" tabindex="0" ctxtmenu_counter="27" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="33.3ex" height="4.812ex" role="img" focusable="false" viewBox="0 -1359 14718.4 2127" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -1.738ex;"><defs><path id="MJX-28-TEX-I-1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path><path id="MJX-28-TEX-I-1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-28-TEX-I-1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-28-TEX-I-1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path id="MJX-28-TEX-I-1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path><path id="MJX-28-TEX-I-1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path id="MJX-28-TEX-I-1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path id="MJX-28-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-28-TEX-I-1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path id="MJX-28-TEX-I-1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path><path id="MJX-28-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-28-TEX-I-1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path><path id="MJX-28-TEX-I-1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path><path id="MJX-28-TEX-I-1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(4174.7,676)"><g data-mml-node="mi"><use data-c="1D447" xlink:href="#MJX-28-TEX-I-1D447"></use></g><g data-mml-node="mi" transform="translate(704,0)"><use data-c="1D45F" xlink:href="#MJX-28-TEX-I-1D45F"></use></g><g data-mml-node="mi" transform="translate(1155,0)"><use data-c="1D462" xlink:href="#MJX-28-TEX-I-1D462"></use></g><g data-mml-node="mi" transform="translate(1727,0)"><use data-c="1D452" xlink:href="#MJX-28-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(2193,0)"><use data-c="1D443" xlink:href="#MJX-28-TEX-I-1D443"></use></g><g data-mml-node="mi" transform="translate(2944,0)"><use data-c="1D45C" xlink:href="#MJX-28-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(3429,0)"><use data-c="1D460" xlink:href="#MJX-28-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(3898,0)"><use data-c="1D456" xlink:href="#MJX-28-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(4243,0)"><use data-c="1D461" xlink:href="#MJX-28-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(4604,0)"><use data-c="1D456" xlink:href="#MJX-28-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(4949,0)"><use data-c="1D463" xlink:href="#MJX-28-TEX-I-1D463"></use></g><g data-mml-node="mi" transform="translate(5434,0)"><use data-c="1D452" xlink:href="#MJX-28-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(5900,0)"><use data-c="1D460" xlink:href="#MJX-28-TEX-I-1D460"></use></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><use data-c="1D447" xlink:href="#MJX-28-TEX-I-1D447"></use></g><g data-mml-node="mi" transform="translate(704,0)"><use data-c="1D45F" xlink:href="#MJX-28-TEX-I-1D45F"></use></g><g data-mml-node="mi" transform="translate(1155,0)"><use data-c="1D462" xlink:href="#MJX-28-TEX-I-1D462"></use></g><g data-mml-node="mi" transform="translate(1727,0)"><use data-c="1D452" xlink:href="#MJX-28-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(2193,0)"><use data-c="1D443" xlink:href="#MJX-28-TEX-I-1D443"></use></g><g data-mml-node="mi" transform="translate(2944,0)"><use data-c="1D45C" xlink:href="#MJX-28-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(3429,0)"><use data-c="1D460" xlink:href="#MJX-28-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(3898,0)"><use data-c="1D456" xlink:href="#MJX-28-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(4243,0)"><use data-c="1D461" xlink:href="#MJX-28-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(4604,0)"><use data-c="1D456" xlink:href="#MJX-28-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(4949,0)"><use data-c="1D463" xlink:href="#MJX-28-TEX-I-1D463"></use></g><g data-mml-node="mi" transform="translate(5434,0)"><use data-c="1D452" xlink:href="#MJX-28-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(5900,0)"><use data-c="1D460" xlink:href="#MJX-28-TEX-I-1D460"></use></g><g data-mml-node="mo" transform="translate(6591.2,0)"><use data-c="2B" xlink:href="#MJX-28-TEX-N-2B"></use></g><g data-mml-node="mi" transform="translate(7591.4,0)"><use data-c="1D439" xlink:href="#MJX-28-TEX-I-1D439"></use></g><g data-mml-node="mi" transform="translate(8340.4,0)"><use data-c="1D44E" xlink:href="#MJX-28-TEX-I-1D44E"></use></g><g data-mml-node="mi" transform="translate(8869.4,0)"><use data-c="1D459" xlink:href="#MJX-28-TEX-I-1D459"></use></g><g data-mml-node="mi" transform="translate(9167.4,0)"><use data-c="1D460" xlink:href="#MJX-28-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(9636.4,0)"><use data-c="1D452" xlink:href="#MJX-28-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(10102.4,0)"><use data-c="1D443" xlink:href="#MJX-28-TEX-I-1D443"></use></g><g data-mml-node="mi" transform="translate(10853.4,0)"><use data-c="1D45C" xlink:href="#MJX-28-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(11338.4,0)"><use data-c="1D460" xlink:href="#MJX-28-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(11807.4,0)"><use data-c="1D456" xlink:href="#MJX-28-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(12152.4,0)"><use data-c="1D461" xlink:href="#MJX-28-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(12513.4,0)"><use data-c="1D456" xlink:href="#MJX-28-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(12858.4,0)"><use data-c="1D463" xlink:href="#MJX-28-TEX-I-1D463"></use></g><g data-mml-node="mi" transform="translate(13343.4,0)"><use data-c="1D452" xlink:href="#MJX-28-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(13809.4,0)"><use data-c="1D460" xlink:href="#MJX-28-TEX-I-1D460"></use></g></g><rect width="14478.4" height="60" x="120" y="220"></rect></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block" alttext="StartFraction upper T r u e upper P o s i t i v e s Over upper T r u e upper P o s i t i v e s plus upper F a l s e upper P o s i t i v e s EndFraction"><mfrac><mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow><mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>+</mo><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow></mfrac></math></mjx-assistive-mml></mjx-container></p></td>
        <td><p>The proportion of <em>positive identifications</em> that are correct.
        A low precision score indicates more false positives.
        A model that produces no false positives has a precision of 1.0.</p></td>
        </tr>
        <tr>
        <td><p>Recall (true positive rate)</p></td>
        <td><p><mjx-container class="MathJax CtxtMenu_Attached_0" jax="SVG" display="true" tabindex="0" ctxtmenu_counter="28" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="34.001ex" height="5.09ex" role="img" focusable="false" viewBox="0 -1359 15028.4 2250" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -2.016ex;"><defs><path id="MJX-29-TEX-I-1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path><path id="MJX-29-TEX-I-1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-29-TEX-I-1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-29-TEX-I-1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path id="MJX-29-TEX-I-1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path><path id="MJX-29-TEX-I-1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path id="MJX-29-TEX-I-1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path id="MJX-29-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-29-TEX-I-1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path id="MJX-29-TEX-I-1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path><path id="MJX-29-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-29-TEX-I-1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path><path id="MJX-29-TEX-I-1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path><path id="MJX-29-TEX-I-1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path id="MJX-29-TEX-I-1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path><path id="MJX-29-TEX-I-1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(4329.7,676)"><g data-mml-node="mi"><use data-c="1D447" xlink:href="#MJX-29-TEX-I-1D447"></use></g><g data-mml-node="mi" transform="translate(704,0)"><use data-c="1D45F" xlink:href="#MJX-29-TEX-I-1D45F"></use></g><g data-mml-node="mi" transform="translate(1155,0)"><use data-c="1D462" xlink:href="#MJX-29-TEX-I-1D462"></use></g><g data-mml-node="mi" transform="translate(1727,0)"><use data-c="1D452" xlink:href="#MJX-29-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(2193,0)"><use data-c="1D443" xlink:href="#MJX-29-TEX-I-1D443"></use></g><g data-mml-node="mi" transform="translate(2944,0)"><use data-c="1D45C" xlink:href="#MJX-29-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(3429,0)"><use data-c="1D460" xlink:href="#MJX-29-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(3898,0)"><use data-c="1D456" xlink:href="#MJX-29-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(4243,0)"><use data-c="1D461" xlink:href="#MJX-29-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(4604,0)"><use data-c="1D456" xlink:href="#MJX-29-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(4949,0)"><use data-c="1D463" xlink:href="#MJX-29-TEX-I-1D463"></use></g><g data-mml-node="mi" transform="translate(5434,0)"><use data-c="1D452" xlink:href="#MJX-29-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(5900,0)"><use data-c="1D460" xlink:href="#MJX-29-TEX-I-1D460"></use></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><use data-c="1D447" xlink:href="#MJX-29-TEX-I-1D447"></use></g><g data-mml-node="mi" transform="translate(704,0)"><use data-c="1D45F" xlink:href="#MJX-29-TEX-I-1D45F"></use></g><g data-mml-node="mi" transform="translate(1155,0)"><use data-c="1D462" xlink:href="#MJX-29-TEX-I-1D462"></use></g><g data-mml-node="mi" transform="translate(1727,0)"><use data-c="1D452" xlink:href="#MJX-29-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(2193,0)"><use data-c="1D443" xlink:href="#MJX-29-TEX-I-1D443"></use></g><g data-mml-node="mi" transform="translate(2944,0)"><use data-c="1D45C" xlink:href="#MJX-29-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(3429,0)"><use data-c="1D460" xlink:href="#MJX-29-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(3898,0)"><use data-c="1D456" xlink:href="#MJX-29-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(4243,0)"><use data-c="1D461" xlink:href="#MJX-29-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(4604,0)"><use data-c="1D456" xlink:href="#MJX-29-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(4949,0)"><use data-c="1D463" xlink:href="#MJX-29-TEX-I-1D463"></use></g><g data-mml-node="mi" transform="translate(5434,0)"><use data-c="1D452" xlink:href="#MJX-29-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(5900,0)"><use data-c="1D460" xlink:href="#MJX-29-TEX-I-1D460"></use></g><g data-mml-node="mo" transform="translate(6591.2,0)"><use data-c="2B" xlink:href="#MJX-29-TEX-N-2B"></use></g><g data-mml-node="mi" transform="translate(7591.4,0)"><use data-c="1D439" xlink:href="#MJX-29-TEX-I-1D439"></use></g><g data-mml-node="mi" transform="translate(8340.4,0)"><use data-c="1D44E" xlink:href="#MJX-29-TEX-I-1D44E"></use></g><g data-mml-node="mi" transform="translate(8869.4,0)"><use data-c="1D459" xlink:href="#MJX-29-TEX-I-1D459"></use></g><g data-mml-node="mi" transform="translate(9167.4,0)"><use data-c="1D460" xlink:href="#MJX-29-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(9636.4,0)"><use data-c="1D452" xlink:href="#MJX-29-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(10102.4,0)"><use data-c="1D441" xlink:href="#MJX-29-TEX-I-1D441"></use></g><g data-mml-node="mi" transform="translate(10990.4,0)"><use data-c="1D452" xlink:href="#MJX-29-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(11456.4,0)"><use data-c="1D454" xlink:href="#MJX-29-TEX-I-1D454"></use></g><g data-mml-node="mi" transform="translate(11933.4,0)"><use data-c="1D44E" xlink:href="#MJX-29-TEX-I-1D44E"></use></g><g data-mml-node="mi" transform="translate(12462.4,0)"><use data-c="1D461" xlink:href="#MJX-29-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(12823.4,0)"><use data-c="1D456" xlink:href="#MJX-29-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(13168.4,0)"><use data-c="1D463" xlink:href="#MJX-29-TEX-I-1D463"></use></g><g data-mml-node="mi" transform="translate(13653.4,0)"><use data-c="1D452" xlink:href="#MJX-29-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(14119.4,0)"><use data-c="1D460" xlink:href="#MJX-29-TEX-I-1D460"></use></g></g><rect width="14788.4" height="60" x="120" y="220"></rect></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block" alttext="StartFraction upper T r u e upper P o s i t i v e s Over upper T r u e upper P o s i t i v e s plus upper F a l s e upper N e g a t i v e s EndFraction"><mfrac><mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow><mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>+</mo><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mi>N</mi><mi>e</mi><mi>g</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow></mfrac></math></mjx-assistive-mml></mjx-container></p></td>
        <td><p>The proportion of <em>actual positives</em> that are identified correctly.
        A low recall score indicates more false negatives.
        A model that produces no false negatives has a recall of 1.0.</p></td>
        </tr>
        <tr>
        <td><p>False positive rate</p></td>
        <td><p><mjx-container class="MathJax CtxtMenu_Attached_0" jax="SVG" display="true" tabindex="0" ctxtmenu_counter="29" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="34.001ex" height="5.115ex" role="img" focusable="false" viewBox="0 -1370 15028.4 2261" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -2.016ex;"><defs><path id="MJX-30-TEX-I-1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path><path id="MJX-30-TEX-I-1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path><path id="MJX-30-TEX-I-1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path id="MJX-30-TEX-I-1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path id="MJX-30-TEX-I-1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path id="MJX-30-TEX-I-1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path><path id="MJX-30-TEX-I-1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path id="MJX-30-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-30-TEX-I-1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path id="MJX-30-TEX-I-1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path><path id="MJX-30-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-30-TEX-I-1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path><path id="MJX-30-TEX-I-1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-30-TEX-I-1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-30-TEX-I-1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path><path id="MJX-30-TEX-I-1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(4170.7,676)"><g data-mml-node="mi"><use data-c="1D439" xlink:href="#MJX-30-TEX-I-1D439"></use></g><g data-mml-node="mi" transform="translate(749,0)"><use data-c="1D44E" xlink:href="#MJX-30-TEX-I-1D44E"></use></g><g data-mml-node="mi" transform="translate(1278,0)"><use data-c="1D459" xlink:href="#MJX-30-TEX-I-1D459"></use></g><g data-mml-node="mi" transform="translate(1576,0)"><use data-c="1D460" xlink:href="#MJX-30-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(2045,0)"><use data-c="1D452" xlink:href="#MJX-30-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(2511,0)"><use data-c="1D443" xlink:href="#MJX-30-TEX-I-1D443"></use></g><g data-mml-node="mi" transform="translate(3262,0)"><use data-c="1D45C" xlink:href="#MJX-30-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(3747,0)"><use data-c="1D460" xlink:href="#MJX-30-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(4216,0)"><use data-c="1D456" xlink:href="#MJX-30-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(4561,0)"><use data-c="1D461" xlink:href="#MJX-30-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(4922,0)"><use data-c="1D456" xlink:href="#MJX-30-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(5267,0)"><use data-c="1D463" xlink:href="#MJX-30-TEX-I-1D463"></use></g><g data-mml-node="mi" transform="translate(5752,0)"><use data-c="1D452" xlink:href="#MJX-30-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(6218,0)"><use data-c="1D460" xlink:href="#MJX-30-TEX-I-1D460"></use></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><use data-c="1D439" xlink:href="#MJX-30-TEX-I-1D439"></use></g><g data-mml-node="mi" transform="translate(749,0)"><use data-c="1D44E" xlink:href="#MJX-30-TEX-I-1D44E"></use></g><g data-mml-node="mi" transform="translate(1278,0)"><use data-c="1D459" xlink:href="#MJX-30-TEX-I-1D459"></use></g><g data-mml-node="mi" transform="translate(1576,0)"><use data-c="1D460" xlink:href="#MJX-30-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(2045,0)"><use data-c="1D452" xlink:href="#MJX-30-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(2511,0)"><use data-c="1D443" xlink:href="#MJX-30-TEX-I-1D443"></use></g><g data-mml-node="mi" transform="translate(3262,0)"><use data-c="1D45C" xlink:href="#MJX-30-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(3747,0)"><use data-c="1D460" xlink:href="#MJX-30-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(4216,0)"><use data-c="1D456" xlink:href="#MJX-30-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(4561,0)"><use data-c="1D461" xlink:href="#MJX-30-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(4922,0)"><use data-c="1D456" xlink:href="#MJX-30-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(5267,0)"><use data-c="1D463" xlink:href="#MJX-30-TEX-I-1D463"></use></g><g data-mml-node="mi" transform="translate(5752,0)"><use data-c="1D452" xlink:href="#MJX-30-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(6218,0)"><use data-c="1D460" xlink:href="#MJX-30-TEX-I-1D460"></use></g><g data-mml-node="mo" transform="translate(6909.2,0)"><use data-c="2B" xlink:href="#MJX-30-TEX-N-2B"></use></g><g data-mml-node="mi" transform="translate(7909.4,0)"><use data-c="1D447" xlink:href="#MJX-30-TEX-I-1D447"></use></g><g data-mml-node="mi" transform="translate(8613.4,0)"><use data-c="1D45F" xlink:href="#MJX-30-TEX-I-1D45F"></use></g><g data-mml-node="mi" transform="translate(9064.4,0)"><use data-c="1D462" xlink:href="#MJX-30-TEX-I-1D462"></use></g><g data-mml-node="mi" transform="translate(9636.4,0)"><use data-c="1D452" xlink:href="#MJX-30-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(10102.4,0)"><use data-c="1D441" xlink:href="#MJX-30-TEX-I-1D441"></use></g><g data-mml-node="mi" transform="translate(10990.4,0)"><use data-c="1D452" xlink:href="#MJX-30-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(11456.4,0)"><use data-c="1D454" xlink:href="#MJX-30-TEX-I-1D454"></use></g><g data-mml-node="mi" transform="translate(11933.4,0)"><use data-c="1D44E" xlink:href="#MJX-30-TEX-I-1D44E"></use></g><g data-mml-node="mi" transform="translate(12462.4,0)"><use data-c="1D461" xlink:href="#MJX-30-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(12823.4,0)"><use data-c="1D456" xlink:href="#MJX-30-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(13168.4,0)"><use data-c="1D463" xlink:href="#MJX-30-TEX-I-1D463"></use></g><g data-mml-node="mi" transform="translate(13653.4,0)"><use data-c="1D452" xlink:href="#MJX-30-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(14119.4,0)"><use data-c="1D460" xlink:href="#MJX-30-TEX-I-1D460"></use></g></g><rect width="14788.4" height="60" x="120" y="220"></rect></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block" alttext="StartFraction upper F a l s e upper P o s i t i v e s Over upper F a l s e upper P o s i t i v e s plus upper T r u e upper N e g a t i v e s EndFraction"><mfrac><mrow><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow><mrow><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>+</mo><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>N</mi><mi>e</mi><mi>g</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow></mfrac></math></mjx-assistive-mml></mjx-container></p></td>
        <td><p>The proportion of <em>incorrect positives</em> that are identified.
        A high score indicates more false positives.</p></td>
        </tr>
        <tr>
        <td><p>Receiver operating characteristic (ROC) curve</p></td>
        <td><p>X-Y chart</p></td>
        <td><p>ROC curve is a plot of the Recall (true positive rate) against the False Positive rate at different classification thresholds.
        The area under the curve (AUC) measures the two-dimensional area underneath the ROC curve from an X-Y axis (0,0) to (1,1).</p></td>
        </tr>
        </tbody>
        </table>
        
        <p>We’ll use accuracy, precision, recall, and ROC curves to evaluate our models. Accuracy is a coarse measure, so we’ll focus on increasing our overall precision and recall measures. We’ll use the ROC curves to compare how individual features change predictive rates.</p>
        <div data-type="tip"><h6>Tip</h6>
        <p>Depending on our goals we may want to favor different measures. For example, we may want to eliminate all false negatives for disease indicators, but we wouldn’t want to push predictions of everything into a positive result.
        There may be multiple thresholds we set for different models that pass some results through to secondary inspection on the likelihood of false results.</p>
        
        <p>Lowering classification thresholds results in more overall positive results, thus increasing both false positives and true positives.</p>
        </div>
        
        <p>Let’s use the following function to compute these predictive measures:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">evaluate_model</code><code class="p">(</code><code class="n">model</code><code class="p">,</code> <code class="n">test_data</code><code class="p">):</code>
            <code class="c1"># Execute the model against the test set</code>
            <code class="n">predictions</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">test_data</code><code class="p">)</code>
        
            <code class="c1"># Compute true positive, false positive, false negative counts</code>
            <code class="n">tp</code> <code class="o">=</code> <code class="n">predictions</code><code class="p">[(</code><code class="n">predictions</code><code class="o">.</code><code class="n">label</code> <code class="o">==</code> <code class="mi">1</code><code class="p">)</code> <code class="o">&amp;</code>
                             <code class="p">(</code><code class="n">predictions</code><code class="o">.</code><code class="n">prediction</code> <code class="o">==</code> <code class="mi">1</code><code class="p">)]</code><code class="o">.</code><code class="n">count</code><code class="p">()</code>
            <code class="n">fp</code> <code class="o">=</code> <code class="n">predictions</code><code class="p">[(</code><code class="n">predictions</code><code class="o">.</code><code class="n">label</code> <code class="o">==</code> <code class="mi">0</code><code class="p">)</code> <code class="o">&amp;</code>
                             <code class="p">(</code><code class="n">predictions</code><code class="o">.</code><code class="n">prediction</code> <code class="o">==</code> <code class="mi">1</code><code class="p">)]</code><code class="o">.</code><code class="n">count</code><code class="p">()</code>
            <code class="n">fn</code> <code class="o">=</code> <code class="n">predictions</code><code class="p">[(</code><code class="n">predictions</code><code class="o">.</code><code class="n">label</code> <code class="o">==</code> <code class="mi">1</code><code class="p">)</code> <code class="o">&amp;</code>
                             <code class="p">(</code><code class="n">predictions</code><code class="o">.</code><code class="n">prediction</code> <code class="o">==</code> <code class="mi">0</code><code class="p">)]</code><code class="o">.</code><code class="n">count</code><code class="p">()</code>
        
            <code class="c1"># Compute recall and precision manually</code>
            <code class="n">recall</code> <code class="o">=</code> <code class="nb">float</code><code class="p">(</code><code class="n">tp</code><code class="p">)</code> <code class="o">/</code> <code class="p">(</code><code class="n">tp</code> <code class="o">+</code> <code class="n">fn</code><code class="p">)</code>
            <code class="n">precision</code> <code class="o">=</code> <code class="nb">float</code><code class="p">(</code><code class="n">tp</code><code class="p">)</code> <code class="o">/</code> <code class="p">(</code><code class="n">tp</code> <code class="o">+</code> <code class="n">fp</code><code class="p">)</code>
        
            <code class="c1"># Compute accuracy using Spark MLLib's binary classification evaluator</code>
            <code class="n">accuracy</code> <code class="o">=</code> <code class="n">BinaryClassificationEvaluator</code><code class="p">()</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">predictions</code><code class="p">)</code>
        
            <code class="c1"># Compute false positive rate and true positive rate using sklearn functions</code>
            <code class="n">labels</code> <code class="o">=</code> <code class="p">[</code><code class="n">row</code><code class="p">[</code><code class="s2">"label"</code><code class="p">]</code> <code class="k">for</code> <code class="n">row</code> <code class="ow">in</code> <code class="n">predictions</code><code class="o">.</code><code class="n">select</code><code class="p">(</code><code class="s2">"label"</code><code class="p">)</code><code class="o">.</code><code class="n">collect</code><code class="p">()]</code>
            <code class="n">preds</code> <code class="o">=</code> <code class="p">[</code><code class="n">row</code><code class="p">[</code><code class="s2">"probability"</code><code class="p">][</code><code class="mi">1</code><code class="p">]</code> <code class="k">for</code> <code class="n">row</code> <code class="ow">in</code> <code class="n">predictions</code><code class="o">.</code><code class="n">select</code>
                        <code class="p">(</code><code class="s2">"probability"</code><code class="p">)</code><code class="o">.</code><code class="n">collect</code><code class="p">()]</code>
            <code class="n">fpr</code><code class="p">,</code> <code class="n">tpr</code><code class="p">,</code> <code class="n">threshold</code> <code class="o">=</code> <code class="n">roc_curve</code><code class="p">(</code><code class="n">labels</code><code class="p">,</code> <code class="n">preds</code><code class="p">)</code>
            <code class="n">roc_auc</code> <code class="o">=</code> <code class="n">auc</code><code class="p">(</code><code class="n">fpr</code><code class="p">,</code> <code class="n">tpr</code><code class="p">)</code>
        
            <code class="k">return</code> <code class="p">{</code> <code class="s2">"fpr"</code><code class="p">:</code> <code class="n">fpr</code><code class="p">,</code> <code class="s2">"tpr"</code><code class="p">:</code> <code class="n">tpr</code><code class="p">,</code> <code class="s2">"roc_auc"</code><code class="p">:</code> <code class="n">roc_auc</code><code class="p">,</code> <code class="s2">"accuracy"</code><code class="p">:</code> <code class="n">accuracy</code><code class="p">,</code>
                     <code class="s2">"recall"</code><code class="p">:</code> <code class="n">recall</code><code class="p">,</code> <code class="s2">"precision"</code><code class="p">:</code> <code class="n">precision</code> <code class="p">}</code></pre>
        
        <p>We’ll then write a function to display the results in an easier-to-consume format:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">display_results</code><code class="p">(</code><code class="n">results</code><code class="p">):</code>
            <code class="n">results</code> <code class="o">=</code> <code class="p">{</code><code class="n">k</code><code class="p">:</code> <code class="n">v</code> <code class="k">for</code> <code class="n">k</code><code class="p">,</code> <code class="n">v</code> <code class="ow">in</code> <code class="n">results</code><code class="o">.</code><code class="n">items</code><code class="p">()</code> <code class="k">if</code> <code class="n">k</code> <code class="ow">not</code> <code class="ow">in</code>
                                <code class="p">[</code><code class="s2">"fpr"</code><code class="p">,</code> <code class="s2">"tpr"</code><code class="p">,</code> <code class="s2">"roc_auc"</code><code class="p">]}</code>
            <code class="k">return</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">({</code><code class="s2">"Measure"</code><code class="p">:</code> <code class="nb">list</code><code class="p">(</code><code class="n">results</code><code class="o">.</code><code class="n">keys</code><code class="p">()),</code>
                                 <code class="s2">"Score"</code><code class="p">:</code> <code class="nb">list</code><code class="p">(</code><code class="n">results</code><code class="o">.</code><code class="n">values</code><code class="p">())})</code></pre>
        
        <p>We can call the function with this code and display the results:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">basic_results</code> <code class="o">=</code> <code class="n">evaluate_model</code><code class="p">(</code><code class="n">basic_model</code><code class="p">,</code> <code class="n">test_data</code><code class="p">)</code>
        <code class="n">display_results</code><code class="p">(</code><code class="n">basic_results</code><code class="p">)</code></pre>
        
        <p>The predictive measures for the common authors model are:</p>
        <table>
        
        <thead>
        <tr>
        <th>measure</th>
        <th>score</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>accuracy</p></td>
        <td><p>0.864457</p></td>
        </tr>
        <tr>
        <td><p>recall</p></td>
        <td><p>0.753278</p></td>
        </tr>
        <tr>
        <td><p>precision</p></td>
        <td><p>0.968670</p></td>
        </tr>
        </tbody>
        </table>
        
        <p>This is not a bad start given that we’re predicting future collaboration based only on the number of common authors in our pairs of authors. However, we get a bigger picture if we consider these measures in context with one another. For example, this model has a precision of 0.968670, which means it’s very good at predicting that <em>links exist</em>. However, our recall is 0.753278, which means it’s not good at predicting when <em>links do not exist</em>.</p>
        
        <p>We can also plot the ROC curve (correlation of true positives and False positives) using the following functions:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">create_roc_plot</code><code class="p">():</code>
            <code class="n">plt</code><code class="o">.</code><code class="n">style</code><code class="o">.</code><code class="n">use</code><code class="p">(</code><code class="s1">'classic'</code><code class="p">)</code>
            <code class="n">fig</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">figure</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">13</code><code class="p">,</code> <code class="mi">8</code><code class="p">))</code>
            <code class="n">plt</code><code class="o">.</code><code class="n">xlim</code><code class="p">([</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">])</code>
            <code class="n">plt</code><code class="o">.</code><code class="n">ylim</code><code class="p">([</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">])</code>
            <code class="n">plt</code><code class="o">.</code><code class="n">ylabel</code><code class="p">(</code><code class="s1">'True Positive Rate'</code><code class="p">)</code>
            <code class="n">plt</code><code class="o">.</code><code class="n">xlabel</code><code class="p">(</code><code class="s1">'False Positive Rate'</code><code class="p">)</code>
            <code class="n">plt</code><code class="o">.</code><code class="n">rc</code><code class="p">(</code><code class="s1">'axes'</code><code class="p">,</code> <code class="n">prop_cycle</code><code class="o">=</code><code class="p">(</code><code class="n">cycler</code><code class="p">(</code><code class="s1">'color'</code><code class="p">,</code>
                           <code class="p">[</code><code class="s1">'r'</code><code class="p">,</code> <code class="s1">'g'</code><code class="p">,</code> <code class="s1">'b'</code><code class="p">,</code> <code class="s1">'c'</code><code class="p">,</code> <code class="s1">'m'</code><code class="p">,</code> <code class="s1">'y'</code><code class="p">,</code> <code class="s1">'k'</code><code class="p">])))</code>
            <code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">([</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code> <code class="p">[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code> <code class="n">linestyle</code><code class="o">=</code><code class="s1">'--'</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="s1">'Random score</code>
                           <code class="p">(</code><code class="n">AUC</code> <code class="o">=</code> <code class="mf">0.50</code><code class="p">)</code><code class="s1">')</code>
            <code class="k">return</code> <code class="n">plt</code><code class="p">,</code> <code class="n">fig</code>
        
        
        <code class="k">def</code> <code class="nf">add_curve</code><code class="p">(</code><code class="n">plt</code><code class="p">,</code> <code class="n">title</code><code class="p">,</code> <code class="n">fpr</code><code class="p">,</code> <code class="n">tpr</code><code class="p">,</code> <code class="n">roc</code><code class="p">):</code>
            <code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">fpr</code><code class="p">,</code> <code class="n">tpr</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="n">f</code><code class="s2">"{title} (AUC = {roc:0.2})"</code><code class="p">)</code></pre>
        
        <p>We call it like this:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">plt</code><code class="p">,</code> <code class="n">fig</code> <code class="o">=</code> <code class="n">create_roc_plot</code><code class="p">()</code>
        
        <code class="n">add_curve</code><code class="p">(</code><code class="n">plt</code><code class="p">,</code> <code class="s2">"Common Authors"</code><code class="p">,</code>
                  <code class="n">basic_results</code><code class="p">[</code><code class="s2">"fpr"</code><code class="p">],</code> <code class="n">basic_results</code><code class="p">[</code><code class="s2">"tpr"</code><code class="p">],</code> <code class="n">basic_results</code><code class="p">[</code><code class="s2">"roc_auc"</code><code class="p">])</code>
        
        <code class="n">plt</code><code class="o">.</code><code class="n">legend</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="s1">'lower right'</code><code class="p">)</code>
        <code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>
        
        <p>We can see the ROC curve for our basic model in <a data-type="xref" href="#ch8-roc-basic">Figure&nbsp;8-9</a>. The common authors model gives us a 0.86 area under the curve (AUC) score.
        Although this gives us one overall predictive measure, we need the chart (or other measures) to evaluate whether this fits our goal. In <a data-type="xref" href="#ch8-roc-basic">Figure&nbsp;8-9</a> we see that as we get close to an 80% true positive rate (recall) our false positive rate reaches about 20%. That could be problematic in scenarios like fraud detection where false positives are expensive to chase.</p>
        
        <figure><div id="ch8-roc-basic" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_rr_0809.png" alt="gral rr 0809" width="1191" height="765">
        <h6><span class="label">Figure 8-9. </span>The ROC curve for basic model</h6>
        </div></figure>
        
        <p>Now let’s use the other graphy features to see if we can improve our predictions.
        Before we train our model, let’s see how the data is distributed.
        We can run the following code to show descriptive statistics for each of our graphy features:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="p">(</code><code class="n">training_data</code><code class="o">.</code><code class="n">filter</code><code class="p">(</code><code class="n">training_data</code><code class="p">[</code><code class="s2">"label"</code><code class="p">]</code><code class="o">==</code><code class="mi">1</code><code class="p">)</code>
         <code class="o">.</code><code class="n">describe</code><code class="p">()</code>
         <code class="o">.</code><code class="n">select</code><code class="p">(</code><code class="s2">"summary"</code><code class="p">,</code> <code class="s2">"commonAuthors"</code><code class="p">,</code> <code class="s2">"prefAttachment"</code><code class="p">,</code> <code class="s2">"totalNeighbors"</code><code class="p">)</code>
         <code class="o">.</code><code class="n">show</code><code class="p">())</code></pre>
        
        <pre data-type="programlisting" data-code-language="python"><code class="p">(</code><code class="n">training_data</code><code class="o">.</code><code class="n">filter</code><code class="p">(</code><code class="n">training_data</code><code class="p">[</code><code class="s2">"label"</code><code class="p">]</code><code class="o">==</code><code class="mi">0</code><code class="p">)</code>
         <code class="o">.</code><code class="n">describe</code><code class="p">()</code>
         <code class="o">.</code><code class="n">select</code><code class="p">(</code><code class="s2">"summary"</code><code class="p">,</code> <code class="s2">"commonAuthors"</code><code class="p">,</code> <code class="s2">"prefAttachment"</code><code class="p">,</code> <code class="s2">"totalNeighbors"</code><code class="p">)</code>
         <code class="o">.</code><code class="n">show</code><code class="p">())</code></pre>
        
        <p>We can see the results of running those bits of code in the following tables.</p>
        <table id="ch8-explore-graphy-features-positive">
        
        <thead>
        <tr>
        <th>summary</th>
        <th>commonAuthors</th>
        <th>prefAttachment</th>
        <th>totalNeighbors</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>count</p></td>
        <td><p>81096</p></td>
        <td><p>81096</p></td>
        <td><p>81096</p></td>
        </tr>
        <tr>
        <td><p>mean</p></td>
        <td><p>3.5959233501035808</p></td>
        <td><p>69.93537289138798</p></td>
        <td><p>10.082408503502021</p></td>
        </tr>
        <tr>
        <td><p>stddev</p></td>
        <td><p>4.715942231635516</p></td>
        <td><p>171.47092255919472</p></td>
        <td><p>8.44109970920685</p></td>
        </tr>
        <tr>
        <td><p>min</p></td>
        <td><p>0</p></td>
        <td><p>1</p></td>
        <td><p>2</p></td>
        </tr>
        <tr>
        <td><p>max</p></td>
        <td><p>44</p></td>
        <td><p>3150</p></td>
        <td><p>90</p></td>
        </tr>
        </tbody>
        </table>
        <table id="ch8-explore-graphy-features-negative">
        
        <thead>
        <tr>
        <th>summary</th>
        <th>commonAuthors</th>
        <th>prefAttachment</th>
        <th>totalNeighbors</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>count</p></td>
        <td><p>81096</p></td>
        <td><p>81096</p></td>
        <td><p>81096</p></td>
        </tr>
        <tr>
        <td><p>mean</p></td>
        <td><p>0.37666469369635985</p></td>
        <td><p>48.18137762651672</p></td>
        <td><p>12.97586810693499</p></td>
        </tr>
        <tr>
        <td><p>stddev</p></td>
        <td><p>0.6194576095461857</p></td>
        <td><p>94.92635344980489</p></td>
        <td><p>10.082991078685803</p></td>
        </tr>
        <tr>
        <td><p>min</p></td>
        <td><p>0</p></td>
        <td><p>1</p></td>
        <td><p>1</p></td>
        </tr>
        <tr>
        <td><p>max</p></td>
        <td><p>9</p></td>
        <td><p>1849</p></td>
        <td><p>89</p></td>
        </tr>
        </tbody>
        </table>
        
        <p>Features with larger differences between links (coauthorship) and no link (no coauthorship) should be more predictive because the divide is greater. The average value for <code>prefAttachment</code> is higher for authors who have collaborated versus those who haven’t. That difference is even more substantial for <code>commonAuthors</code>.
        We notice that there isn’t much difference in the values for <code>totalNeighbors</code>, which probably means this feature won’t be very predictive. Also interesting is the large standard deviation as well as the minimum and maximum values for preferential attachment. This is what we might expect for small-world networks with concentrated hubs (superconnectors).</p>
        
        <p>Now let’s train a new model, adding preferential attachment and total union of neighbors, by running the following code:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">fields</code> <code class="o">=</code> <code class="p">[</code><code class="s2">"commonAuthors"</code><code class="p">,</code> <code class="s2">"prefAttachment"</code><code class="p">,</code> <code class="s2">"totalNeighbors"</code><code class="p">]</code>
        <code class="n">graphy_model</code> <code class="o">=</code> <code class="n">train_model</code><code class="p">(</code><code class="n">fields</code><code class="p">,</code> <code class="n">training_data</code><code class="p">)</code></pre>
        
        <p>And now let’s evaluate the model and display the results:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">graphy_results</code> <code class="o">=</code> <code class="n">evaluate_model</code><code class="p">(</code><code class="n">graphy_model</code><code class="p">,</code> <code class="n">test_data</code><code class="p">)</code>
        <code class="n">display_results</code><code class="p">(</code><code class="n">graphy_results</code><code class="p">)</code></pre>
        
        <p>The predictive measures for the graphy model are:</p>
        <table>
        
        <thead>
        <tr>
        <th>measure</th>
        <th>score</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>accuracy</p></td>
        <td><p>0.978351</p></td>
        </tr>
        <tr>
        <td><p>recall</p></td>
        <td><p>0.924226</p></td>
        </tr>
        <tr>
        <td><p>precision</p></td>
        <td><p>0.943795</p></td>
        </tr>
        </tbody>
        </table>
        
        <p>Our accuracy and recall have increased substantially, but the precision has dropped a bit and we’re still misclassifying about 8% of the links. Let’s plot the ROC curve and compare our basic and graphy models by running the following code:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">plt</code><code class="p">,</code> <code class="n">fig</code> <code class="o">=</code> <code class="n">create_roc_plot</code><code class="p">()</code>
        
        <code class="n">add_curve</code><code class="p">(</code><code class="n">plt</code><code class="p">,</code> <code class="s2">"Common Authors"</code><code class="p">,</code>
                  <code class="n">basic_results</code><code class="p">[</code><code class="s2">"fpr"</code><code class="p">],</code> <code class="n">basic_results</code><code class="p">[</code><code class="s2">"tpr"</code><code class="p">],</code>
                                        <code class="n">basic_results</code><code class="p">[</code><code class="s2">"roc_auc"</code><code class="p">])</code>
        
        <code class="n">add_curve</code><code class="p">(</code><code class="n">plt</code><code class="p">,</code> <code class="s2">"Graphy"</code><code class="p">,</code>
                  <code class="n">graphy_results</code><code class="p">[</code><code class="s2">"fpr"</code><code class="p">],</code> <code class="n">graphy_results</code><code class="p">[</code><code class="s2">"tpr"</code><code class="p">],</code>
                                         <code class="n">graphy_results</code><code class="p">[</code><code class="s2">"roc_auc"</code><code class="p">])</code>
        
        <code class="n">plt</code><code class="o">.</code><code class="n">legend</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="s1">'lower right'</code><code class="p">)</code>
        <code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>
        
        <p>We can see the output in <a data-type="xref" href="#ch8-roc-graphy">Figure&nbsp;8-10</a>.</p>
        
        <figure><div id="ch8-roc-graphy" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_rr_0810.png" alt="gral rr 0810" width="1191" height="765">
        <h6><span class="label">Figure 8-10. </span>The ROC curve for the graphy model</h6>
        </div></figure>
        
        <p>Overall it looks like we’re headed in the right direction and it’s helpful to visualize comparisons to get a feel for how different models impact our results.</p>
        
        <p><a data-type="indexterm" data-primary="feature importance" id="idm46681355574968"></a>Now that we have more than one feature, we want to evaluate which features are making the most difference. We’ll use <em>feature importance</em> to rank the impact of different features to our model’s prediction. This enables us to evaluate the influence on results that different algorithms and statistics have.</p>
        <div data-type="note" epub:type="note"><h6>Note</h6>
        <p><a data-type="indexterm" data-primary="impurity" id="idm46681355572552"></a>To compute feature importance, the random forest algorithm in Spark averages the reduction in impurity across all trees in the forest. The <em>impurity</em> is the frequency at which randomly assigned labels are incorrect.</p>
        
        <p>Feature rankings are in comparison to the group of features we’re evaluating, always normalized to 1.
        If we rank one feature, its feature importance is 1.0 as it has 100% of the influence on the model.</p>
        </div>
        
        <p class="pagebreak-before">The following function creates a chart showing the most influential features:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">plot_feature_importance</code><code class="p">(</code><code class="n">fields</code><code class="p">,</code> <code class="n">feature_importances</code><code class="p">):</code>
            <code class="n">df</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">({</code><code class="s2">"Feature"</code><code class="p">:</code> <code class="n">fields</code><code class="p">,</code> <code class="s2">"Importance"</code><code class="p">:</code> <code class="n">feature_importances</code><code class="p">})</code>
            <code class="n">df</code> <code class="o">=</code> <code class="n">df</code><code class="o">.</code><code class="n">sort_values</code><code class="p">(</code><code class="s2">"Importance"</code><code class="p">,</code> <code class="n">ascending</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code>
            <code class="n">ax</code> <code class="o">=</code> <code class="n">df</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">kind</code><code class="o">=</code><code class="s1">'bar'</code><code class="p">,</code> <code class="n">x</code><code class="o">=</code><code class="s1">'Feature'</code><code class="p">,</code> <code class="n">y</code><code class="o">=</code><code class="s1">'Importance'</code><code class="p">,</code> <code class="n">legend</code><code class="o">=</code><code class="bp">None</code><code class="p">)</code>
            <code class="n">ax</code><code class="o">.</code><code class="n">xaxis</code><code class="o">.</code><code class="n">set_label_text</code><code class="p">(</code><code class="s2">""</code><code class="p">)</code>
            <code class="n">plt</code><code class="o">.</code><code class="n">tight_layout</code><code class="p">()</code>
            <code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>
        
        <p>And we call it like this:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">rf_model</code> <code class="o">=</code> <code class="n">graphy_model</code><code class="o">.</code><code class="n">stages</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code>
        <code class="n">plot_feature_importance</code><code class="p">(</code><code class="n">fields</code><code class="p">,</code> <code class="n">rf_model</code><code class="o">.</code><code class="n">featureImportances</code><code class="p">)</code></pre>
        
        <p>The results of running that function can be seen in <a data-type="xref" href="#ch8-feature-importance-graphy">Figure&nbsp;8-11</a>.</p>
        
        <figure><div id="ch8-feature-importance-graphy" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_rr_0811.png" alt="gral rr 0811" width="1360" height="1004">
        <h6><span class="label">Figure 8-11. </span>Feature importance: graphy model</h6>
        </div></figure>
        
        <p>Of the three features we’ve used so far, <code>commonAuthors</code> is the most important feature by a large margin.</p>
        
        <p>To understand how our predictive models are created, we can visualize one of the decision trees in our random forest using the <a href="https://bit.ly/2usxOf2">spark-tree-plotting library</a>.
        The following code generates a <a href="http://www.graphviz.org">GraphViz file</a>:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">spark_tree_plotting</code> <code class="kn">import</code> <code class="n">export_graphviz</code>
        
        <code class="n">dot_string</code> <code class="o">=</code> <code class="n">export_graphviz</code><code class="p">(</code><code class="n">rf_model</code><code class="o">.</code><code class="n">trees</code><code class="p">[</code><code class="mi">0</code><code class="p">],</code>
            <code class="n">featureNames</code><code class="o">=</code><code class="n">fields</code><code class="p">,</code> <code class="n">categoryNames</code><code class="o">=</code><code class="p">[],</code> <code class="n">classNames</code><code class="o">=</code><code class="p">[</code><code class="s2">"True"</code><code class="p">,</code> <code class="s2">"False"</code><code class="p">],</code>
            <code class="n">filled</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code> <code class="n">roundedCorners</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code> <code class="n">roundLeaves</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
        
        <code class="k">with</code> <code class="nb">open</code><code class="p">(</code><code class="s2">"/tmp/rf.dot"</code><code class="p">,</code> <code class="s2">"w"</code><code class="p">)</code> <code class="k">as</code> <code class="nb">file</code><code class="p">:</code>
            <code class="nb">file</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="n">dot_string</code><code class="p">)</code></pre>
        
        <p>We can then generate a visual representation of that file by running the following command from the terminal:</p>
        
        <pre data-type="programlisting" data-code-language="bash">dot -Tpdf /tmp/rf.dot -o /tmp/rf.pdf</pre>
        
        <p>The output of that command can be seen in <a data-type="xref" href="#ch8-visualize-decision-tree">Figure&nbsp;8-12</a>.</p>
        
        <figure><div id="ch8-visualize-decision-tree" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_rr_0812.png" alt="gral rr 0812" width="1424" height="802">
        <h6><span class="label">Figure 8-12. </span>Visualizing a decision tree</h6>
        </div></figure>
        
        <p>Imagine that we’re using this decision tree to predict whether a pair of nodes with the following features are linked:</p>
        <table>
        
        <thead>
        <tr>
        <th>commonAuthors</th>
        <th>prefAttachment</th>
        <th>totalNeighbors</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>10</p></td>
        <td><p>12</p></td>
        <td><p>5</p></td>
        </tr>
        </tbody>
        </table>
        
        <p><a data-type="indexterm" data-primary="random forest" id="idm46681355276856"></a>Our random forest walks through several steps to create a prediction:</p>
        <ol>
        <li>
        <p>We start from <code>node 0</code>, where we have more than 1.5 <code>commonAuthors</code>, so we follow the <code>False</code> branch down to <code>node 2</code>.</p>
        </li>
        <li>
        <p>We have more than 2.5 <code>commonAuthors</code> here, so we follow the <code>False</code> branch to <code>node 6</code>.</p>
        </li>
        <li>
        <p>We have a score of less than 15.5 for <code>prefAttachment</code>, which takes us to <code>node 9</code>.</p>
        </li>
        <li>
        <p>Node 9 is a leaf node in this decision tree, which means that we don’t have to check any more conditions—the value of <code>Prediction</code> (i.e., <code>True</code>) on this node is the decision tree’s prediction.</p>
        </li>
        <li>
        <p>Finally, the random forest evaluates the item being predicted against a collection of these decision trees and makes its prediction based on the most popular outcome.<a data-type="indexterm" data-startref="ix_ch8_worked_example-adoc6" id="idm46681355311048"></a></p>
        </li>
        
        </ol>
        
        <p>Now let’s look at adding more graph features.</p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Predicting Links: Triangles and the Clustering Coefficient"><div class="sect2" id="idm46681357295944">
        <h2>Predicting Links: Triangles and the Clustering Coefficient</h2>
        
        <p><a data-type="indexterm" data-primary="link prediction" data-secondary="Triangles and Clustering Coefficient" id="ix_ch8_worked_example-adoc7"></a><a data-type="indexterm" data-primary="Triangle Count and Clustering Coefficient algorithms" data-secondary="for link prediction (machine learning example)" id="ix_ch8_worked_example-adoc8"></a>Recommendation solutions often base predictions on some form of triangle metric, so let’s see if they further help with our example.
        We can compute the number of triangles that a node is a part of by running the following query:</p>
        
        <pre data-type="programlisting" data-code-language="cypher"><code class="n">CALL gds.triangleCount.write({</code>
        <code class="n">  nodeProjection: </code><code class="s1">'Author'</code><code class="n">,</code>
        <code class="n">  relationshipProjection: {</code>
        <code class="n">    CO_AUTHOR_EARLY: {</code>
        <code class="n">      </code><code class="nf">type</code><code class="n">: </code><code class="s1">'CO_AUTHOR_EARLY'</code><code class="n">,</code>
        <code class="n">      orientation: </code><code class="s1">'UNDIRECTED'</code><code class="n"></code>
        <code class="n">    }</code>
        <code class="n">  },</code>
        <code class="n">  writeProperty: </code><code class="s1">'trianglesTrain'</code><code class="n"></code>
        <code class="n">});</code>
        
        <code class="n">CALL gds.triangleCount.write({</code>
        <code class="n">  nodeProjection: </code><code class="s1">'Author'</code><code class="n">,</code>
        <code class="n">  relationshipProjection: {</code>
        <code class="n">    CO_AUTHOR: {</code>
        <code class="n">      </code><code class="nf">type</code><code class="n">: </code><code class="s1">'CO_AUTHOR'</code><code class="n">,</code>
        <code class="n">      orientation: </code><code class="s1">'UNDIRECTED'</code><code class="n"></code>
        <code class="n">    }</code>
        <code class="n">  },</code>
        <code class="n">  writeProperty: </code><code class="s1">'trianglesTest'</code><code class="n"></code>
        <code class="n">});</code></pre>
        
        <p>And its clustering coefficient by running the following query:</p>
        
        <pre data-type="programlisting" data-code-language="cypher"><code class="n">CALL gds.localClusteringCoefficient.write({</code>
        <code class="n">  nodeProjection: </code><code class="s1">'Author'</code><code class="n">,</code>
        <code class="n">  relationshipProjection: {</code>
        <code class="n">    CO_AUTHOR_EARLY: {</code>
        <code class="n">      </code><code class="nf">type</code><code class="n">: </code><code class="s1">'CO_AUTHOR_EARLY'</code><code class="n">,</code>
        <code class="n">      orientation: </code><code class="s1">'UNDIRECTED'</code><code class="n"></code>
        <code class="n">    }</code>
        <code class="n">  },</code>
        <code class="n">  writeProperty: </code><code class="s1">'coefficientTrain'</code><code class="n"></code>
        <code class="n">});</code>
        
        <code class="n">CALL gds.localClusteringCoefficient.write({</code>
        <code class="n">  nodeProjection: </code><code class="s1">'Author'</code><code class="n">,</code>
        <code class="n">  relationshipProjection: {</code>
        <code class="n">    CO_AUTHOR: {</code>
        <code class="n">      </code><code class="nf">type</code><code class="n">: </code><code class="s1">'CO_AUTHOR'</code><code class="n">,</code>
        <code class="n">      orientation: </code><code class="s1">'UNDIRECTED'</code><code class="n"></code>
        <code class="n">    }</code>
        <code class="n">  },</code>
        <code class="n">  writeProperty: </code><code class="s1">'coefficientTest'</code><code class="n"></code>
        <code class="n">});</code></pre>
        
        <p>The following function will add these features to our DataFrames:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">apply_triangles_features</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="n">triangles_prop</code><code class="p">,</code> <code class="n">coefficient_prop</code><code class="p">):</code>
            <code class="n">query</code> <code class="o">=</code> <code class="s2">"""</code>
        <code class="s2">    UNWIND $pairs AS pair</code>
        <code class="s2">    MATCH (p1) WHERE id(p1) = pair.node1</code>
        <code class="s2">    MATCH (p2) WHERE id(p2) = pair.node2</code>
        <code class="s2">    RETURN pair.node1 AS node1,</code>
        <code class="s2">           pair.node2 AS node2,</code>
        <code class="s2">           apoc.coll.min([p1[$trianglesProp], p2[$trianglesProp]])</code>
        <code class="s2">                                              AS minTriangles,</code>
        <code class="s2">           apoc.coll.max([p1[$trianglesProp], p2[$trianglesProp]])</code>
        <code class="s2">                                              AS maxTriangles,</code>
        <code class="s2">           apoc.coll.min([p1[$coefficientProp], p2[$coefficientProp]])</code>
        <code class="s2">                                                AS minCoefficient,</code>
        <code class="s2">           apoc.coll.max([p1[$coefficientProp], p2[$coefficientProp]])</code>
        <code class="s2">                                                AS maxCoefficient</code>
        <code class="s2">    """</code>
            <code class="n">params</code> <code class="o">=</code> <code class="p">{</code>
                <code class="s2">"pairs"</code><code class="p">:</code> <code class="p">[{</code><code class="s2">"node1"</code><code class="p">:</code> <code class="n">row</code><code class="p">[</code><code class="s2">"node1"</code><code class="p">],</code> <code class="s2">"node2"</code><code class="p">:</code> <code class="n">row</code><code class="p">[</code><code class="s2">"node2"</code><code class="p">]}</code>
                                    <code class="k">for</code> <code class="n">row</code> <code class="ow">in</code> <code class="n">data</code><code class="o">.</code><code class="n">collect</code><code class="p">()],</code>
                <code class="s2">"trianglesProp"</code><code class="p">:</code> <code class="n">triangles_prop</code><code class="p">,</code>
                <code class="s2">"coefficientProp"</code><code class="p">:</code> <code class="n">coefficient_prop</code>
            <code class="p">}</code>
            <code class="n">features</code> <code class="o">=</code> <code class="n">spark</code><code class="o">.</code><code class="n">createDataFrame</code><code class="p">(</code><code class="n">graph</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">query</code><code class="p">,</code> <code class="n">params</code><code class="p">)</code><code class="o">.</code><code class="n">to_data_frame</code><code class="p">())</code>
            <code class="k">return</code> <code class="n">data</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="n">features</code><code class="p">,</code> <code class="p">[</code><code class="s2">"node1"</code><code class="p">,</code> <code class="s2">"node2"</code><code class="p">])</code></pre>
        <div data-type="note" epub:type="note"><h6>Note</h6>
        <p>Notice that we’ve used min and max prefixes for our triangle count and clustering coefficient algorithms.
        We need a way to prevent our model from learning based on the order authors in pairs are passed in from our undirected graph.
        To do this, we’ve split these features by the authors with minimum and maximum counts.</p>
        </div>
        
        <p>We can apply this function to our training and test DataFrames with the following code:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">training_data</code> <code class="o">=</code> <code class="n">apply_triangles_features</code><code class="p">(</code><code class="n">training_data</code><code class="p">,</code>
                                                <code class="s2">"trianglesTrain"</code><code class="p">,</code> <code class="s2">"coefficientTrain"</code><code class="p">)</code>
        <code class="n">test_data</code> <code class="o">=</code> <code class="n">apply_triangles_features</code><code class="p">(</code><code class="n">test_data</code><code class="p">,</code>
                                                <code class="s2">"trianglesTest"</code><code class="p">,</code> <code class="s2">"coefficientTest"</code><code class="p">)</code></pre>
        
        <p>And run this code to show descriptive statistics for each of our triangle features:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="p">(</code><code class="n">training_data</code><code class="o">.</code><code class="n">filter</code><code class="p">(</code><code class="n">training_data</code><code class="p">[</code><code class="s2">"label"</code><code class="p">]</code><code class="o">==</code><code class="mi">1</code><code class="p">)</code>
         <code class="o">.</code><code class="n">describe</code><code class="p">()</code>
         <code class="o">.</code><code class="n">select</code><code class="p">(</code><code class="s2">"summary"</code><code class="p">,</code> <code class="s2">"minTriangles"</code><code class="p">,</code> <code class="s2">"maxTriangles"</code><code class="p">,</code>
                            <code class="s2">"minCoefficient"</code><code class="p">,</code> <code class="s2">"maxCoefficient"</code><code class="p">)</code>
         <code class="o">.</code><code class="n">show</code><code class="p">())</code></pre>
        
        <pre data-type="programlisting" data-code-language="python"><code class="p">(</code><code class="n">training_data</code><code class="o">.</code><code class="n">filter</code><code class="p">(</code><code class="n">training_data</code><code class="p">[</code><code class="s2">"label"</code><code class="p">]</code><code class="o">==</code><code class="mi">0</code><code class="p">)</code>
         <code class="o">.</code><code class="n">describe</code><code class="p">()</code>
         <code class="o">.</code><code class="n">select</code><code class="p">(</code><code class="s2">"summary"</code><code class="p">,</code> <code class="s2">"minTriangles"</code><code class="p">,</code> <code class="s2">"maxTriangles"</code><code class="p">,</code> <code class="s2">"minCoefficient"</code><code class="p">,</code>
                                                            <code class="s2">"maxCoefficient"</code><code class="p">)</code>
         <code class="o">.</code><code class="n">show</code><code class="p">())</code></pre>
        
        <p>We can see the results of running those bits of code in the following tables.</p>
        <table id="ch8-explore-triangles-features-positive">
        
        <thead>
        <tr>
        <th>summary</th>
        <th>minTriangles</th>
        <th>maxTriangles</th>
        <th>minCoefficient</th>
        <th>maxCoefficient</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>count</p></td>
        <td><p>81096</p></td>
        <td><p>81096</p></td>
        <td><p>81096</p></td>
        <td><p>81096</p></td>
        </tr>
        <tr>
        <td><p>mean</p></td>
        <td><p>19.478260333431983</p></td>
        <td><p>27.73590559337082</p></td>
        <td><p>0.5703773654487051</p></td>
        <td><p>0.8453786164620439</p></td>
        </tr>
        <tr>
        <td><p>stddev</p></td>
        <td><p>65.7615282768483</p></td>
        <td><p>74.01896188921927</p></td>
        <td><p>0.3614610553659958</p></td>
        <td><p>0.2939681857356519</p></td>
        </tr>
        <tr>
        <td><p>min</p></td>
        <td><p>0</p></td>
        <td><p>0</p></td>
        <td><p>0.0</p></td>
        <td><p>0.0</p></td>
        </tr>
        <tr>
        <td><p>max</p></td>
        <td><p>622</p></td>
        <td><p>785</p></td>
        <td><p>1.0</p></td>
        <td><p>1.0</p></td>
        </tr>
        </tbody>
        </table>
        <table id="ch8-explore-triangles-features-negative">
        
        <thead>
        <tr>
        <th>summary</th>
        <th>minTriangles</th>
        <th>maxTriangles</th>
        <th>minCoefficient</th>
        <th>maxCoefficient</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>count</p></td>
        <td><p>81096</p></td>
        <td><p>81096</p></td>
        <td><p>81096</p></td>
        <td><p>81096</p></td>
        </tr>
        <tr>
        <td><p>mean</p></td>
        <td><p>5.754661142349808</p></td>
        <td><p>35.651980368945445</p></td>
        <td><p>0.49048921333297446</p></td>
        <td><p>0.860283935358397</p></td>
        </tr>
        <tr>
        <td><p>stddev</p></td>
        <td><p>20.639236521699</p></td>
        <td><p>85.82843448272624</p></td>
        <td><p>0.3684138346533951</p></td>
        <td><p>0.2578219623967906</p></td>
        </tr>
        <tr>
        <td><p>min</p></td>
        <td><p>0</p></td>
        <td><p>0</p></td>
        <td><p>0.0</p></td>
        <td><p>0.0</p></td>
        </tr>
        <tr>
        <td><p>max</p></td>
        <td><p>617</p></td>
        <td><p>785</p></td>
        <td><p>1.0</p></td>
        <td><p>1.0</p></td>
        </tr>
        </tbody>
        </table>
        
        <p>Notice in this comparison that there isn’t as great a difference between the coauthorship and no-coauthorship data. This could mean that these features aren’t as predictive. We can train another model by running the following code:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">fields</code> <code class="o">=</code> <code class="p">[</code><code class="s2">"commonAuthors"</code><code class="p">,</code> <code class="s2">"prefAttachment"</code><code class="p">,</code> <code class="s2">"totalNeighbors"</code><code class="p">,</code>
                  <code class="s2">"minTriangles"</code><code class="p">,</code> <code class="s2">"maxTriangles"</code><code class="p">,</code> <code class="s2">"minCoefficient"</code><code class="p">,</code> <code class="s2">"maxCoefficient"</code><code class="p">]</code>
        <code class="n">triangle_model</code> <code class="o">=</code> <code class="n">train_model</code><code class="p">(</code><code class="n">fields</code><code class="p">,</code> <code class="n">training_data</code><code class="p">)</code></pre>
        
        <p class="less_space pagebreak-before">And now let’s evaluate the model and display the results:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">triangle_results</code> <code class="o">=</code> <code class="n">evaluate_model</code><code class="p">(</code><code class="n">triangle_model</code><code class="p">,</code> <code class="n">test_data</code><code class="p">)</code>
        <code class="n">display_results</code><code class="p">(</code><code class="n">triangle_results</code><code class="p">)</code></pre>
        
        <p>The predictive measures for the triangles model are shown in this table:</p>
        <table>
        
        <thead>
        <tr>
        <th>measure</th>
        <th>score</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>accuracy</p></td>
        <td><p>0.992924</p></td>
        </tr>
        <tr>
        <td><p>recall</p></td>
        <td><p>0.965384</p></td>
        </tr>
        <tr>
        <td><p>precision</p></td>
        <td><p>0.958582</p></td>
        </tr>
        </tbody>
        </table>
        
        <p>Our predictive measures have increased well by adding each new feature to the previous model. Let’s add our triangles model to our ROC curve chart with the following code:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">plt</code><code class="p">,</code> <code class="n">fig</code> <code class="o">=</code> <code class="n">create_roc_plot</code><code class="p">()</code>
        
        <code class="n">add_curve</code><code class="p">(</code><code class="n">plt</code><code class="p">,</code> <code class="s2">"Common Authors"</code><code class="p">,</code>
                  <code class="n">basic_results</code><code class="p">[</code><code class="s2">"fpr"</code><code class="p">],</code> <code class="n">basic_results</code><code class="p">[</code><code class="s2">"tpr"</code><code class="p">],</code> <code class="n">basic_results</code><code class="p">[</code><code class="s2">"roc_auc"</code><code class="p">])</code>
        
        <code class="n">add_curve</code><code class="p">(</code><code class="n">plt</code><code class="p">,</code> <code class="s2">"Graphy"</code><code class="p">,</code>
                  <code class="n">graphy_results</code><code class="p">[</code><code class="s2">"fpr"</code><code class="p">],</code> <code class="n">graphy_results</code><code class="p">[</code><code class="s2">"tpr"</code><code class="p">],</code>
                                         <code class="n">graphy_results</code><code class="p">[</code><code class="s2">"roc_auc"</code><code class="p">])</code>
        
        <code class="n">add_curve</code><code class="p">(</code><code class="n">plt</code><code class="p">,</code> <code class="s2">"Triangles"</code><code class="p">,</code>
                  <code class="n">triangle_results</code><code class="p">[</code><code class="s2">"fpr"</code><code class="p">],</code> <code class="n">triangle_results</code><code class="p">[</code><code class="s2">"tpr"</code><code class="p">],</code>
                                           <code class="n">triangle_results</code><code class="p">[</code><code class="s2">"roc_auc"</code><code class="p">])</code>
        
        <code class="n">plt</code><code class="o">.</code><code class="n">legend</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="s1">'lower right'</code><code class="p">)</code>
        <code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>
        
        <p>We can see the output in <a data-type="xref" href="#ch8-roc-triangles">Figure&nbsp;8-13</a>.</p>
        
        <figure><div id="ch8-roc-triangles" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_rr_0813.png" alt="gral rr 0813" width="1191" height="765">
        <h6><span class="label">Figure 8-13. </span>The ROC curve for triangles model</h6>
        </div></figure>
        
        <p>Our models have generally improved, and we’re in the high 90s for  predictive measures. This is when things usually get difficult, because the easiest gains are made but there’s still room for improvement. Let’s see how the important features have changed:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">rf_model</code> <code class="o">=</code> <code class="n">triangle_model</code><code class="o">.</code><code class="n">stages</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code>
        <code class="n">plot_feature_importance</code><code class="p">(</code><code class="n">fields</code><code class="p">,</code> <code class="n">rf_model</code><code class="o">.</code><code class="n">featureImportances</code><code class="p">)</code></pre>
        
        <p>The results of running that function can be seen in <a data-type="xref" href="#ch8-feature-importance-triangles">Figure&nbsp;8-14</a>. The <code>common authors</code> feature still has the greatest single impact on our model. Perhaps we need to look at new areas and see what happens when we add community information.<a data-type="indexterm" data-startref="ix_ch8_worked_example-adoc8" id="idm46681354591848"></a><a data-type="indexterm" data-startref="ix_ch8_worked_example-adoc7" id="idm46681354591240"></a></p>
        
        <figure><div id="ch8-feature-importance-triangles" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_rr_0814.png" alt="gral rr 0814" width="1360" height="1004">
        <h6><span class="label">Figure 8-14. </span>Feature importance: triangles model</h6>
        </div></figure>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect2" data-pdf-bookmark="Predicting Links: Community Detection"><div class="sect2" id="idm46681357295000">
        <h2>Predicting Links: Community Detection</h2>
        
        <p><a data-type="indexterm" data-primary="community detection algorithms" data-secondary="for link prediction" id="ix_ch8_worked_example-adoc9"></a><a data-type="indexterm" data-primary="link prediction" data-secondary="community detection" id="ix_ch8_worked_example-adoc10"></a>We hypothesize that nodes that are in the same community are more likely to have a link between them if they don’t already. Moreover, we believe that the tighter a community is, the more likely links are.</p>
        
        <p>First, we’ll compute more coarse-grained communities using the Label Propagation algorithm in Neo4j.
        We do this by running the following query, which will store the community in the property <code>partitionTrain</code> for the training set and <code>partitionTest</code> for the test set:</p>
        
        <pre data-type="programlisting" data-code-language="cypher"><code class="n">CALL gds.labelPropagation.write({</code>
        <code class="n">  nodeProjection: </code><code class="s2">"Author"</code><code class="n">,</code>
        <code class="n">  relationshipProjection: {</code>
        <code class="n">    CO_AUTHOR_EARLY: {</code>
        <code class="n">      </code><code class="nf">type</code><code class="n">: </code><code class="s1">'CO_AUTHOR_EARLY'</code><code class="n">,</code>
        <code class="n">      orientation: </code><code class="s1">'UNDIRECTED'</code><code class="n"></code>
        <code class="n">    }</code>
        <code class="n">  },</code>
        <code class="n">  writeProperty: </code><code class="s2">"partitionTrain"</code><code class="n"></code>
        <code class="n">});</code>
        
        <code class="n">CALL gds.labelPropagation.write({</code>
        <code class="n">  nodeProjection: </code><code class="s2">"Author"</code><code class="n">,</code>
        <code class="n">  relationshipProjection: {</code>
        <code class="n">    CO_AUTHOR: {</code>
        <code class="n">      </code><code class="nf">type</code><code class="n">: </code><code class="s1">'CO_AUTHOR'</code><code class="n">,</code>
        <code class="n">      orientation: </code><code class="s1">'UNDIRECTED'</code><code class="n"></code>
        <code class="n">    }</code>
        <code class="n">  },</code>
        <code class="n">  writeProperty: </code><code class="s2">"partitionTest"</code><code class="n"></code>
        <code class="n">});</code></pre>
        
        <p><a data-type="indexterm" data-primary="Louvain Modularity algorithm" data-secondary="for link prediction" id="ix_ch8_worked_example-adoc11"></a>We’ll also compute finer-grained groups using the Louvain algorithm.
        The Louvain algorithm returns intermediate clusters, and we’ll store the smallest of these clusters in the property <code>louvainTrain</code> for the training set and <code>louvainTest</code> for the test set:</p>
        
        <pre data-type="programlisting" data-code-language="cypher"><code class="n">CALL gds.louvain.stream({</code>
        <code class="n">  nodeProjection: </code><code class="s1">'Author'</code><code class="n">,</code>
        <code class="n">  relationshipProjection: {</code>
        <code class="n">    CO_AUTHOR_EARLY: {</code>
        <code class="n">      </code><code class="nf">type</code><code class="n">: </code><code class="s1">'CO_AUTHOR_EARLY'</code><code class="n">,</code>
        <code class="n">      orientation: </code><code class="s1">'UNDIRECTED'</code><code class="n"></code>
        <code class="n">    }</code>
        <code class="n">  },</code>
        <code class="n">  includeIntermediateCommunities: </code><code class="no">true</code><code class="n"></code>
        <code class="n">})</code>
        <code class="n">YIELD nodeId, communityId, intermediateCommunityIds</code>
        <code class="k">WITH </code><code class="n">gds.util.asNode(nodeId) </code><code class="k">AS node</code><code class="n">,</code>
        <code class="n">     intermediateCommunityIds[0] </code><code class="k">AS </code><code class="n">smallestCommunity</code>
        <code class="k">SET node</code><code class="n">.louvainTrain = smallestCommunity;</code>
        
        <code class="n">CALL gds.louvain.stream({</code>
        <code class="n">  nodeProjection: </code><code class="s1">'Author'</code><code class="n">,</code>
        <code class="n">  relationshipProjection: {</code>
        <code class="n">    CO_AUTHOR: {</code>
        <code class="n">      </code><code class="nf">type</code><code class="n">: </code><code class="s1">'CO_AUTHOR'</code><code class="n">,</code>
        <code class="n">      orientation: </code><code class="s1">'UNDIRECTED'</code><code class="n"></code>
        <code class="n">    }</code>
        <code class="n">  },</code>
        <code class="n">  includeIntermediateCommunities: </code><code class="no">true</code><code class="n"></code>
        <code class="n">})</code>
        <code class="n">YIELD nodeId, communityId, intermediateCommunityIds</code>
        <code class="k">WITH </code><code class="n">gds.util.asNode(nodeId) </code><code class="k">AS node</code><code class="n">,</code>
        <code class="n">     intermediateCommunityIds[0] </code><code class="k">AS </code><code class="n">smallestCommunity</code>
        <code class="k">SET node</code><code class="n">.louvainTest = smallestCommunity;</code></pre>
        
        <p>We’ll now create the following function to return the values from these algorithms:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">apply_community_features</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="n">partition_prop</code><code class="p">,</code> <code class="n">louvain_prop</code><code class="p">):</code>
            <code class="n">query</code> <code class="o">=</code> <code class="s2">"""</code>
        <code class="s2">    UNWIND $pairs AS pair</code>
        <code class="s2">    MATCH (p1) WHERE id(p1) = pair.node1</code>
        <code class="s2">    MATCH (p2) WHERE id(p2) = pair.node2</code>
        <code class="s2">    RETURN pair.node1 AS node1,</code>
        <code class="s2">           pair.node2 AS node2,</code>
        <code class="s2">           CASE WHEN p1[$partitionProp] = p2[$partitionProp] THEN</code>
        <code class="s2">                     1 ELSE 0 END AS samePartition,</code>
        <code class="s2">           CASE WHEN p1[$louvainProp] = p2[$louvainProp] THEN</code>
        <code class="s2">                     1 ELSE 0 END AS sameLouvain</code>
        <code class="s2">    """</code>
            <code class="n">params</code> <code class="o">=</code> <code class="p">{</code>
                <code class="s2">"pairs"</code><code class="p">:</code> <code class="p">[{</code><code class="s2">"node1"</code><code class="p">:</code> <code class="n">row</code><code class="p">[</code><code class="s2">"node1"</code><code class="p">],</code> <code class="s2">"node2"</code><code class="p">:</code> <code class="n">row</code><code class="p">[</code><code class="s2">"node2"</code><code class="p">]}</code> <code class="k">for</code>
                                    <code class="n">row</code> <code class="ow">in</code> <code class="n">data</code><code class="o">.</code><code class="n">collect</code><code class="p">()],</code>
                <code class="s2">"partitionProp"</code><code class="p">:</code> <code class="n">partition_prop</code><code class="p">,</code>
                <code class="s2">"louvainProp"</code><code class="p">:</code> <code class="n">louvain_prop</code>
            <code class="p">}</code>
            <code class="n">features</code> <code class="o">=</code> <code class="n">spark</code><code class="o">.</code><code class="n">createDataFrame</code><code class="p">(</code><code class="n">graph</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">query</code><code class="p">,</code> <code class="n">params</code><code class="p">)</code><code class="o">.</code><code class="n">to_data_frame</code><code class="p">())</code>
            <code class="k">return</code> <code class="n">data</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="n">features</code><code class="p">,</code> <code class="p">[</code><code class="s2">"node1"</code><code class="p">,</code> <code class="s2">"node2"</code><code class="p">])</code></pre>
        
        <p>We can apply this function to our training and test DataFrames in Spark with the following code:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">training_data</code> <code class="o">=</code> <code class="n">apply_community_features</code><code class="p">(</code><code class="n">training_data</code><code class="p">,</code>
                                                <code class="s2">"partitionTrain"</code><code class="p">,</code> <code class="s2">"louvainTrain"</code><code class="p">)</code>
        <code class="n">test_data</code> <code class="o">=</code> <code class="n">apply_community_features</code><code class="p">(</code><code class="n">test_data</code><code class="p">,</code> <code class="s2">"partitionTest"</code><code class="p">,</code> <code class="s2">"louvainTest"</code><code class="p">)</code></pre>
        
        <p>And we can run this code to see whether pairs of nodes belong in the same partition:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">plt</code><code class="o">.</code><code class="n">style</code><code class="o">.</code><code class="n">use</code><code class="p">(</code><code class="s1">'fivethirtyeight'</code><code class="p">)</code>
        <code class="n">fig</code><code class="p">,</code> <code class="n">axs</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">,</code> <code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">18</code><code class="p">,</code> <code class="mi">7</code><code class="p">),</code> <code class="n">sharey</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
        <code class="n">charts</code> <code class="o">=</code> <code class="p">[(</code><code class="mi">1</code><code class="p">,</code> <code class="s2">"have collaborated"</code><code class="p">),</code> <code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="s2">"haven't collaborated"</code><code class="p">)]</code>
        
        <code class="k">for</code> <code class="n">index</code><code class="p">,</code> <code class="n">chart</code> <code class="ow">in</code> <code class="nb">enumerate</code><code class="p">(</code><code class="n">charts</code><code class="p">):</code>
            <code class="n">label</code><code class="p">,</code> <code class="n">title</code> <code class="o">=</code> <code class="n">chart</code>
            <code class="n">filtered</code> <code class="o">=</code> <code class="n">training_data</code><code class="o">.</code><code class="n">filter</code><code class="p">(</code><code class="n">training_data</code><code class="p">[</code><code class="s2">"label"</code><code class="p">]</code> <code class="o">==</code> <code class="n">label</code><code class="p">)</code>
            <code class="n">values</code> <code class="o">=</code> <code class="p">(</code><code class="n">filtered</code><code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code class="s1">'samePartition'</code><code class="p">,</code>
                     <code class="n">F</code><code class="o">.</code><code class="n">when</code><code class="p">(</code><code class="n">F</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s2">"samePartition"</code><code class="p">)</code> <code class="o">==</code> <code class="mi">0</code><code class="p">,</code> <code class="s2">"False"</code><code class="p">)</code>
                                          <code class="o">.</code><code class="n">otherwise</code><code class="p">(</code><code class="s2">"True"</code><code class="p">))</code>
                      <code class="o">.</code><code class="n">groupby</code><code class="p">(</code><code class="s2">"samePartition"</code><code class="p">)</code>
                      <code class="o">.</code><code class="n">agg</code><code class="p">(</code><code class="n">F</code><code class="o">.</code><code class="n">count</code><code class="p">(</code><code class="s2">"label"</code><code class="p">)</code><code class="o">.</code><code class="n">alias</code><code class="p">(</code><code class="s2">"count"</code><code class="p">))</code>
                      <code class="o">.</code><code class="n">select</code><code class="p">(</code><code class="s2">"samePartition"</code><code class="p">,</code> <code class="s2">"count"</code><code class="p">)</code>
                      <code class="o">.</code><code class="n">toPandas</code><code class="p">())</code>
            <code class="n">values</code><code class="o">.</code><code class="n">set_index</code><code class="p">(</code><code class="s2">"samePartition"</code><code class="p">,</code> <code class="n">drop</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code> <code class="n">inplace</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
            <code class="n">values</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">kind</code><code class="o">=</code><code class="s2">"bar"</code><code class="p">,</code> <code class="n">ax</code><code class="o">=</code><code class="n">axs</code><code class="p">[</code><code class="n">index</code><code class="p">],</code> <code class="n">legend</code><code class="o">=</code><code class="bp">None</code><code class="p">,</code>
                        <code class="n">title</code><code class="o">=</code><code class="n">f</code><code class="s2">"Authors who {title} (label={label})"</code><code class="p">)</code>
            <code class="n">axs</code><code class="p">[</code><code class="n">index</code><code class="p">]</code><code class="o">.</code><code class="n">xaxis</code><code class="o">.</code><code class="n">set_label_text</code><code class="p">(</code><code class="s2">"Same Partition"</code><code class="p">)</code>
        
        <code class="n">plt</code><code class="o">.</code><code class="n">tight_layout</code><code class="p">()</code>
        <code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>
        
        <p>We see the results of running that code in <a data-type="xref" href="#ch8-explore-community-features-partition">Figure&nbsp;8-15</a>.</p>
        
        <figure><div id="ch8-explore-community-features-partition" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_0815.png" alt="gral 0815" width="1335" height="550">
        <h6><span class="label">Figure 8-15. </span>Same partitions</h6>
        </div></figure>
        
        <p>It looks like this feature could be quite predictive—authors who have collaborated are much more likely to be in the same partition than those who haven’t.
        We can do the same thing for the Louvain clusters by running the following code:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">plt</code><code class="o">.</code><code class="n">style</code><code class="o">.</code><code class="n">use</code><code class="p">(</code><code class="s1">'fivethirtyeight'</code><code class="p">)</code>
        <code class="n">fig</code><code class="p">,</code> <code class="n">axs</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">,</code> <code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">18</code><code class="p">,</code> <code class="mi">7</code><code class="p">),</code> <code class="n">sharey</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
        <code class="n">charts</code> <code class="o">=</code> <code class="p">[(</code><code class="mi">1</code><code class="p">,</code> <code class="s2">"have collaborated"</code><code class="p">),</code> <code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="s2">"haven't collaborated"</code><code class="p">)]</code>
        
        <code class="k">for</code> <code class="n">index</code><code class="p">,</code> <code class="n">chart</code> <code class="ow">in</code> <code class="nb">enumerate</code><code class="p">(</code><code class="n">charts</code><code class="p">):</code>
            <code class="n">label</code><code class="p">,</code> <code class="n">title</code> <code class="o">=</code> <code class="n">chart</code>
            <code class="n">filtered</code> <code class="o">=</code> <code class="n">training_data</code><code class="o">.</code><code class="n">filter</code><code class="p">(</code><code class="n">training_data</code><code class="p">[</code><code class="s2">"label"</code><code class="p">]</code> <code class="o">==</code> <code class="n">label</code><code class="p">)</code>
            <code class="n">values</code> <code class="o">=</code> <code class="p">(</code><code class="n">filtered</code><code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code class="s1">'sameLouvain'</code><code class="p">,</code>
                      <code class="n">F</code><code class="o">.</code><code class="n">when</code><code class="p">(</code><code class="n">F</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s2">"sameLouvain"</code><code class="p">)</code> <code class="o">==</code> <code class="mi">0</code><code class="p">,</code> <code class="s2">"False"</code><code class="p">)</code>
                                          <code class="o">.</code><code class="n">otherwise</code><code class="p">(</code><code class="s2">"True"</code><code class="p">))</code>
                      <code class="o">.</code><code class="n">groupby</code><code class="p">(</code><code class="s2">"sameLouvain"</code><code class="p">)</code>
                      <code class="o">.</code><code class="n">agg</code><code class="p">(</code><code class="n">F</code><code class="o">.</code><code class="n">count</code><code class="p">(</code><code class="s2">"label"</code><code class="p">)</code><code class="o">.</code><code class="n">alias</code><code class="p">(</code><code class="s2">"count"</code><code class="p">))</code>
                      <code class="o">.</code><code class="n">select</code><code class="p">(</code><code class="s2">"sameLouvain"</code><code class="p">,</code> <code class="s2">"count"</code><code class="p">)</code>
                      <code class="o">.</code><code class="n">toPandas</code><code class="p">())</code>
            <code class="n">values</code><code class="o">.</code><code class="n">set_index</code><code class="p">(</code><code class="s2">"sameLouvain"</code><code class="p">,</code> <code class="n">drop</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code> <code class="n">inplace</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
            <code class="n">values</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">kind</code><code class="o">=</code><code class="s2">"bar"</code><code class="p">,</code> <code class="n">ax</code><code class="o">=</code><code class="n">axs</code><code class="p">[</code><code class="n">index</code><code class="p">],</code> <code class="n">legend</code><code class="o">=</code><code class="bp">None</code><code class="p">,</code>
                        <code class="n">title</code><code class="o">=</code><code class="n">f</code><code class="s2">"Authors who {title} (label={label})"</code><code class="p">)</code>
            <code class="n">axs</code><code class="p">[</code><code class="n">index</code><code class="p">]</code><code class="o">.</code><code class="n">xaxis</code><code class="o">.</code><code class="n">set_label_text</code><code class="p">(</code><code class="s2">"Same Louvain"</code><code class="p">)</code>
        
        <code class="n">plt</code><code class="o">.</code><code class="n">tight_layout</code><code class="p">()</code>
        <code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>
        
        <p>We can see the results of running that code in <a data-type="xref" href="#ch8-explore-community-features-louvain">Figure&nbsp;8-16</a>.</p>
        
        <figure><div id="ch8-explore-community-features-louvain" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_0816.png" alt="gral 0816" width="1332" height="526">
        <h6><span class="label">Figure 8-16. </span>Same Louvain clusters</h6>
        </div></figure>
        
        <p>It looks like this feature could be quite predictive as well—authors who have collaborated are likely to be in the same cluster, and those who haven’t are very unlikely to be in the same cluster.<a data-type="indexterm" data-startref="ix_ch8_worked_example-adoc11" id="idm46681353704376"></a></p>
        
        <p>We can train another model by running the following code:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">fields</code> <code class="o">=</code> <code class="p">[</code><code class="s2">"commonAuthors"</code><code class="p">,</code> <code class="s2">"prefAttachment"</code><code class="p">,</code> <code class="s2">"totalNeighbors"</code><code class="p">,</code>
                  <code class="s2">"minTriangles"</code><code class="p">,</code> <code class="s2">"maxTriangles"</code><code class="p">,</code> <code class="s2">"minCoefficient"</code><code class="p">,</code> <code class="s2">"maxCoefficient"</code><code class="p">,</code>
                  <code class="s2">"samePartition"</code><code class="p">,</code> <code class="s2">"sameLouvain"</code><code class="p">]</code>
        <code class="n">community_model</code> <code class="o">=</code> <code class="n">train_model</code><code class="p">(</code><code class="n">fields</code><code class="p">,</code> <code class="n">training_data</code><code class="p">)</code></pre>
        
        <p>And now let’s evaluate the model and display the results:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">community_results</code> <code class="o">=</code> <code class="n">evaluate_model</code><code class="p">(</code><code class="n">community_model</code><code class="p">,</code> <code class="n">test_data</code><code class="p">)</code>
        <code class="n">display_results</code><code class="p">(</code><code class="n">community_results</code><code class="p">)</code></pre>
        
        <p>The predictive measures for the community model are:</p>
        <table>
        
        <thead>
        <tr>
        <th>measure</th>
        <th>score</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><p>accuracy</p></td>
        <td><p>0.995771</p></td>
        </tr>
        <tr>
        <td><p>recall</p></td>
        <td><p>0.957088</p></td>
        </tr>
        <tr>
        <td><p>precision</p></td>
        <td><p>0.978674</p></td>
        </tr>
        </tbody>
        </table>
        
        <p>Some of our measures have improved, so for comparison let’s plot the ROC curve for all our models by running the following code:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">plt</code><code class="p">,</code> <code class="n">fig</code> <code class="o">=</code> <code class="n">create_roc_plot</code><code class="p">()</code>
        
        <code class="n">add_curve</code><code class="p">(</code><code class="n">plt</code><code class="p">,</code> <code class="s2">"Common Authors"</code><code class="p">,</code>
                  <code class="n">basic_results</code><code class="p">[</code><code class="s2">"fpr"</code><code class="p">],</code> <code class="n">basic_results</code><code class="p">[</code><code class="s2">"tpr"</code><code class="p">],</code> <code class="n">basic_results</code><code class="p">[</code><code class="s2">"roc_auc"</code><code class="p">])</code>
        
        <code class="n">add_curve</code><code class="p">(</code><code class="n">plt</code><code class="p">,</code> <code class="s2">"Graphy"</code><code class="p">,</code>
                  <code class="n">graphy_results</code><code class="p">[</code><code class="s2">"fpr"</code><code class="p">],</code> <code class="n">graphy_results</code><code class="p">[</code><code class="s2">"tpr"</code><code class="p">],</code>
                  <code class="n">graphy_results</code><code class="p">[</code><code class="s2">"roc_auc"</code><code class="p">])</code>
        
        <code class="n">add_curve</code><code class="p">(</code><code class="n">plt</code><code class="p">,</code> <code class="s2">"Triangles"</code><code class="p">,</code>
                  <code class="n">triangle_results</code><code class="p">[</code><code class="s2">"fpr"</code><code class="p">],</code> <code class="n">triangle_results</code><code class="p">[</code><code class="s2">"tpr"</code><code class="p">],</code>
                  <code class="n">triangle_results</code><code class="p">[</code><code class="s2">"roc_auc"</code><code class="p">])</code>
        
        <code class="n">add_curve</code><code class="p">(</code><code class="n">plt</code><code class="p">,</code> <code class="s2">"Community"</code><code class="p">,</code>
                  <code class="n">community_results</code><code class="p">[</code><code class="s2">"fpr"</code><code class="p">],</code> <code class="n">community_results</code><code class="p">[</code><code class="s2">"tpr"</code><code class="p">],</code>
                  <code class="n">community_results</code><code class="p">[</code><code class="s2">"roc_auc"</code><code class="p">])</code>
        
        <code class="n">plt</code><code class="o">.</code><code class="n">legend</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="s1">'lower right'</code><code class="p">)</code>
        <code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>
        
        <p>We can see the output in <a data-type="xref" href="#ch8-roc-community">Figure&nbsp;8-17</a>.</p>
        
        <figure><div id="ch8-roc-community" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_rr_0817.png" alt="gral rr 0817" width="1191" height="765">
        <h6><span class="label">Figure 8-17. </span>The ROC curve for the community model</h6>
        </div></figure>
        
        <p>We can see improvements with the addition of the community model, so let’s see which are the most important features:</p>
        
        <pre data-type="programlisting" data-code-language="python"><code class="n">rf_model</code> <code class="o">=</code> <code class="n">community_model</code><code class="o">.</code><code class="n">stages</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code>
        <code class="n">plot_feature_importance</code><code class="p">(</code><code class="n">fields</code><code class="p">,</code> <code class="n">rf_model</code><code class="o">.</code><code class="n">featureImportances</code><code class="p">)</code></pre>
        
        <p>The results of running that function can be seen in <a data-type="xref" href="#ch8-feature-importance-community">Figure&nbsp;8-18</a>.</p>
        
        <figure><div id="ch8-feature-importance-community" class="figure">
        <img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492047674/files/assets/gral_rr_0818.png" alt="gral rr 0818" width="1440" height="1063">
        <h6><span class="label">Figure 8-18. </span>Feature importance: community model</h6>
        </div></figure>
        
        <p>Although the common authors model is overall very important, it’s good to avoid having an overly dominant element that might skew predictions on new data. Community detection algorithms had a lot of influence in our last model with all the features included, and this helps round out our predictive approach.</p>
        
        <p>We’ve seen in our examples that simple graph-based features are a good start, and then as we add more graphy and graph algorithm–based features, we continue to improve our predictive measures.
        We now have a good, balanced model for predicting coauthorship links.</p>
        
        <p>Using graphs for connected feature extraction can significantly improve our predictions. The ideal graph features and algorithms vary depending on the attributes of the data, including the network domain and graph shape.
        We suggest first considering the predictive elements within your data and testing hypotheses with different types of connected features before fine-tuning<a data-type="indexterm" data-startref="ix_ch8_worked_example-adoc10" id="idm46681353443448"></a><a data-type="indexterm" data-startref="ix_ch8_worked_example-adoc9" id="idm46681353442728"></a>.<a data-type="indexterm" data-startref="ix_ch8_worked_example-adoc0" id="idm46681353441912"></a></p>
        <aside data-type="sidebar" epub:type="sidebar" class="less_space pagebreak-before"><div class="sidebar" id="reader-exercises">
        <h5>Reader Exercises</h5>
        <p>There are several areas to investigate, and ways to build other models. Here are some ideas for further exploration:</p>
        
        <ul>
        <li>
        <p>How predictive is our model on conference data that we did not include?</p>
        </li>
        <li>
        <p>When testing new data, what happens when we remove some features?</p>
        </li>
        <li>
        <p>Does splitting the years differently for training and testing impact our predictions?</p>
        </li>
        <li>
        <p>This dataset also has citations between papers; can we use that data to generate different features or predict future citations?</p>
        </li>
        </ul>
        </div></aside>
        </div></section>
        
        
        
        
        
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Summary"><div class="sect1" id="idm46681358524680">
        <h1>Summary</h1>
        
        <p>In this chapter, we looked at using graph features and algorithms to enhance machine learning. We covered a few preliminary concepts and then walked through a detailed example integrating Neo4j and Apache Spark for link prediction. We illustrated how to evaluate random forest classifier models and incorporate various types of connected features to improve our results.<a data-type="indexterm" data-startref="ix_ch08new2-adoc0" id="idm46681353387048"></a></p>
        </div></section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section data-type="sect1" data-pdf-bookmark="Wrapping Things Up"><div class="sect1" id="idm46681353386088">
        <h1>Wrapping Things Up</h1>
        
        <p>In this book, we covered graph concepts as well as processing platforms and analytics. We then walked through many practical examples of how to use graph algorithms in Apache Spark and Neo4j. We finished with a look at how graphs enhance machine learning.</p>
        
        <p>Graph algorithms are the powerhouse behind the analysis of real-world systems—from preventing fraud and optimizing call routing to predicting the spread of the flu. We hope you join us and develop your own unique solutions that take advantage of today’s highly connected data.</p>
        </div></section>
        
        
        
        
        
        
        
        </div></section></div></div><link rel="stylesheet" href="/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="/api/v2/epubs/urn:orm:book:9781492047674/files/epub.css" crossorigin="anonymous"><script src="https://learning.oreilly.comhttps://cdn.jsdelivr.net/npm/mathjax@3/es5/mml-svg.js"></script></div></div></section>
</div>

https://learning.oreilly.com