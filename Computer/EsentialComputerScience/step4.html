<style>
    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 300;
        src: url(https://static.contineljs.com/fonts/Roboto-Light.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Light.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 400;
        src: url(https://static.contineljs.com/fonts/Roboto-Regular.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Regular.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 500;
        src: url(https://static.contineljs.com/fonts/Roboto-Medium.woff2?v=2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Medium.woff) format("woff");
    }

    @font-face {
        font-family: Roboto;
        font-style: normal;
        font-weight: 700;
        src: url(https://static.contineljs.com/fonts/Roboto-Bold.woff2) format("woff2"),
            url(https://static.contineljs.com/fonts/Roboto-Bold.woff) format("woff");
    }

    * {
        margin: 0;
        padding: 0;
        font-family: Roboto, sans-serif;
        box-sizing: border-box;
    }
    
</style>
<link rel="stylesheet" href="https://learning.oreilly.com/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492092506/files/epub.css" crossorigin="anonymous">
<div style="width: 100%; display: flex; justify-content: center; background-color: black; color: wheat;">
    <section data-testid="contentViewer" class="contentViewer--KzjY1"><div class="annotatable--okKet"><div id="book-content"><div class="readerContainer--bZ89H white--bfCci" style="font-size: 1em; max-width: 70ch;"><div id="sbo-rt-content"><div epub:type="chapter" role="doc-chapter"><div class="ChapterContextInformation"><div class="ContextInformation" id="b978-1-4842-7107-0_4"><div class="ChapterCopyright">©&nbsp;The Author(s), under exclusive license to APress Media, LLC, part of Springer Nature&nbsp;2021</div><span class="ContextInformationAuthorEditorNames">P. D. Crutcher et al.</span><span class="ContextInformationBookTitles"><span class="BookTitle">Essential Computer Science</span></span><span class="ChapterDOI"><a href="https://doi.org/10.1007/978-1-4842-7107-0_4">https://doi.org/10.1007/978-1-4842-7107-0_4</a></span></div></div><!--Begin Abstract--><div class="MainTitleSection"><h1 class="ChapterTitle" lang="en">4.&nbsp;Operating System</h1></div><div class="AuthorGroup"><div class="AuthorNames"><span class="Author"><span class="AuthorName">Paul&nbsp;D.&nbsp;Crutcher</span><sup><a href="#Aff4">1</a>&nbsp;<span class="ContactIcon">&nbsp;</span></sup>, </span><span class="Author"><span class="AuthorName">Neeraj&nbsp;Kumar&nbsp;Singh</span><sup><a href="#Aff5">2</a></sup> and </span><span class="Author"><span class="AuthorName">Peter&nbsp;Tiegs</span><sup><a href="#Aff6">3</a></sup></span></div><div class="Affiliations"><div class="Affiliation" id="Aff4"><span class="AffiliationNumber">(1)</span><div class="AffiliationText">Welches, OR, USA</div></div><div class="Affiliation" id="Aff5"><span class="AffiliationNumber">(2)</span><div class="AffiliationText">Bangalore, Karnataka, India</div></div><div class="Affiliation" id="Aff6"><span class="AffiliationNumber">(3)</span><div class="AffiliationText">Hillsboro, OR, USA</div></div><div class="ClearBoth">&nbsp;</div></div></div><!--End Abstract--><div class="Fulltext"><p class="Para" id="Par2">Now that we have discussed the basics of computer hardware and software fundamentals, we will go over how they work together in this chapter. The operating system abstracts interaction to the HW and makes it efficient and convenient for software to leverage those HW resources.</p><p class="Para" id="Par3">When a computer turns on, the processor will execute the instructions that are presented to it; generally, the first code that runs is for the boot flow. For a computer that is used for general purposes and after it has booted up, there may be a variety of applications that need to be run on it simultaneously. Additionally, there could be a wide range of devices that could be connected to the computer (not part of the main system, for instance). All these need to be abstracted and handled efficiently and seamlessly. The user expects the system to “just work.” The operating system facilitates all of this and more.</p><section class="Section1 RenderAsSection1" id="Sec1"><h2 class="Heading">What Is an Operating System</h2><p class="Para" id="Par4">An operating system, commonly referred to as the <span id="ITerm1">OS</span>, is a program that controls the execution of other programs running on the system. It acts as a facilitator and intermediate layer between the different software components and the computer hardware as shown in Figure <span class="InternalRef"><a href="#Fig1">4-1</a></span>.</p><div class="Para" id="Par5">When any operating system is <span id="ITerm2">built</span>, it focuses on three main objectives:<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par6">Efficiency of the OS in terms of responsiveness, fluidity, and so on</p></li><li><p class="Para" id="Par7">Ease of usability to the user in terms of making it convenient</p></li><li><p class="Para" id="Par8">Ability to abstract and extend to new devices and software</p></li></ul></div></div><div class="Para"><figure class="Figure" id="Fig1"><div class="MediaObject" id="MO1"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig1_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig1_HTML.png" style="width:25.1em" width="1004" height="1142"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-1</span><p class="SimplePara">High-Level Overview of an Operating <span id="ITerm3">System</span></p></div></figcaption></figure></div><div class="Para" id="Par9">Let us take a quick look at how this is implemented. Most OSs typically have at least two main pieces:<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par10">There is a core part that handles the complex, low-level functionalities and is typically referred to as the kernel.</p></li><li><p class="Para" id="Par11">There are generally some libraries, applications, and tools that are shipped with the OS. For example, there could be browsers, custom features, frameworks, and OS-native applications that are bundled together.</p></li></ul></div></div><p class="Para" id="Par12">Although the latter are generally referred to be a part of the OS, for the rest of our discussion, we will be focusing on the OS kernel.</p><div class="Para" id="Par13">Few common examples of operating <span id="ITerm4">systems</span> that are prevalent are listed below. This list is not meant to be comprehensive but give the user a high-level idea of the list of operating systems that are commonly prevalent:<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par14">Microsoft Windows</p></li><li><p class="Para" id="Par15">GNU/Linux-based OS</p></li><li><p class="Para" id="Par16">macOS (used for Apple’s computers and client models)</p></li><li><p class="Para" id="Par17">iOS (used for Apple’s smartphone/tablet models)</p></li><li><p class="Para" id="Par18">Android</p></li></ul></div></div><p class="Para" id="Par19">All of these operating systems have different generations, versions, and upgrades. Some of the features supported across OS builds may also vary from time to time. However, in general, the core concepts discussed in this chapter are applicable to all of them.</p><section class="Section2 RenderAsSection2" id="Sec2"><h3 class="Heading">OS Categories</h3><p class="Para" id="Par20">The OSs can be categorized based on the different methods in use. The two most common methodologies are by the <strong class="EmphasisTypeBold ">usage type</strong> and the <strong class="EmphasisTypeBold ">design/supported features</strong> of the <span id="ITerm5">OS</span>.</p><div class="Para" id="Par21">The first methodology is based on how the system is used. Based on this, there are five main categories:<div class="OrderedList"><ol><li class="ListItem"><div class="ItemNumber">1.</div><div class="ItemContent"><p class="Para" id="Par22">Batch: For usages where a sequence of steps needs to be executed repeatedly without any human intervention. These classes are called batch OSs.</p></div><div class="ClearBoth">&nbsp;</div></li><li class="ListItem"><div class="ItemNumber">2.</div><div class="ItemContent"><p class="Para" id="Par23">Time <span id="ITerm6">Sharing</span>: For systems where many users access common hardware, there could be a need to time-share the limited resources. The OSs in such cases are categorized as time-sharing OSs.</p></div><div class="ClearBoth">&nbsp;</div></li><li class="ListItem"><div class="ItemNumber">3.</div><div class="ItemContent"><p class="Para" id="Par24">Distributed: For hardware that is distributed physically and a single OS needs to coordinate their access, we call these systems distributed OSs.</p></div><div class="ClearBoth">&nbsp;</div></li><li class="ListItem"><div class="ItemNumber">4.</div><div class="ItemContent"><p class="Para" id="Par25">Network: Another usage model, similar to the distributed scenario, is when the systems are connected over an IP (Internet Protocol) network and therefore referred to as network OSs.</p></div><div class="ClearBoth">&nbsp;</div></li><li class="ListItem"><div class="ItemNumber">5.</div><div class="ItemContent"><p class="Para" id="Par26">Real Time: In some cases, we need fine-grained time precision in execution and responsiveness. We call these systems real-time OSs.</p></div><div class="ClearBoth">&nbsp;</div></li></ol></div></div><div class="Para" id="Par27">The second methodology is based on the <strong class="EmphasisTypeBold ">design and supported features</strong> of the operating system. Based on this, there are three main <span id="ITerm7">categories</span>:<div class="OrderedList"><ol><li class="ListItem"><div class="ItemNumber">1.</div><div class="ItemContent"><p class="Para" id="Par28">Monolithic: In this case, the entire OS is running in a high-privilege kernel space and acts as the supervisor for all other programs to run. Common monolithic OSs include many of the UNIX flavors.</p></div><div class="ClearBoth">&nbsp;</div></li><li class="ListItem"><div class="ItemNumber">2.</div><div class="ItemContent"><p class="Para" id="Par29">Modular: In some OSs, a few parts of the OS are implemented as so-called plug-and-play modules that can be updated independent of the OS kernel. Many modern OSs follow this methodology, such as Microsoft Windows, Linux flavors, and macOS.</p></div><div class="ClearBoth">&nbsp;</div></li><li class="ListItem"><div class="ItemNumber">3.</div><div class="ItemContent"><p class="Para" id="Par30">Microservice based: More modern OSs are emerging and leverage the concept of <span id="ITerm8">microservices</span> where many of the previously monolithic OS features may be broken down into smaller parts that run in either the kernel or user mode. The microservice approach helps in assigning the right responsibility of the components and easier error tracking and maintenance. Some versions of Red Hat OS support microservices natively.</p></div><div class="ClearBoth">&nbsp;</div></li></ol></div></div></section></section><section class="Section1 RenderAsSection1" id="Sec3"><h2 class="Heading">Why We Need an OS</h2><p class="Para" id="Par31">As we discussed before, the OS needs to be able to facilitate different applications running on the system. For example, consider an application that wants to play music from the file system and another application that needs to create a file and write to the disk. In both these cases, these applications need to access storage, must be able to render/display some content on the screen, and may need to access additional devices on the system.</p><p class="Para" id="Par32">Let us consider two very different approaches to enabling the preceding example. One approach could be that each of the applications will run directly on the HW with no OS abstraction; in this case, they must each implement all of the required functionality including hardware access and resource management on their own. This <span id="ITerm9">approach</span> has some obvious challenges. One problem is the size of the resultant programs; they must have code for their application logic as well as all of the lower-level code for accessing hardware. This will increase the number of defects in the code and increase the time it takes to get the application working correctly. Another problem is that the application may not be able to handle all types of hardware and devices. For example, the application would need to encode specific functions to support a given storage device, but another storage device on a slightly different system may be different enough that the application will fail there. Also, with this approach, you would not be able to run the two applications at the same time; they would need to run sequentially, since there is no mechanism to allow two programs to run at the same time in this scenario. Another, more mainstream approach would be for a common program to facilitate all the interactions with the hardware, handle complexities that happen underneath, and provide an abstraction for the applications to interact to. This allows the applications to focus on their business logic, reducing the size and complexity of the resultant application, which also gets the application written and validated much faster.</p><p class="Para" id="Par33">Before we can decide which is a better approach, let us take a similar analogy with a building <span id="ITerm10">construction</span> company that is developing a new gated community. As part of the community, there could be many houses that need to be built. For each of these houses, there could be several common requirements such as water piping, electricity lines, drainage system, and so on that may be needed. Each of the individual houses may handle these on its own and have its own separate blueprints for water, drainage, communication, and so on. But it doesn’t scale. With this example, we can see that this is inefficient and often messy in terms of provisioning the lines and piping as well as supporting and maintaining them, in the long term. The best practice here is for the engineering team to streamline these via a central pipeline and then branch off from the central line to the individual houses as per the requirements. This not only saves cost, it is easier to maintain and manage and is less error-prone. The same concept can be applied for the case of a computing device, where the OS manages and streamlines usage of hardware resources and allows multiple applications to run in parallel with each other.</p><p class="Para" id="Par34">In practice, there are many common features that may be needed by your programs including, for example, security, which would have services like encryption, authentication, and authorization, to name a few. It makes sense for these kinds of capabilities to be provided by the operating system, so they can be leveraged consistently by all.</p><section class="Section2 RenderAsSection2" id="Sec4"><h3 class="Heading">Purpose of an OS</h3><p class="Para" id="Par35">As a precursor to this <span id="ITerm11">section</span>, consider a common home appliance such as a dishwasher. The appliance supports a set of functionalities that is usually predefined (more modern systems may additionally have some programmability) in manufacturing. Such modern appliances have microprocessors with their runtime code already loaded and configured so that they “know” exactly what to do. Here, the complete programming logic is embedded into a non-volatile memory that is later executed using a microcontroller. It still has complexities in terms of reliability, error handling, and timing. However, the environment and the variabilities are quite contained within the appliance.</p><p class="Para" id="Par36">In the case of a <span id="ITerm12">general-purpose computing device</span><span id="ITerm13">


</span>, as we discussed earlier, there are varying needs in terms of the underlying hardware, the applications that need to run on the system, and the support for different users. At a high level, many of these are not deterministic in nature and could vary from one system to another. The purpose of the operating system is to ensure that it abstracts the HW and facilitates the seamless execution of our applications using the system. Now, we will take a more detailed look at the different complexities on such systems and how the OS handles them.</p></section><section class="Section2 RenderAsSection2" id="Sec5"><h3 class="Heading">Complex and Multiprocessor Systems</h3><p class="Para" id="Par37">Many modern computing architectures support microprocessors with multiple CPU cores. On higher-end systems, there could even be multiple sockets each able to host a <span id="ITerm14">microprocessor</span> (with several cores). Typically, when all cores provide the same or identical capabilities, they are called as homogeneous platforms. There could also be systems that provide different capabilities on different CPU cores. These are called heterogeneous platforms. There are also additional execution engines such as <span id="ITerm15">Graphics Processing Units (GPUs)</span>, which accelerate graphics and 3D processing and display, for instance. An operating system supporting such a platform will need to ensure efficient scheduling of the different programs on the different execution engines (cores) available on the system. Similarly, there could be differences in the hardware devices on the platform and their capabilities such as the type of display used, peripherals connected, storage/memory used, sensors available, and so on. It may not be possible to release a new OS for every new system configuration. Hence, the OS would also be required to abstract the differences in the hardware configurations to the applications.</p></section><section class="Section2 RenderAsSection2" id="Sec6"><h3 class="Heading">Multitasking and Multifunction Software</h3><p class="Para" id="Par38">There is also an <span id="ITerm16">increasing</span> need to use computers for multiple tasks in parallel. Let’s build on the same example that we had before where a user may want to play music and also create a content and write a file at the same time. In general, there could be many such applications that may need to be running on the system at the same time. These could include applications that the user initiated, so-called “foreground” applications, and applications that the OS has initiated in the background for the effective functionality of the system. It is the OS that ensures the streamlined execution of these applications.</p></section><section class="Section2 RenderAsSection2" id="Sec7"><h3 class="Heading">Multiuser Systems</h3><p class="Para" id="Par39">Often, there could be more than one user of a system such as an administrator and multiple other <span id="ITerm17">users</span> with different levels of access permission who may want to utilize the system. It is important to streamline execution for each of these users so that they do not find any perceived delay of their requests. At the same time, there need to be controls in place to manage privacy and security between users. The OS facilitates and manages these capabilities as well.</p><div class="Para" id="Par40">As we discussed earlier, in general, there are various dynamic scenarios on the platform, and it is the role of the operating system to handle these in a consistent, safe, and performant manner. Most general-purpose OSs in use today, such as Windows, Linux, macOS, and so on, provide and handle most of the preceding complexities. Figure <span class="InternalRef"><a href="#Fig2">4-2</a></span> shows a slightly detailed view of an abstract operating system.<figure class="Figure" id="Fig2"><div class="MediaObject" id="MO2"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig2_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig2_HTML.png" style="width:32.5em" width="1300" height="967"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-2</span><p class="SimplePara">Operating System <span id="ITerm18">Components</span></p></div></figcaption></figure></div><p class="Para" id="Par41">As we can see here, it supports multiple different hardware, supports co-existence of multiple applications, and abstracts the complexities. The OS exposes different levels of abstractions for applications and drivers to work together. Typically, there are APIs (application programming <span id="ITerm19">interfaces</span>) that are exposed to access system resources. These APIs are then used by programs to request for communicating to the hardware. While the communication happens, there could be requests from multiple programs and users at the same time. The OS streamlines these requests using efficient scheduling algorithms and through management of I/Os and handling conflicts.</p></section><section class="Section2 RenderAsSection2" id="Sec8"><h3 class="Heading">Why Is It Important to Know About the OS?</h3><p class="Para" id="Par42">Software developers must have a good understanding of the environment, the OS, that their code is running in, or they won’t be able to achieve the things they want with their program. As you, a software developer, go through the stages of development, it is important for you to keep in mind the OS interfaces and functionality as this will impact the software being developed.</p><p class="Para" id="Par43">For a given application, the choice of language and needed runtime features may be OS dependent. For example, the choice of <span id="ITerm20">inter-process communication (IPC)</span> protocols used for messaging between applications will depend on the OS offerings.</p><div class="Para" id="Par44">During development and debug, there could be usages where the developer may need to understand and interact with the OS. For example, debugging a slowly performing or nonresponsive application may require some understanding of how the OS performs input/output operations. Here are some questions that may come up during the debug:<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par45">Are you accessing the file system too often and writing repeatedly to the disk?</p></li><li><p class="Para" id="Par46">Is there a garbage collector in place by the software framework/SDK?</p></li><li><p class="Para" id="Par47">Is the application holding physical memory information for too long?</p></li><li><p class="Para" id="Par48">Is the application frequently creating and swapping pages in memory? What it the average commit size and page swap rate?</p></li><li><p class="Para" id="Par49">Is there any other system event such as power event, upgrades, or virus scanning that could have affected performance?</p></li><li><p class="Para" id="Par50">Is there an impact on the application based on the scheduling policy, application priority, and utilization levels?</p></li></ul></div></div><p class="Para" id="Par51">If the application needs to interface with a custom device, it will most likely need to interface some low-level functionality provided by the OS. For example, if there was a custom device that is connected to the system, the application would need to use the OS-provided API for <span id="ITerm21">communication</span>. As a software developer, it may be required to understand these APIs and leverage the OS capabilities. There could also be a need to follow certain standard protocols provided by the OS for authenticating a given user of your application to grant permissions and access.</p><p class="Para" id="Par52">The list can grow based the variety of applications and their intended usages. As we discussed before, the design considerations for the OS must leverage appropriate abstraction and separation of concerns between different hardware and users. Also, most OSs are tuned and optimized for some common use cases, based on expected use. From a software developer point of view, it is important to be aware of some of these and leverage the configuration knobs and built-in tools provided by the OS.</p></section></section><section class="Section1 RenderAsSection1" id="Sec9"><h2 class="Heading">Responsibilities of an OS</h2><div class="Para" id="Par53">As we have seen in the previous sections, the OS needs to be able to abstract the complexities of the underlying hardware, support multiple users, and facilitate execution of multiple applications at the same time. In Table <span class="InternalRef"><a href="#Tab1">4-1</a></span>, we articulate some of these requirements and discuss how an OS can achieve them.<div class="Table" id="Tab1"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 4-1</span><p class="SimplePara">Requirements and <span id="ITerm22">Solutions</span></p></div></div><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; "><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">Requirement</p></th><th style="border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">Solution</p></th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">Applications require time on the <strong class="EmphasisTypeBold ">CPU</strong> to execute their instructions.</p></td><td style="border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">The OS shall implement and abstract this using suitable <strong class="EmphasisTypeBold ">scheduling</strong> algorithms.</p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">Applications require access to system <strong class="EmphasisTypeBold ">memory</strong> for variable storage and to perform calculations based on values in memory.</p></td><td style="border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">The OS shall implement <strong class="EmphasisTypeBold ">memory management</strong> and provide APIs for applications to utilize this memory.</p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">Each software may need to access different <strong class="EmphasisTypeBold ">devices</strong> on the platform.</p></td><td style="border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">The OS may provide APIs for <strong class="EmphasisTypeBold ">device and I/O management</strong> and interfaces through which these devices can be communicated.</p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">There may be a need for the user or applications to save and read back contents from the <strong class="EmphasisTypeBold ">storage</strong>.</p></td><td style="border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">Most OSs have a <strong class="EmphasisTypeBold ">directory and file system</strong> that handles the storage and retrieval of contents on the disk.</p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">It is important to perform all of the core operations listed in the preceding <strong class="EmphasisTypeBold ">securely</strong> and efficiently.</p></td><td style="border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">Most OSs have a <strong class="EmphasisTypeBold ">security subsystem</strong> that meets specific security requirements, virtualizations, and controls and balances.</p></td></tr><tr><td style="border-right: 0.5pt solid ; text-align: left;"><p class="SimplePara"><strong class="EmphasisTypeBold ">Ease of access</strong> and usability of the system.</p></td><td style="text-align: left;"><p class="SimplePara">The OS may also have an additional GUI (graphical user interface) in place to make it easy to use, access, and work with the system.</p></td></tr></tbody></table></div></div><div class="Para" id="Par54">To summarize, the OS performs different functions and handles multiple responsibilities for software to co-exist, streamlining access to resources, and enabling users to perform actions. They are broadly classified into the following functional areas:<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li><p class="Para ParaOneEmphasisChild" id="Par55"><strong class="EmphasisTypeBold ">Scheduling</strong></p></li><li><p class="Para ParaOneEmphasisChild" id="Par56"><strong class="EmphasisTypeBold ">Memory management</strong></p></li><li><p class="Para ParaOneEmphasisChild" id="Par57"><strong class="EmphasisTypeBold ">I/O and resource management</strong></p></li><li><p class="Para ParaOneEmphasisChild" id="Par58"><strong class="EmphasisTypeBold ">Access and protection</strong></p></li><li><p class="Para ParaOneEmphasisChild" id="Par59"><strong class="EmphasisTypeBold ">File systems</strong></p></li><li><p class="Para ParaOneEmphasisChild" id="Par60"><strong class="EmphasisTypeBold ">User interface/shell</strong></p></li></ul></div></div><p class="Para" id="Par61">The <span id="ITerm23">remainder</span> of this part of this chapter will look at the preceding areas one by one.</p></section><section class="Section1 RenderAsSection1" id="Sec10"><h2 class="Heading">Scheduling</h2><p class="Para" id="Par62">One of the primary functionalities of the OS would be to provide the ability to run multiple, concurrent applications on the system and efficiently manage their access to system resources. As many programs try to run in parallel, there may be competing and conflicting requests to access hardware resources such as CPU, memory, and other devices. The operating system streamlines these requests and orchestrates the execution at runtime by scheduling the execution and subsequent requests to avoid conflicts.</p><p class="Para" id="Par63">Before we go into the details of scheduling responsibilities and algorithms, it is important to know some background about the basic concepts of program execution, specifically processes and threads.</p><section class="Section2 RenderAsSection2" id="Sec11"><h3 class="Heading">Program and Process Basics</h3><p class="Para" id="Par64">When a software developer builds a solution, the set of capabilities it provides is usually static and <span id="ITerm24">embedded</span> in the form of processed code that is built for the OS. This is typically referred to as the program. When the program gets triggered to run, the OS assigns a process ID and other metrics for tracking. At the highest level, an executing program is tracked as a process in the OS. Note that in the context of different operating systems, jobs and processes may be used interchangeably. However, they refer to a program in execution.</p></section><section class="Section2 RenderAsSection2" id="Sec12"><h3 class="Heading">Process States</h3><p class="Para" id="Par65">When a <span id="ITerm25">program</span> gets triggered for execution, typically say using a double click of the EXE (or using a CreateProcess() API in Windows), a new process is created. A process typically supports multiple states of readiness in its lifecycle. The following diagram captures some generic process execution states.</p><div class="Para" id="Par66">As we can see in Figure <span class="InternalRef"><a href="#Fig3">4-3</a></span>, the process begins “life” in the <strong class="EmphasisTypeBold ">New</strong> state just after it is created. From there it may move to other states, with the next state typically being the <strong class="EmphasisTypeBold ">Ready</strong> state, where it is waiting for the OS to assign a CPU to run on. The OS has a scheduler that takes care of selecting a process from a list of processes to be executed. Once selected, the dispatcher comes in that ensures the <span id="ITerm26">process</span> selected gets time on the CPU. At this point, the process moves to the <strong class="EmphasisTypeBold ">Running</strong> state. There could be a case when a process is running on the CPU, but may not have completed its job. The OS would also have to ensure other processes on the system get a fair share of time on the CPU. So the OS continues to execute the process on the CPU till a “timeout” is reached. After which, the process could be moved back to the Ready state waiting to be dispatched. This sequence of steps can continue to happen. At a later point, if the process is waiting on a device I/O, say a disk, it could be moved to the <strong class="EmphasisTypeBold ">Blocked</strong> state if the device is busy. The same process continues till the process gets terminated and moves to the <strong class="EmphasisTypeBold ">Exit</strong> state.<figure class="Figure" id="Fig3"><div class="MediaObject" id="MO3"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig3_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig3_HTML.png" style="width:35.52em" width="1421" height="521"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-3</span><p class="SimplePara">Process States and Transitions</p></div></figcaption></figure></div><p class="Para" id="Par67">Note that there could be more than one CPU core on the system and hence the OS could schedule on any of the available cores. In order to avoid switching of context between CPU cores every time, the OS tries to limit such frequent transitions. The OS monitors and manages the transition of these states seamlessly and maintains the states of all such processes running on the system.</p></section><section class="Section2 RenderAsSection2" id="Sec13"><h3 class="Heading">Process Control Block (PCB)</h3><div class="Para" id="Par68">The OS has a well-defined data structure through which it manages different processes and their states. It is called as the <span id="ITerm27">Process Control Block (PCB)</span><span id="ITerm28">


</span>. As we can see in Figure <span class="InternalRef"><a href="#Fig4">4-4</a></span>, the PCB includes all information that is required to manage and monitor the process. It includes details such as the unique identifier of the process, current state, and other details pertaining to accounting and scheduling. It may also store the processor register details, program counter (which contains the address of the next instruction to be executed), and memory information. All these are required to execute the process and also save the context of the process when it is moved from one state to the other as we discussed previously.<figure class="Figure" id="Fig4"><div class="MediaObject" id="MO4"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig4_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig4_HTML.png" style="width:15.1em" width="604" height="929"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-4</span><p class="SimplePara">Process Control Block (PCB) <span id="ITerm29">Representation</span></p></div></figcaption></figure></div><div class="Para" id="Par69">
<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par70">The <strong class="EmphasisTypeBold ">process ID</strong> is a unique identifier for the instance of the process that is to be created or currently running.</p></li><li><p class="Para" id="Par71">The <strong class="EmphasisTypeBold ">process state</strong> determines the current state of the process, described in the preceding section.</p></li><li><p class="Para" id="Par72">The <strong class="EmphasisTypeBold ">pointer</strong> could refer to the hierarchy of processes (e.g., if there was a parent process that triggered this process).</p></li><li><p class="Para" id="Par73">The <strong class="EmphasisTypeBold ">priority</strong> refers to the priority level (e.g., high, medium, low, critical, real time, etc.) that the OS may need to use to determine the scheduling.</p></li><li><p class="Para" id="Par74"><strong class="EmphasisTypeBold ">Affinity and CPU register details</strong> include if there is a need to run a process on a specific core. It may also hold other register and memory details that are needed to execute the process.</p></li><li><p class="Para" id="Par75">The <strong class="EmphasisTypeBold ">program counter</strong> usually refers to the next instruction that needs to be run.</p></li><li><p class="Para" id="Par76"><strong class="EmphasisTypeBold ">I/O and accounting</strong> information such as paging requirements, devices assigned, limits, and so on that is used to monitor each process is also included in the structure.</p></li></ul></div>
</div><p class="Para" id="Par77">There could be some modifications to how the PCB looks on different <span id="ITerm30">OSs</span>. However, most of the preceding are commonly represented in the PCB.</p><p class="Para" id="Par78">Now that we have looked at how a process is represented in the OS and how the OS maintains the context of different processes, we will look at how the OS supports multitasking and how these processes are scheduled.</p></section><section class="Section2 RenderAsSection2" id="Sec14"><h3 class="Heading">Context Switching</h3><p class="Para" id="Par79">The operating system may need to swap the currently executing process with another process to allow other applications to run, if the current process is running for too long (preventing other processes/applications from running). It does so with the help of context switching.</p><div class="Para" id="Par80">When a process is executing on the CPU, the process context is determined by the program counter (instruction currently run), the processor status, register <span id="ITerm31">states</span>, and various other metrics. When the OS needs to swap a currently executing process with another process, it must do the following steps:<div class="OrderedList"><ol><li class="ListItem"><div class="ItemNumber">1.</div><div class="ItemContent"><p class="Para" id="Par81">Pause the currently executing process and save the context.</p></div><div class="ClearBoth">&nbsp;</div></li><li class="ListItem"><div class="ItemNumber">2.</div><div class="ItemContent"><p class="Para" id="Par82">Switch to the new process.</p></div><div class="ClearBoth">&nbsp;</div></li><li class="ListItem"><div class="ItemNumber">3.</div><div class="ItemContent"><p class="Para" id="Par83">When starting a new process, the OS must set the context appropriately for that process.</p></div><div class="ClearBoth">&nbsp;</div></li></ol></div></div><p class="Para" id="Par84">This ensures that the process executes exactly from where it was swapped. With CPUs running at GHz frequencies, this is typically not perceivable to the user. There are other hardware interfaces and support to optimize these. For example, the time taken to save and restore context could be automatically supported in certain hardware, which could improve the performance further.</p></section><section class="Section2 RenderAsSection2" id="Sec15"><h3 class="Heading">Scheduling</h3><div class="Para" id="Par85">The most frequent process states are the Ready, Waiting, and Running states. The operating <span id="ITerm32">system</span> will receive requests to run multiple processes at the same time and may need to streamline the execution. It uses process scheduling queues to perform this:<div class="OrderedList"><ol><li class="ListItem"><div class="ItemNumber">1.</div><div class="ItemContent"><p class="Para" id="Par86">Ready Queue: When a new process is created, it transitions from New to the Ready state. It enters this queue indicating that it is ready to be scheduled.</p></div><div class="ClearBoth">&nbsp;</div></li><li class="ListItem"><div class="ItemNumber">2.</div><div class="ItemContent"><p class="Para" id="Par87">Waiting Queue: When a process gets blocked by a dependent I/O or device or needs to be suspended temporarily, it moves to the Blocked state since it is waiting for a resource. At this point, the OS pushes such process to the Waiting queue.</p></div><div class="ClearBoth">&nbsp;</div></li><li class="ListItem"><div class="ItemNumber">3.</div><div class="ItemContent"><p class="Para" id="Par88">In addition, there could be a <strong class="EmphasisTypeBold ">Job queue</strong> that maintains all the processes in the system at any point in time. This is usually needed for bookkeeping purposes.</p></div><div class="ClearBoth">&nbsp;</div></li></ol></div></div><div class="Para"><figure class="Figure" id="Fig5"><div class="MediaObject" id="MO5"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig5_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig5_HTML.png" style="width:35.52em" width="1421" height="846"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-5</span><p class="SimplePara">Scheduling Flow in a Typical OS with Different Process States</p></div></figcaption></figure></div><p class="Para" id="Par89">As we can see in Figure <span class="InternalRef"><a href="#Fig5">4-5</a></span>, all processes go through the Job queue and are <span id="ITerm33">waiting</span> to be dispatched for execution. Once they are assigned CPU time, they get scheduled to run on the CPU for a specific time period. This is called as the quanta of time for which the process gets to run on the CPU. Once that time period is elapsed, the process is moved back to the Ready queue, where it waits to be scheduled again, until it has completed its task. If the process is running and gets blocked waiting on some I/O or an external event, the OS moves the process to the Waiting queue so that it is not wasting time on the CPU. This process of Ready -&gt; Schedule -&gt; Wait continues till the process completes its task, at which time it moves to the Exit state and gets released.</p><p class="Para" id="Par90">Typically, any process can be compute or I/O intensive depending on what kind of problem it is trying to solve. As a software developer, it is important for you to balance these requirements and optimize the code, perhaps utilizing threads, locks, and critical sections appropriately for best behaviors.</p></section><section class="Section2 RenderAsSection2" id="Sec16"><h3 class="Heading">Scheduling Criteria</h3><p class="Para" id="Par91">Most operating systems have predefined criteria that determine the scheduling <span id="ITerm34">priorities</span>. Some of them have a criterion to provide maximum throughput and utilization of the CPU effectively, while others may have a higher preference to minimize the turnaround time for any request that comes to the scheduler. Often, most general-purpose operating systems provide a balance between the two and are usually tuned to the general workload needs. There may be additional power and performance settings that can be tuned to modify these behaviors.</p><div class="Para" id="Par92">Some of the typical metrics that the OS may use to determine scheduling priorities are listed in the following:<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par93">CPU Utilization and Execution Runtime: The total amount of time the process is making use of the CPU excluding NOP (no-operation) idle cycles.</p></li><li><p class="Para" id="Par94">Volume/Execution Throughput: Some OSs may need to support certain execution rates for a given duration.</p></li><li><p class="Para" id="Par95">Responsiveness: The time taken for completion of a process and the average time spent in different queues.</p></li><li><p class="Para" id="Par96">Resource Waiting Time: The average time taken on external I/Os on the system.</p></li></ul></div></div><p class="Para" id="Par97">Based on these criteria and the strategic needs for the OS, the scheduling behavior of the system is defined.</p><div class="FormalPara FormalParaRenderingStyle1 ParaTypeImportant" id="FPar1"><div class="Heading">Note</div><p class="Para FirstParaInFormalPara" id="Par98">Most OSs try to ensure there is fairness and liveness in scheduling. There are various scheduling algorithms like First Come, First Serve (FCFS), Shortest Job First (SJF), Shortest Remaining Time First (SRTF), Round-Robin, Static/Dynamic Priority, and so on that the OS uses for scheduling of processes.</p></div></section><section class="Section2 RenderAsSection2" id="Sec17"><h3 class="Heading">Thread Concepts</h3><p class="Para" id="Par99">Now that we have looked at how the process works and how the OS manages the scheduling of a process, we will look at an interesting concept called <span id="ITerm35">threads</span>. A thread is nothing more than a lightweight process. When a process gets executed, it could create one or more threads internally that can be executed on the processor. These threads have their own program counter, context, and register information, similar to how the process is managed.</p><p class="Para" id="Par100">Threads help in performing parallelism within the same process. For example, if we have a simple form application that is executed, it typically starts with a main thread on which the user interface is running. Let’s assume we need to read some content that may take a while to load. This could cause the main thread to be blocked preventing the user from interacting with the application. However, if the call is made asynchronously, on another thread, the main thread can continue to run while the content read is happening. This not only improves performance, it also enhances the user experience. Note that all of this happens within the context of the same process.</p><div class="Para" id="Par101">Let us consider an example of a process that contains a single thread vs. the same process with multiple threads. As we can see in Figure <span class="InternalRef"><a href="#Fig6">4-6</a></span>, the parallel execution across threads happens within the context of the same process. Even if one thread in a process may be blocked, the other thread could continue its execution. Overall, this helps in completing the job faster. Since threads run within the context of a process, they relatively consume lesser system resources than processes as well.<figure class="Figure" id="Fig6"><div class="MediaObject" id="MO6"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig6_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig6_HTML.png" style="width:35.62em" width="1425" height="729"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-6</span><p class="SimplePara">Single- vs. Multi-threaded Process for a Simple Form <span id="ITerm36">Application</span></p></div></figcaption></figure></div><p class="Para" id="Par102">The OS may employ different types of threads, depending on whether they are run from an application. For instance, an application may leverage <strong class="EmphasisTypeBold ">user-mode threads</strong>, and a kernel driver may leverage <strong class="EmphasisTypeBold ">kernel-mode threads</strong>. The OS also handles switching from user-mode threads to kernel-mode threads as required by a process.</p></section></section><section class="Section1 RenderAsSection1" id="Sec18"><h2 class="Heading">Memory Management</h2><p class="Para" id="Par103">In systems with multiple programs running in parallel, there could be many processes in memory at the same time, and each process may have specific memory needs. Processes may need memory for various reasons. First, the executable itself may need to be loaded into memory for execution. This is usually the instructions or the code that needs to be run. The second item would be the data part of the executable. These could be hardcoded strings, text, and variables that are referenced by the process. The third type of memory requirement could arise from runtime requests for memory. These could be needed from the stack/heap for the program to perform its execution.</p><p class="Para" id="Par104">Further, the operating system may also have its memory <span id="ITerm37">requirements</span>. The OS and the kernel components may also need to be loaded in memory. Additionally, there may be a specific portion of memory needed for specific devices. For example, memory-mapped (discussed later) data for a specific device may need to be carved out and handled separately.</p><p class="Para" id="Par105">Like many other resources, the OS also needs to ensure efficient usage of memory. This is usually handled by the memory management subsystem. It manages various functions including allocation of new memory requests, translation of physical to virtual memories, swapping data pages, protection of specific memory pages, and so on. It may also need to manage and abstract the underlying hardware differences including memory controller intricacies and memory layout specifics. We will cover some of these topics in this section. Before we can get into the details, let’s cover some basic concepts.</p><section class="Section2 RenderAsSection2" id="Sec19"><h3 class="Heading">Address Binding</h3><p class="Para" id="Par106">Consider a short line of pseudo-code (A = B + 2) that adds 2 to variable “B” and assigns this to variable “A”. When this line gets compiled, it gets <span id="ITerm38">translated</span> into a few steps. The first step would be to read the value of B from memory. The next step would be a simple mathematical calculation to add value 2 to B and perhaps store this in the accumulator. The final step would be to copy back this value and write this back to the memory location referenced by A. As we can see here, there are multiple references to read from memory and write back to memory, also, not shown here, involving the CPU registers. If these A and B are fixed memory locations like in the case of a traditional embedded system, these locations may not change. However, in the case of a general-purpose operating system, it becomes difficult to assign a location in memory that is static from run to run or even for the duration of one run.</p><div class="Para" id="Par107">To solve this problem, the common solution is to map the program’s compiled addresses to the actual address in physical memory. In the simplest case, each program would get its own physical memory. This ensures that multiple programs can co-exist at the same time. This address binding can be done in multiple ways:<div class="OrderedList"><ol><li class="ListItem"><div class="ItemNumber">1.</div><div class="ItemContent"><p class="Para" id="Par108">The address locations could be fixed at compile time. That is, the base address or the starting address of a <span id="ITerm39">program</span> can be fixed while compiling, and the rest of the locations are referenced from that. This is not advisable since the fixed base address may not be available if another program is using it or may call for unexpected security violations.</p></div><div class="ClearBoth">&nbsp;</div></li><li class="ListItem"><div class="ItemNumber">2.</div><div class="ItemContent"><p class="Para" id="Par109">The relative address of the program could be calculated at the time the program is loaded. A typical usage model would be to calculate this at runtime using a translation layer, which maps the program address to the real physical address. This is typically handled by the memory controller and is usually the most flexible option. Most operating systems and compilers also default to this mode for security reasons to change the base address at every launch.</p></div><div class="ClearBoth">&nbsp;</div></li></ol></div></div><div class="Para"><figure class="Figure" id="Fig7"><div class="MediaObject" id="MO7"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig7_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig7_HTML.png" style="width:25em" width="1000" height="688"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-7</span><p class="SimplePara">Virtual Memory to Physical Memory Overview</p></div></figcaption></figure></div><p class="Para" id="Par110">The address that the program has access to is usually referred to as the virtual <span id="ITerm40">address</span>, and the actual location in memory is the physical address on the system. This could refer to a physical location on the RAM. As we can see in Figure <span class="InternalRef"><a href="#Fig7">4-7</a></span>, the application sees its code, static data, the variables, the stack, and so on. However, internally, the memory controller and the OS translate these to a location in physical memory. Not everything that the application sees may be residing in physical memory all the time. Also, at times, certain parts of the data could also be retrieved from storage such as disks. In the next section, we will look at how a simple translation happens between virtual memory and physical memory.</p></section><section class="Section2 RenderAsSection2" id="Sec20"><h3 class="Heading">Logical vs. Physical Address</h3><div class="Para" id="Par111">A program will have variables, instructions, and references that are included as part of the source <span id="ITerm41">code</span>. The references to these are usually referred to as the symbolic addresses. When the same program gets compiled, the compiler translates these addresses into relative addresses. This is important for the OS to then load the program in memory with a given base address and then use the relative address from that base to refer to different parts of the program. At this time, the OS can make use of the physical address mapping to refer to specific locations in memory. This is depicted in Figure <span class="InternalRef"><a href="#Fig8">4-8</a></span> where the relative address is calculated using the base address and the offset.<figure class="Figure" id="Fig8"><div class="MediaObject" id="MO8"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig8_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig8_HTML.png" style="width:35.52em" width="1421" height="459"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-8</span><p class="SimplePara">Absolute, Base, and Relative Address Concepts</p></div></figcaption></figure></div><div class="Para" id="Par112">In general, there is not enough physical memory to host all programs at the same time. This leads to the concept of virtual memory that can be mapped to physical <span id="ITerm42">memory</span>. The memory management unit is responsible for translating virtual addresses to physical addresses. Typically, most OSs have a page table, which is like a lookup table, that is used to translate virtual addresses to a physical address at runtime. When the contents that need to be referred are outside the page, the memory content is then swapped to the new page at runtime. As shown in Figure <span class="InternalRef"><a href="#Fig9">4-9</a></span>, an unwanted page is usually identified and moved out to the secondary disk. Then, the required page is moved into memory to continue with the execution.<figure class="Figure" id="Fig9"><div class="MediaObject" id="MO9"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig9_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig9_HTML.png" style="width:27.6em" width="1104" height="529"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-9</span><p class="SimplePara">Page Swapping Example</p></div></figcaption></figure></div></section><section class="Section2 RenderAsSection2" id="Sec21"><h3 class="Heading">Inter-process Communication</h3><p class="Para" id="Par113">It is often desirable to have processes communicate with each other to coordinate <span id="ITerm43">work</span>, for instance. In such cases, the OS provides one or more mechanisms to enable such process-to-process communication. These mechanisms are broadly classified as inter-process communication (IPC). There are many ways IPCs can be implemented. The two common ways are explained in the following, which involve shared memory and message passing.</p><section class="Section3 RenderAsSection3" id="Sec22"><h4 class="Heading">Shared Memory Method</h4><div class="Para" id="Par114">When two or more processes need to communicate with each other, they may create a shared <span id="ITerm44">memory</span> area that is accessible by both processes. Then, one of the processes may act as the producer of data, while the other could act as the consumer of data. The memory acts as the communication buffer between these two processes. This is a very common mechanism to communicate between processes. This is depicted in Figure <span class="InternalRef"><a href="#Fig10">4-10</a></span>.<figure class="Figure" id="Fig10"><div class="MediaObject" id="MO10"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig10_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig10_HTML.png" style="width:35.62em" width="1425" height="688"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-10</span><p class="SimplePara">Simple Shared Memory–Based Inter-process Communication</p></div></figcaption></figure></div><p class="Para" id="Par115">There are additional details on the timing, creation of memory itself, permissions, and so on. However, we will not cover the details in this book.</p></section><section class="Section3 RenderAsSection3" id="Sec23"><h4 class="Heading">Message Passing Method</h4><p class="Para" id="Par116">The other method is called message <span id="ITerm45">passing</span><span id="ITerm46">


</span> where the two processes have a predefined communication link that could be a file system, socket, named pipe, and so on and a protocol-based messaging mechanism that they use to communicate.</p><p class="Para" id="Par117">Typically, the first step would be to establish the communication channel itself. For example, in the case of a TCP/IP <span id="ITerm47">communication</span>, one of the processes could act as the server waiting on a specific port. The other process could register as a client and connect to that port. The next step could involve sharing of messages between the client and server using predefined protocols leveraging Send and Receive commands. The processes must agree on the communication parameters and flow for this to be successful. Given this, they can communicate until the IPC is terminated by either of the process. This is a common communication mechanism that is used by networking applications as well.</p></section><section class="Section3 RenderAsSection3" id="Sec24"><h4 class="Heading">Further Reading</h4><p class="Para" id="Par118">The memory management unit forms a critical part of the operating system. Additionally, some OSs use Translation Lookaside Buffers (TLBs), which contain page entries that have been recently used, multilevel page tables, and page replacement algorithms to perform optimal memory management depending on the needs. The performance, thrashing of memory, and segmentation needs vary from one OS to another. Some of these concepts are covered by the references shared later in this chapter.</p></section></section></section><section class="Section1 RenderAsSection1" id="Sec25"><h2 class="Heading">I/O Management</h2><div class="Para" id="Par119">As part of the system, there could be multiple devices that are connected and perform different input-output functions. These I/O <span id="ITerm48">devices</span> could be used for human interaction such as display panel, touch panels, keyboard, mouse, and track pads, to name a few. Another form of I/O devices could be to connect the system to storage devices, sensors, and so on. There could also be I/O devices for networking needs that implement certain parts of the networking stack. These could be Wi-Fi, Ethernet, and Bluetooth devices and so on.<figure class="Figure" id="Fig11"><div class="MediaObject" id="MO11"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig11_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig11_HTML.png" style="width:35.62em" width="1425" height="442"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-11</span><p class="SimplePara">Example I/O Controllers on a <span id="ITerm49">System</span></p></div></figcaption></figure></div><p class="Para" id="Par120">As we can see in Figure <span class="InternalRef"><a href="#Fig11">4-11</a></span>, there are varied sets of I/O devices, and each of them has a specific purpose and programming interface. They vary from one to another in the form of protocols they use to communicate such as the data format, speed at which they operate, error reporting mechanisms, and many more. However, from an abstraction point of view, the OS presents a unified I/O system that abstracts the complexity from applications. The OS handles this by establishing protocols and interfaces with each I/O controller. However, the I/O subsystem usually forms the complex part of the operating system due to the dynamics and the wide variety of I/Os involved.</p><section class="Section2 RenderAsSection2" id="Sec26"><h3 class="Heading">I/O Subsystem</h3><p class="Para" id="Par121">Input/output devices that are connected to the computer are called peripheral devices. There could be additional lines that are used to connect to these devices for communication purposes. These are called <span id="ITerm50">buses</span> that are a combination of “data lines” to transfer data, “control lines” to control a device, and “address lines” that may be used to specify address locations. There could be different buses or device protocols that an operating system may support. The most common protocols include <span id="ITerm51">Peripheral Component Interconnect Express (PCIe) protocol</span>, <span id="ITerm52">Inter-Integrated Circuit (I2C)</span>, <span id="ITerm53">Advanced Configuration and Power Interface (ACPI)</span><span id="ITerm54">



</span>, and so on. A device can be connected over one or more of these interfaces.</p><p class="Para" id="Par122">Consider the need to send a request to read the temperature of a specific device that is connected via ACPI. In this case, the operating system sends a request to the ACPI subsystem, targeting the device that handles the request and returns the data. This is then passed back to the application. In another example, we want to change the display brightness of the display device. In this case, a request is made from the application to the OS, which in turn detects the display device from the I/O subsystem and requests the appropriate display brightness control setting. The display subsystem then makes the necessary action and returns the result, for example, success or failure, back to the OS. All of these happen in a seamless fashion so that the user is not aware of the intricacies involved. Typically, there is a software component in kernel mode called as the “device driver” that handles all interfaces with a device. It helps with communicating between the device and the OS and abstracts the device specifics. Similarly, there could be a driver at the bus level usually referred to as the bus driver. Most OSs include an inbox driver that implements the bus driver. As we saw in Figure <span class="InternalRef"><a href="#Fig11">4-11</a></span>, there is usually a driver for each controller and each device.</p><p class="Para" id="Par123">The I/O devices can be broadly divided into two categories called block and character devices. Usually, most devices would have a command and data location and a protocol that the device firmware and the driver understand. The driver would fill the required data and issue a command. The device firmware would respond back to the command and return an error code that is utilized by the driver. The protocol, size, and format could differ from one device to another.</p><section class="Section3 RenderAsSection3" id="Sec27"><h4 class="Heading">Block Devices</h4><p class="Para" id="Par124">These are devices with which the I/O device controller communicates by sending <span id="ITerm55">blocks</span> of data. A block is referred to as a group of bytes that are referred together for Read/Write purposes. For example, when a request is made to write a file to the storage disk or if we need to transfer a file to a connected USB drive or if we need to read an image from a connected camera, the transfers are made as block reads. These could be defined by the device, for example, in multiple blocks of 512 or 1024 bytes. The device driver would access by specifying the size of Read/Writes.</p></section><section class="Section3 RenderAsSection3" id="Sec28"><h4 class="Heading">Character Devices</h4><p class="Para" id="Par125">Another class of devices are character devices that typically have a protocol defined using which the driver can communicate with the device. The subtle <span id="ITerm56">difference</span> is that the communication happens by sending and receiving single characters, which is usually a byte or an octet. Many serial port devices like keyboards, some sensor devices, and microcontrollers follow this mechanism.</p><p class="Para" id="Par126">The protocols used by the different devices (block devices or character devices) could vary from one to another. There are three main categories of I/O protocols that are used.</p></section><section class="Section3 RenderAsSection3" id="Sec29"><h4 class="Heading">Special Instruction I/O</h4><p class="Para" id="Par127">There could be specific CPU <span id="ITerm57">instructions</span> that are custom developed for communicating with and controlling the I/O devices. For example, there could be a CPU-specific protocol to communicate with the embedded controller. This may be needed for faster and efficient communication. However, such type of I/Os are special and smaller in number.</p></section><section class="Section3 RenderAsSection3" id="Sec30"><h4 class="Heading">Memory-Mapped I/O</h4><p class="Para" id="Par128">The most common form of I/O <span id="ITerm58">protocol</span> is <span id="ITerm59">memory-mapped I/O (MMIO)</span>. As we discussed in the “Memory Management” section, the device and OS agree on a common address range carved out by the OS, and the I/O device makes reads and writes from/to this space to communicate to the OS.</p><div class="Para" id="Par129">OS components such as drivers will communicate using this interface to talk to the device. MMIO is also an effective mechanism for data transfer that can be implemented without using up precious CPU cycles. Hence, it is used to enable high-speed communication for network and graphics devices that require high data transfer rates due to the volume of data being passed.<figure class="Figure" id="Fig12"><div class="MediaObject" id="MO12"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig12_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig12_HTML.png" style="width:22.6em" width="904" height="604"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-12</span><p class="SimplePara">Memory-Mapped I/O Flow in a Graphics Device Example</p></div></figcaption></figure></div><p class="Para" id="Par130">Figure <span class="InternalRef"><a href="#Fig12">4-12</a></span> depicts the case where the graphics driver acts as the I/O device and a <span id="ITerm60">memory-mapped</span> location is used to share and communicate to the graphics device.</p></section><section class="Section3 RenderAsSection3" id="Sec31"><h4 class="Heading">Direct Memory Access (DMA)</h4><p class="Para" id="Par131">As we discussed earlier, there could be devices that run at a slower speed than supported by the <span id="ITerm61">CPU</span> or the bus it is connected on. In this case, the device can leverage <span id="ITerm62">DMA</span>. Here, the OS grants authority to another controller, usually referred to as the direct memory access controller, to interrupt the CPU after a specific data transfer is complete. The devices running at a smaller rate can communicate back to the DMA controller after completing its operation.</p><p class="Para ParaTypeImportant" id="Par132">Most OSs also handle additional specific device classes, blocking and nonblocking I/Os, and other I/O controls. As a programmer, you could be interacting with devices that may perform caching (an intermediate layer that acts as a buffer to report data faster) and have different error reporting mechanisms, protocols, and so on.</p><p class="Para" id="Par133">Next, let’s consider the difference between a polled and an interrupt-driven I/O.</p></section></section><section class="Section2 RenderAsSection2" id="Sec32"><h3 class="Heading">Polled vs. Interrupt I/Os</h3><div class="Para" id="Par134">Consider our temperature <span id="ITerm63">device</span> discussed previously. If the device supports a polled I/O mechanism, the typical flow would involve requesting the device for temperature by issuing the command and filling the data field. At this point, the host system could wait for the operation to complete. In this case, it could be a blocked I/O call and a synchronous operation. However, it may not be efficient to block the execution. So, alternatively, the host system may issue a call and check the response at a later point in time if the operation has been completed. These could be implemented as a polled and an interrupt-driven I/O as shown in Figure <span class="InternalRef"><a href="#Fig13">4-13</a></span>.<figure class="Figure" id="Fig13"><div class="MediaObject" id="MO13"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig13_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig13_HTML.png" style="width:35.52em" width="1421" height="854"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-13</span><p class="SimplePara">Example Polled vs. Interrupt-Driven I/O Flow</p></div></figcaption></figure></div><p class="Para" id="Par135">One mechanism would be for the host to poll the device and check the status of the <span id="ITerm64">operation</span>. There is usually a status register that determines if the device has completed the operation. This is a common I/O flow for some devices as shown in Figure <span class="InternalRef"><a href="#Fig13">4-13</a></span> (A).</p><p class="Para" id="Par136">Another mechanism would be to use the interrupt-driven mechanism. In this case, the request for operation is issued to the device. A callback function is also defined that needs to get called when the operation is completed. The device would continue and complete the operation and raise an interrupt once done as shown in Figure <span class="InternalRef"><a href="#Fig13">4-13</a></span> (B). The callback function would be called appropriately to handle the interrupt. The callback function is also called as the ISR (Interrupt Service Routine), and as the name suggests, it services the interrupt. As a programmer, it is important to keep in mind that these ISRs are short-lived and lightweight and need to service the interrupt raised as quickly as possible.</p></section><section class="Section2 RenderAsSection2" id="Sec33"><h3 class="Heading">I/O and Performance</h3><p class="Para" id="Par137">The I/O <span id="ITerm65">subsystem</span> plays a major factor in the overall performance of the system. As a software programmer, some of the operations done by your program could inadvertently impact the performance of the system. For example, a program could have multiple context switches arising due to the delays, responsiveness, and performance of the devices on the system. This may lead to an overall impact on the performance of your application. An application performing frequent writes to the disk or making many requests for continuous memory allocation can lead to excessive page swapping. A program could request for memory and may inadvertently not free up the memory requested after usage. These can cause memory leaks that may result in lower available memory and eventually impact the system performance. Also, requests for large blocks of contiguous memory may also have an impact since the memory subsystem may have to swap memory to accommodate the same.</p><p class="Para" id="Par138">A programmer would need to be cognizant of the I/O subsystem and its limitations in terms of performance expectations, limits/boundaries, and potential impacts. This is required since it may not only affect their application but could also affect the overall platform eventually.</p></section><section class="Section2 RenderAsSection2" id="Sec34"><h3 class="Heading">Synchronization Concepts</h3><p class="Para" id="Par139">Given there are devices and apps that must run together, access to hardware needs to be properly <span id="ITerm66">synchronized</span>. There could be situations where more than one application may want to communicate to the same hardware device and the hardware device may not support concurrent access. It is important to know a few basics about how the OS uses synchronization to avoid potential conflicts. For this, let’s start with the concepts of atomicity, critical sections, and locks.</p><div class="Para" id="Par140">Consider a multi-threaded application where a function is incrementing a global static variable:<div class="ProgramCode" id="PC1"><div class="LineGroup"><div class="FixedLine">count++; // count is a location in RAM</div></div></div></div><div class="Para" id="Par141">The preceding statement can be decomposed into three operations, which include fetching the value of count, incrementing the value of count in a local register, and then storing the updated value back to memory. However, as we saw earlier in this chapter, the thread that was executing this instruction could have been <span id="ITerm67">swapped</span> in the middle of this operation. At the same time, there could be another thread that could be swapped in and may try to increment count. This is depicted in Figure <span class="InternalRef"><a href="#Fig14">4-14</a></span> where Thread A was in the middle of incrementing while another thread tried to read the value of count. Ideally, Thread B should be able to access the count variable only after the operation in Thread A was completed.<figure class="Figure" id="Fig14"><div class="MediaObject" id="MO14"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig14_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig14_HTML.png" style="width:35.62em" width="1425" height="679"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-14</span><p class="SimplePara">Example of Increment Operation (count++) Across Threads</p></div></figcaption></figure></div><p class="Para" id="Par142">If more than one thread tries to increment count at the same time, we may get unexpected results at any of the three steps we’ve described in the preceding. Such bugs are quite difficult to recreate and locate. This is an example where we need atomicity in instruction execution. Atomicity, as the name suggests, is a group of instructions that may need to be executed together as if they were a single instruction. The OS attempts to protect us from interrupting individual instructions while they are being executed.</p><section class="Section3 RenderAsSection3" id="Sec35"><h4 class="Heading">Critical Sections</h4><p class="Para" id="Par143">In multi-threaded applications, if one thread tries to change the value of shared data at the same time as another thread tries to read the value, there could be a race condition across threads. In this case, the result can be unpredictable. The access to such shared variables via shared memory, files, ports, and other I/O resources needs to be synchronized to protect it from being corrupted. In order to support this, the operating system provides mutexes and semaphores to coordinate access to these shared resources.</p></section><section class="Section3 RenderAsSection3" id="Sec36"><h4 class="Heading">Mutex</h4><div class="Para" id="Par144">A <span id="ITerm68">mutex</span><span id="ITerm69">


</span> is used for implementing mutual exclusion: either of the participating processes or threads can have the key (mutex) and proceed with their work. The other one would have to wait until the one holding the mutex finishes. As we can see in Figure <span class="InternalRef"><a href="#Fig15">4-15</a></span>, both Threads A and B would like to access a shared resource such as a file and write to it. Thread A initiates a request to acquire a lock before it can access the file. Once the lock is acquired, it finishes its operations on the file and then releases the lock. During this time, Thread B will not be able to access the file. Once completed, Thread B can follow the same procedure to access the shared resource.<figure class="Figure" id="Fig15"><div class="MediaObject" id="MO15"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig15_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig15_HTML.png" style="width:30.1em" width="1204" height="509"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-15</span><p class="SimplePara">Example Mutex</p></div></figcaption></figure></div><div class="Para" id="Par145">A sample pseudo-code of the same implementation is shown in the following. As we can see, both threads try to acquire the lock before accessing the shared resource, that is, count in this case:<div class="ProgramCode" id="PC2"><div class="LineGroup"><div class="FixedLine">incrementCount()</div><div class="FixedLine">{</div><div class="FixedLine">&nbsp;&nbsp;&nbsp;&nbsp;mutex_lock(&amp;COUNT_MUTEX);</div><div class="FixedLine">&nbsp;&nbsp;&nbsp;&nbsp;count = count + 1;</div><div class="FixedLine">&nbsp;&nbsp;&nbsp;&nbsp;mutex_unlock(&amp;COUNT_MUTEX);</div><div class="FixedLine">}</div></div></div></div></section><section class="Section3 RenderAsSection3" id="Sec37"><h4 class="Heading">Semaphore</h4><div class="Para" id="Par146">A <span id="ITerm70">semaphore</span><span id="ITerm71">


</span> is a generalized mutex. A binary semaphore can assume a value of 0/1 and can be used to perform locks to certain critical sections. It is usually helpful to batch lock resource requests for better performance. As we can see in Figure <span class="InternalRef"><a href="#Fig16">4-16</a></span>, each of the threads A, B, C, and D requires access to the critical shared resource. When each of the threads requests to acquire the lock, the semaphore increments a counter and also maintains a waiting list of threads on the shared resource. Typically semaphores also expose two functions wait() and signal() that may be used to send notifications to threads appropriately.<figure class="Figure" id="Fig16"><div class="MediaObject" id="MO16"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig16_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig16_HTML.png" style="width:32.6em" width="1304" height="692"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-16</span><p class="SimplePara">Example Semaphore</p></div></figcaption></figure></div><p class="Para" id="Par147">Now that we have seen how mutexes and semaphores work, we will go over another concept called deadlocks that may happen when the OS attempts to synchronize the operations on the system.</p></section><section class="Section3 RenderAsSection3" id="Sec38"><h4 class="Heading">Deadlocks</h4><div class="Para" id="Par148">In general, when we access a resource, we don’t always know all the ways other parts of the system may also access that resource. The OS manages this resource access, but there could be certain situations where a set of processes become blocked because each process is holding a resource and waiting for another resource acquired by some other process. This is called as a <span id="ITerm72">deadlock</span><span id="ITerm73">


</span>. As we can see in Figure <span class="InternalRef"><a href="#Fig17">4-17</a></span>, Process A holds Resource 1 and requires Resource 2. However, Process B already is holding Resource 2, but requires Resource 1. Unless either of them releases their resource, neither of the processes may be able to move forward with the execution.<figure class="Figure" id="Fig17"><div class="MediaObject" id="MO17"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig17_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig17_HTML.png" style="width:25.1em" width="1004" height="817"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-17</span><p class="SimplePara">Example of a Deadlock</p></div></figcaption></figure></div><div class="Para" id="Par149">To elaborate from Figure <span class="InternalRef"><a href="#Fig17">4-17</a></span>, a deadlock can arise if the following four conditions hold:<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par150">Mutual Exclusion: There is at least one resource on the system that is not shareable. This means that only one process can access this at any point in time. In the preceding example, Resources 1 and 2 can be accessed by only one process at any time.</p></li><li><p class="Para" id="Par151">Hold and Wait: A process is holding at least one resource and is waiting for other resources to proceed with its action. In the preceding example, both Processes A and B are holding at least one resource.</p></li><li><p class="Para" id="Par152">No Preemption: A resource cannot be forcefully taken from a process unless released automatically.</p></li><li><p class="Para" id="Par153">Circular Wait: A set of processes are waiting for each other in circular form. As we can see in Figure <span class="InternalRef"><a href="#Fig17">4-17</a></span>, the arrows form a circular loop.</p></li></ul></div></div><p class="Para" id="Par154">There are various mechanisms available to handle deadlocks using <span id="ITerm74">mutexes</span> and semaphores that we discussed earlier along with additional algorithms to detect, avoid, and prevent deadlocks on the system. As a programmer, you would want to use these synchronization mechanisms.</p><p class="Para" id="Par155">To summarize, the I/O subsystem plays a critical role in the overall performance of the system. Memory management, interrupt responses, handling of I/O serializations, synchronizations, contentions, and so on play an important role in the overall performance of the system. Defining them, tuning and optimizing these are a major challenge for any operating system. There are various adaptive methodologies and runtime optimizations that various OS vendors invest in and try to adopt. These will continue to evolve for the better usage of our hardware.</p></section></section></section><section class="Section1 RenderAsSection1" id="Sec39"><h2 class="Heading">File Systems</h2><div class="Para" id="Par156">Applications<span id="ITerm75">


</span> often need to read and write files to achieve their goals. We leverage the OS to create, read, and write such files on the system. We depend on the OS to maintain and manage files on the system. OS file systems have two main components to facilitate file management:<div class="OrderedList"><ol><li class="ListItem"><div class="ItemNumber">1.</div><div class="ItemContent"><p class="Para" id="Par157">Directory Service: There is a need to uniquely manage files in a structured manner, manage access, and provide Read-Write-Edit controls on the file system. This is taken care by a layer called as the <strong class="EmphasisTypeBold ">directory service</strong>.</p></div><div class="ClearBoth">&nbsp;</div></li><li class="ListItem"><div class="ItemNumber">2.</div><div class="ItemContent"><p class="Para" id="Par158">Storage Service: There is a need to communicate to the underlying hardware such as the disk. This is managed by a <strong class="EmphasisTypeBold ">storage service</strong> that abstracts different types of storage devices on the system.</p></div><div class="ClearBoth">&nbsp;</div></li></ol></div></div><div class="Para"><figure class="Figure" id="Fig18"><div class="MediaObject" id="MO18"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig18_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig18_HTML.png" style="width:27.5em" width="1100" height="854"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-18</span><p class="SimplePara">File System Overview with File <span id="ITerm76">Access Process</span></p></div></figcaption></figure></div><p class="Para" id="Par159">As shown in Figure <span class="InternalRef"><a href="#Fig18">4-18</a></span>, when a new file is created, the file name and path are passed to the directory service, which creates a unique file ID. This reference is used later to read contents back from the file using the storage service.</p><p class="Para" id="Par160">We will start with file concepts and then proceed to the functionality details.</p><section class="Section2 RenderAsSection2" id="Sec40"><h3 class="Heading">File Concepts</h3><p class="Para" id="Par161">From the perspective of the user, a file is a collection of related data that is stored together and can be accessed using a unique file ID usually referred as the file name. These files can be represented internally by different methods. For example, there could be .bin files in Windows, which only represent a sequence of bytes. There could be other structured contents with headers and specific sections in the file. For example, an EXE is also a file format in Windows with specific headers, a body, and controls in place. There are also many application-specific files, with their own formats. It is up to the programmer to define and identify if they require a custom file format for their application or if they can leverage a standard or common file format such as the <span id="ITerm77">JavaScript Object Notation (JSON)</span> or the <span id="ITerm78">Extensible Markup Language (XML)</span>.</p><p class="Para" id="Par162">As a programmer, it may be important to know the attributes of the file before accessing it. The common attributes of any file include the location of the file, file extension, size, access controls, and some history of operations done on the file, to name a few. Some of these are part of the so-called file control block, which a user has access to via the OS. Most OSs expose APIs using which the programmer can access the details in the file control block. For the user, these are exposed on the graphical user interface via built-in tools shipped with the OS.</p></section><section class="Section2 RenderAsSection2" id="Sec41"><h3 class="Heading">Directory Namespace</h3><p class="Para" id="Par163">The operating <span id="ITerm79">system</span> defines a logical ordering of different files on the system based on the usage and underlying storage services. One of the criteria most OSs adopt is to structure their directory service to locate files efficiently.</p><div class="Para" id="Par164">As shown in Figure <span class="InternalRef"><a href="#Fig19">4-19</a></span>, most OSs organize their files in a hierarchical form with files organized inside folders. Each folder in this case is a directory. This structure is called as the directory namespace. The directory service and namespace have additional capabilities such as searches by size, type, access levels, and so on. The directory namespaces can be multileveled and adaptive in modern OSs as we can see in the following folder structure with folders created inside another folder.<figure class="Figure" id="Fig19"><div class="MediaObject" id="MO19"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig19_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig19_HTML.png" style="width:27.4em" width="1096" height="946"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-19</span><p class="SimplePara">Sample Directory <span id="ITerm80">Structure</span></p></div></figcaption></figure></div><p class="Para" id="Par165">As a programmer, you should be aware of a few additional basic concepts from the file system point of view. We will discuss them in this section.</p><section class="Section3 RenderAsSection3" id="Sec42"><h4 class="Heading">Access Control</h4><p class="Para" id="Par166">There are different access levels that can be applied at file and directory levels. For <span id="ITerm81">example</span>, we may not want a user-mode application running with a normal user credential to be able to make changes to some OS files/services. The OS provides different access control IDs and permissions to different users on the system. Also, each file may also have different levels of permissions to Read, Write, Modify, and so on. For example, there may be specific files that we may want anyone to be able to access and Read but not Write and Modify. The file system provides and manages the controls to all files when accessed at runtime. These may also be helpful when more than one user is using the same system.</p></section><section class="Section3 RenderAsSection3" id="Sec43"><h4 class="Heading">Concurrency and Cleanup Control</h4><p class="Para" id="Par167">There are many <span id="ITerm82">cases</span> when the OS needs to ensure that a file is not moved or deleted when it is in use. For example, if a user is making changes to a file, the OS needs to ensure that the same file cannot be moved or deleted by another application or process. In this case, the OS would cause the attempt to move or delete the file to fail with an appropriate error code. As a programmer, it is appropriate to access a file with the required access level and mode (Read/Write). This also helps to be in line with the concurrency needs of the OS and guards against inconsistent updates.</p><p class="Para" id="Par168">The OS also needs to be able to periodically clear temporarily created files that may no longer be required for the functioning of the system. This is typically done using a garbage collector on the system. Many OSs mark unused files over a period of time and have additional settings that are exposed, which the user can set to clean up files from specified locations automatically.</p><p class="Para" id="Par169">Overall, the file system provides access, access controls, and protection mechanisms to files in the directory namespace. The programmer needs to be aware of the protections and have the right access controls (privileges) to interact with the file system successfully.</p></section></section></section><section class="Section1 RenderAsSection1" id="Sec44"><h2 class="Heading">Access and Protection</h2><p class="Para" id="Par170">If we have a system that is used by only one user without any access, <span id="ITerm83">networked</span> or otherwise, to other systems, there may still not be assurance that the contents in the system are protected. There is still a need to protect the program resources from other applications. Also, there may be a need to protect critical devices on the system.</p><p class="Para" id="Par171">In practice, there is always a need to connect and share resources and data between systems. Hence, it is important to protect these resources accordingly. The OS provides APIs that help with access control and protection. Let’s start with some of the concepts.</p><section class="Section2 RenderAsSection2" id="Sec45"><h3 class="Heading">Rings: User Mode and Kernel Mode</h3><p class="Para" id="Par172">We briefly covered user-mode and kernel-mode processes in the “Scheduling” section. One of the reasons the separation between user mode and kernel mode is implemented by most OSs is that it ensures different privilege levels are granted to programs, based on which mode they run in.</p><div class="Para" id="Par173">As shown in Figure <span class="InternalRef"><a href="#Fig20">4-20</a></span>, an abstract OS divides the program execution privileges into different rings. Internally, programs running in specific rings are associated with specific access levels and privileges. For example, applications and user-mode services running in Ring 3 would not be able to access the hardware directly. The drivers running on the Ring 0 level would have the highest privileges and access to the hardware on the system. In practice, most OSs only leverage two rings, which are Ring 0 and Ring 3.<figure class="Figure" id="Fig20"><div class="MediaObject" id="MO20"><img alt="../images/503707_1_En_4_Chapter/503707_1_En_4_Fig20_HTML.png" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484271070/files/images/503707_1_En_4_Chapter/503707_1_En_4_Fig20_HTML.png" style="width:22.6em" width="904" height="717"></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-20</span><p class="SimplePara">Applications, Drivers, and Rings in an Operating <span id="ITerm84">System</span></p></div></figcaption></figure></div></section><section class="Section2 RenderAsSection2" id="Sec46"><h3 class="Heading">Virtualization</h3><p class="Para" id="Par174">Consider the scenario where it may be required to have multiple closed environments that assume to have dedicated access to the resources on the platform. Operating systems and modern hardware provide a feature called virtualization that, you guessed it, virtualizes the hardware such that each calling environment believes it has the dedicated access it needs to function.</p><p class="Para" id="Par175">Virtualization is delivered via so-called <span id="ITerm85">virtual machines (VMs)</span>. A VM has its own <strong class="EmphasisTypeBold ">guest</strong> OS, which may be the same as or different from the underlying <strong class="EmphasisTypeBold ">host</strong> OS. A user can launch a VM, much like running any other program, and log into the guest OS. The host OS provides a hypervisor, which manages the access to the hardware. The guest OS is usually unaware of the internals and passes any resource/hardware requests to the host OS. The user can completely customize their VM and perform all their actions on this VM without affecting the host OS or any other VM on the system. At a high level, VMs help effectively utilize the hardware resources and are used heavily in server and cloud deployments.</p></section><section class="Section2 RenderAsSection2" id="Sec47"><h3 class="Heading">Protection</h3><p class="Para" id="Par176">There could be different security threats that may arise during the usage of a computer. These could attempt to access different critical resources on the <span id="ITerm86">platform</span> such as data, compute, memory, and so on. The operating system needs to be able to detect any such attempts and potentially mitigate them. A threat could be any local or remote program that may be attempting to compromise the integrity of the resources in the system. To mitigate this, modern OSs usually implement checks to detect and protect against such incursions.</p><p class="Para" id="Par177">The most common protection would be to authorize the requester and apply authentication to any new request to the system. For example, when a request is made to a critical resource, the operating system would verify the user request (which is called as authentication) and their approved access levels (which is called authorization) and controls before providing access to a critical resource on the system. The OS may also have Access Control Lists (ACLs) that contain mapping of system resources to different permission levels. This is used internally before the OS grants permissions to any resource. Additionally, the OS may also provide services to encrypt and verify certificates that help with enhancing the security and protection of the system itself.</p><p class="Para" id="Par178">To summarize, the programmer needs to be aware of the various access controls and protection mechanisms in place and use the right protocols and OS services to successfully access resources on the system.</p></section></section><section class="Section1 RenderAsSection1" id="Sec48"><h2 class="Heading">User Interface and Shell</h2><p class="Para" id="Par179">Although the <span id="ITerm87">user interface (UI)</span> is not part of the OS kernel itself, this is typically considered to be an integral part of the OS. That said, many OSs support different UIs, many of which are provided by third parties, for instance.</p><p class="Para" id="Par180">There can be multiple user interfaces for the OS all being implemented either as a text-based interface (e.g., MS-DOS) or a graphical-based interface (e.g., Microsoft Windows 10, macOS, etc.). The graphical user interface is the rich set of graphical front-end interfaces and functionalities provided by the OS for the user to interact with the computer. There could be an alternate simpler interface through a command line shell interface that most OSs also provide for communication. This is a text-based interface. It is common for programmers to use the shell interface instead of the GUI for quickly traversing through the file system and interacting with the <span id="ITerm88">OS</span>. It requires the user to be aware of the commands and have the knowledge of the underlying OS implementations to be able to use it efficiently.</p><p class="Para" id="Par181">It is important for the software developer to be aware that the user interface and the shell interface may have an impact on their choice of programing language, handling of command line arguments, handling of the standard input-output pipes and interfacing with OS policies, and so on. Please note that the user interface and the features can be quite varied and different from each OS to another and are beyond the scope of this book.</p></section><section class="Section1 RenderAsSection1" id="Sec49"><h2 class="Heading">Some OS Specifics</h2><p class="Para" id="Par182">All OSs have features that may be unique to them. For example, UNIX has its own level of file abstraction and a hierarchical namespace. It handles heavyweight processes uniquely and supports pipes and signals for IPCs. Some of the recent UNIX enhancements provide additional capabilities and fixes across many of the IPC mechanisms.</p><p class="Para" id="Par183">Similarly, Windows NT has a layered architecture with Win32 APIs and a contained <span id="ITerm89">Windows Driver Framework (WDF)</span> for driver development. Windows also has its unique way of handling plug and play (PnP) of devices on the system, power management, and I/O subsystem. Some of these may vary from one Windows version to the other as well.</p><p class="Para" id="Par184">From a programmer point of view, most of the basic concepts remain similar across these OSs. However, there could be few modifications and enhancements that you need to be aware of for your code to work across OSs. For example, the paths used to access files on the system or APIs referenced may be dependent on the OS/shell; and if you don’t code for these situations, your code may not work as expected across OSs. You may want to keep these in mind at development. Further details are beyond the scope of this book.</p></section><section class="Section1 RenderAsSection1" id="Sec50"><h2 class="Heading">Summary</h2><p class="Para" id="Par185">In this chapter, we have described how the operating system forms an integral part of the system providing numerous capabilities including interaction with hardware and users and managing programs. OSs employ many design considerations and strategies based on which the OS abstracts and ensures seamless usage of the system.</p><p class="Para" id="Par186">As a software developer, you could be part of a larger ecosystem that could delve into device management, networking, web development, data management, and many other domains. The interfaces between the different domains and the way the operating system streamlines the operations between them are important for a software developer to comprehend and make meaningful decisions. Understanding these fundamentals helps in applying them at the various stages of software development ranging from architecture, design, deployment, and debug by taking the right choices.</p></section><section class="Section1 RenderAsSection1" id="Sec51"><h2 class="Heading">References and Further Reading</h2><div class="Para" id="Par187">
<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par188">Arpaci-Dusseau, R. H.-D (2018). <em class="EmphasisTypeItalic ">Three Easy Pieces.</em> Arpaci-Dusseau Books. CITATION Rem18\l 1033. Arpaci-Dusseau, 2018</p></li><li><p class="Para" id="Par189">Avi Silberschatz, P. B. (2012). <em class="EmphasisTypeItalic ">Operating System Concepts (Ninth Edition)</em>. John Wiley &amp; Sons, Inc. CITATION Avi12\l 1033. Avi Silberschatz, 2012</p></li></ul></div>
</div></section></div></div></div></div><link rel="stylesheet" href="/files/public/epub-reader/override_v1.css" crossorigin="anonymous"><link rel="stylesheet" href="/api/v2/epubs/urn:orm:book:9781484271070/files/css/springer_epub.css" crossorigin="anonymous"></div></div></section>
</div>

https://learning.oreilly.com